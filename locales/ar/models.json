{
  "01-ai/Yi-1.5-34B-Chat-16K": {
    "description": "Yi-1.5 34B، يقدم أداءً ممتازًا في التطبيقات الصناعية بفضل مجموعة التدريب الغنية."
  },
  "01-ai/Yi-1.5-6B-Chat": {
    "description": "Yi-1.5-6B-Chat هو متغير من سلسلة Yi-1.5، وهو نموذج دردشة مفتوح المصدر. Yi-1.5 هو إصدار مطور من Yi، تم تدريبه على 500B من البيانات عالية الجودة، وتم تحسينه على 3M من عينات التعديل المتنوعة. مقارنةً بـ Yi، يظهر Yi-1.5 أداءً أقوى في الترميز، والرياضيات، والاستدلال، والامتثال للتعليمات، مع الحفاظ على قدرة ممتازة في فهم اللغة، والاستدلال العام، وفهم القراءة. يتوفر هذا النموذج بإصدارات بطول سياق 4K و16K و32K، مع إجمالي تدريب يصل إلى 3.6T توكن."
  },
  "01-ai/Yi-1.5-9B-Chat-16K": {
    "description": "Yi-1.5 9B يدعم 16K توكن، ويوفر قدرة توليد لغوية فعالة وسلسة."
  },
  "360gpt-pro": {
    "description": "360GPT Pro كعضو مهم في سلسلة نماذج 360 AI، يلبي احتياجات معالجة النصوص المتنوعة بفعالية، ويدعم فهم النصوص الطويلة والحوار المتعدد الجولات."
  },
  "360gpt-turbo": {
    "description": "يوفر 360GPT Turbo قدرات حسابية وحوارية قوية، ويتميز بفهم دلالي ممتاز وكفاءة في التوليد، مما يجعله الحل المثالي للمؤسسات والمطورين كمساعد ذكي."
  },
  "360gpt-turbo-responsibility-8k": {
    "description": "360GPT Turbo Responsibility 8K يركز على الأمان الدلالي والتوجيه المسؤول، مصمم خصيصًا لتطبيقات تتطلب مستوى عالٍ من الأمان في المحتوى، مما يضمن دقة وموثوقية تجربة المستخدم."
  },
  "360gpt2-pro": {
    "description": "360GPT2 Pro هو نموذج متقدم لمعالجة اللغة الطبيعية تم إطلاقه من قبل شركة 360، يتمتع بقدرات استثنائية في توليد وفهم النصوص، خاصة في مجالات التوليد والإبداع، ويستطيع التعامل مع مهام تحويل اللغة المعقدة وأداء الأدوار."
  },
  "4.0Ultra": {
    "description": "Spark4.0 Ultra هو أقوى إصدار في سلسلة نماذج Spark، حيث يعزز فهم النصوص وقدرات التلخيص مع تحسين روابط البحث عبر الإنترنت. إنه حل شامل يهدف إلى تعزيز إنتاجية المكتب والاستجابة الدقيقة للاحتياجات، ويعتبر منتجًا ذكيًا رائدًا في الصناعة."
  },
  "Baichuan2-Turbo": {
    "description": "يستخدم تقنية تعزيز البحث لتحقيق الربط الشامل بين النموذج الكبير والمعرفة الميدانية والمعرفة من جميع أنحاء الشبكة. يدعم تحميل مستندات PDF وWord وغيرها من المدخلات، مما يضمن الحصول على المعلومات بشكل سريع وشامل، ويقدم نتائج دقيقة واحترافية."
  },
  "Baichuan3-Turbo": {
    "description": "تم تحسينه لمشاهد الاستخدام المتكررة في الشركات، مما أدى إلى تحسين كبير في الأداء وتكلفة فعالة. مقارنةً بنموذج Baichuan2، زادت قدرة الإبداع بنسبة 20%، وزادت قدرة الإجابة على الأسئلة المعرفية بنسبة 17%، وزادت قدرة التمثيل بنسبة 40%. الأداء العام أفضل من GPT3.5."
  },
  "Baichuan3-Turbo-128k": {
    "description": "يمتلك نافذة سياق طويلة جدًا تصل إلى 128K، تم تحسينه لمشاهد الاستخدام المتكررة في الشركات، مما أدى إلى تحسين كبير في الأداء وتكلفة فعالة. مقارنةً بنموذج Baichuan2، زادت قدرة الإبداع بنسبة 20%، وزادت قدرة الإجابة على الأسئلة المعرفية بنسبة 17%، وزادت قدرة التمثيل بنسبة 40%. الأداء العام أفضل من GPT3.5."
  },
  "Baichuan4": {
    "description": "النموذج الأول في البلاد من حيث القدرة، يتفوق على النماذج الرئيسية الأجنبية في المهام الصينية مثل الموسوعات، والنصوص الطويلة، والإبداع. كما يتمتع بقدرات متعددة الوسائط رائدة في الصناعة، ويظهر أداءً ممتازًا في العديد من معايير التقييم الموثوقة."
  },
  "Baichuan4-Air": {
    "description": "النموذج الأول محليًا، يتفوق على النماذج الرئيسية الأجنبية في المهام الصينية مثل المعرفة الموسوعية، النصوص الطويلة، والإبداع. كما يتمتع بقدرات متعددة الوسائط الرائدة في الصناعة، ويظهر أداءً ممتازًا في العديد من معايير التقييم الموثوقة."
  },
  "Baichuan4-Turbo": {
    "description": "النموذج الأول محليًا، يتفوق على النماذج الرئيسية الأجنبية في المهام الصينية مثل المعرفة الموسوعية، النصوص الطويلة، والإبداع. كما يتمتع بقدرات متعددة الوسائط الرائدة في الصناعة، ويظهر أداءً ممتازًا في العديد من معايير التقييم الموثوقة."
  },
  "Doubao-lite-128k": {
    "description": "دو باو-لايت يوفر سرعة استجابة فائقة وقيمة جيدة للكلفة، ويقدم خيارات أكثر مرونة للعملاء في سيناريوهات مختلفة. يدعم الاستدلال والتنقيح بسعة سياق 128k."
  },
  "Doubao-lite-32k": {
    "description": "دو باو-لايت يوفر سرعة استجابة فائقة وقيمة جيدة للكلفة، ويقدم خيارات أكثر مرونة للعملاء في سيناريوهات مختلفة. يدعم الاستدلال والتنقيح بسعة سياق 32k."
  },
  "Doubao-lite-4k": {
    "description": "دو باو-لايت يوفر سرعة استجابة فائقة وقيمة جيدة للكلفة، ويقدم خيارات أكثر مرونة للعملاء في سيناريوهات مختلفة. يدعم الاستدلال والتنقيح بسعة سياق 4k."
  },
  "Doubao-pro-128k": {
    "description": "النموذج الرئيسي الأفضل أداءً، مناسب لمعالجة المهام المعقدة، يقدم أداءً جيدًا في السيناريوهات مثل الاستجابة المرجعية، والتلخيص، والإبداع، وتصنيف النصوص، وألعاب الأدوار. يدعم الاستدلال والتنقيح بسعة سياق 128k."
  },
  "Doubao-pro-32k": {
    "description": "النموذج الرئيسي الأفضل أداءً، مناسب لمعالجة المهام المعقدة، يقدم أداءً جيدًا في السيناريوهات مثل الاستجابة المرجعية، والتلخيص، والإبداع، وتصنيف النصوص، وألعاب الأدوار. يدعم الاستدلال والتنقيح بسعة سياق 32k."
  },
  "Doubao-pro-4k": {
    "description": "النموذج الرئيسي الأفضل أداءً، مناسب لمعالجة المهام المعقدة، يقدم أداءً جيدًا في السيناريوهات مثل الاستجابة المرجعية، والتلخيص، والإبداع، وتصنيف النصوص، وألعاب الأدوار. يدعم الاستدلال والتنقيح بسعة سياق 4k."
  },
  "ERNIE-3.5-128K": {
    "description": "نموذج اللغة الكبير الرائد الذي طورته بايدو، يغطي كمية هائلة من البيانات باللغة الصينية والإنجليزية، ويتميز بقدرات عامة قوية، يمكنه تلبية معظم متطلبات الحوار، والإجابة على الأسئلة، وإنشاء المحتوى، وتطبيقات الإضافات؛ يدعم الاتصال التلقائي بإضافات بحث بايدو، مما يضمن تحديث معلومات الإجابة."
  },
  "ERNIE-3.5-8K": {
    "description": "نموذج اللغة الكبير الرائد الذي طورته بايدو، يغطي كمية هائلة من البيانات باللغة الصينية والإنجليزية، ويتميز بقدرات عامة قوية، يمكنه تلبية معظم متطلبات الحوار، والإجابة على الأسئلة، وإنشاء المحتوى، وتطبيقات الإضافات؛ يدعم الاتصال التلقائي بإضافات بحث بايدو، مما يضمن تحديث معلومات الإجابة."
  },
  "ERNIE-3.5-8K-Preview": {
    "description": "نموذج اللغة الكبير الرائد الذي طورته بايدو، يغطي كمية هائلة من البيانات باللغة الصينية والإنجليزية، ويتميز بقدرات عامة قوية، يمكنه تلبية معظم متطلبات الحوار، والإجابة على الأسئلة، وإنشاء المحتوى، وتطبيقات الإضافات؛ يدعم الاتصال التلقائي بإضافات بحث بايدو، مما يضمن تحديث معلومات الإجابة."
  },
  "ERNIE-4.0-8K-Latest": {
    "description": "نموذج اللغة الكبير الرائد الذي طورته بايدو، والذي شهد ترقية شاملة في القدرات مقارنةً بـERNIE 3.5، ويستخدم على نطاق واسع في مجالات متعددة لمهام معقدة؛ يدعم الاتصال التلقائي بإضافات بحث بايدو لضمان تحديث معلومات الإجابة."
  },
  "ERNIE-4.0-8K-Preview": {
    "description": "نموذج اللغة الكبير الرائد الذي طورته بايدو، والذي شهد ترقية شاملة في القدرات مقارنةً بـERNIE 3.5، ويستخدم على نطاق واسع في مجالات متعددة لمهام معقدة؛ يدعم الاتصال التلقائي بإضافات بحث بايدو لضمان تحديث معلومات الإجابة."
  },
  "ERNIE-4.0-Turbo-128K": {
    "description": "نموذج اللغة الكبير الرائد من بايدو، يظهر أداءً ممتازًا في مجموعة واسعة من المهام المعقدة في مختلف المجالات؛ يدعم الاتصال التلقائي بمكونات بحث بايدو، مما يضمن تحديث معلومات الأسئلة والأجوبة. مقارنةً بـ ERNIE 4.0، يظهر أداءً أفضل."
  },
  "ERNIE-4.0-Turbo-8K-Latest": {
    "description": "نموذج اللغة الكبير الرائد الذي طورته بايدو، والذي يظهر أداءً ممتازًا في مجالات متعددة، مما يجعله مناسبًا لمجموعة واسعة من المهام المعقدة؛ يدعم الاتصال التلقائي بمكونات البحث من بايدو، مما يضمن تحديث معلومات الأسئلة والأجوبة. مقارنة بـ ERNIE 4.0، يظهر أداءً أفضل."
  },
  "ERNIE-4.0-Turbo-8K-Preview": {
    "description": "نموذج اللغة الكبير الرائد الذي طورته بايدو، يتميز بأداء شامل ممتاز، ويستخدم على نطاق واسع في مجالات متعددة لمهام معقدة؛ يدعم الاتصال التلقائي بإضافات بحث بايدو لضمان تحديث معلومات الإجابة. مقارنةً بـERNIE 4.0، يتمتع بأداء أفضل."
  },
  "ERNIE-Character-8K": {
    "description": "نموذج اللغة الكبير الذي طورته بايدو، مناسب لمشاهد الألعاب، والحوار مع خدمة العملاء، وأدوار الحوار، وغيرها من تطبيقات السيناريوهات، حيث يتميز بأسلوب شخصيات واضح ومتسق، وقدرة قوية على اتباع التعليمات، وأداء استدلال أفضل."
  },
  "ERNIE-Lite-Pro-128K": {
    "description": "نموذج اللغة الخفيف الذي طورته بايدو، يجمع بين أداء النموذج الممتاز وأداء الاستدلال، ويتميز بأداء أفضل من ERNIE Lite، مناسب للاستخدام في بطاقات تسريع الذكاء الاصطناعي ذات القدرة الحاسوبية المنخفضة."
  },
  "ERNIE-Speed-128K": {
    "description": "نموذج اللغة الكبير عالي الأداء الذي طورته بايدو، والذي تم إصداره في عام 2024، يتمتع بقدرات عامة ممتازة، مناسب كنموذج أساسي للتعديل الدقيق، مما يساعد على معالجة مشكلات السيناريوهات المحددة بشكل أفضل، مع أداء استدلال ممتاز."
  },
  "ERNIE-Speed-Pro-128K": {
    "description": "نموذج اللغة الكبير عالي الأداء الذي طورته بايدو، والذي تم إصداره في عام 2024، يتمتع بقدرات عامة ممتازة، ويتميز بأداء أفضل من ERNIE Speed، مناسب كنموذج أساسي للتعديل الدقيق، مما يساعد على معالجة مشكلات السيناريوهات المحددة بشكل أفضل، مع أداء استدلال ممتاز."
  },
  "Gryphe/MythoMax-L2-13b": {
    "description": "MythoMax-L2 (13B) هو نموذج مبتكر، مناسب لتطبيقات متعددة المجالات والمهام المعقدة."
  },
  "InternVL2-8B": {
    "description": "InternVL2-8B هو نموذج قوي للغة البصرية، يدعم المعالجة متعددة الوسائط للصورة والنص، قادر على التعرف بدقة على محتوى الصورة وتوليد أوصاف أو إجابات ذات صلة."
  },
  "InternVL2.5-26B": {
    "description": "InternVL2.5-26B هو نموذج قوي للغة البصرية، يدعم المعالجة متعددة الوسائط للصورة والنص، قادر على التعرف بدقة على محتوى الصورة وتوليد أوصاف أو إجابات ذات صلة."
  },
  "LoRA/Qwen/Qwen2.5-72B-Instruct": {
    "description": "Qwen2.5-72B-Instruct هو أحد أحدث نماذج اللغة الكبيرة التي أصدرتها Alibaba Cloud. يتمتع هذا النموذج بقدرات محسنة بشكل ملحوظ في مجالات الترميز والرياضيات. كما يوفر دعمًا للغات متعددة، تغطي أكثر من 29 لغة، بما في ذلك الصينية والإنجليزية. أظهر النموذج تحسينات ملحوظة في اتباع التعليمات، وفهم البيانات الهيكلية، وتوليد المخرجات الهيكلية (خاصة JSON)."
  },
  "LoRA/Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-Instruct هو أحد أحدث نماذج اللغة الكبيرة التي أصدرتها Alibaba Cloud. يتمتع هذا النموذج بقدرات محسنة بشكل ملحوظ في مجالات الترميز والرياضيات. كما يوفر دعمًا للغات متعددة، تغطي أكثر من 29 لغة، بما في ذلك الصينية والإنجليزية. أظهر النموذج تحسينات ملحوظة في اتباع التعليمات، وفهم البيانات الهيكلية، وتوليد المخرجات الهيكلية (خاصة JSON)."
  },
  "Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Hermes 2 Mixtral 8x7B DPO هو دمج متعدد النماذج مرن للغاية، يهدف إلى تقديم تجربة إبداعية ممتازة."
  },
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) هو نموذج تعليمات عالي الدقة، مناسب للحسابات المعقدة."
  },
  "OpenGVLab/InternVL2-26B": {
    "description": "أظهر InternVL2 أداءً رائعًا في مجموعة متنوعة من مهام اللغة البصرية، بما في ذلك فهم الوثائق والرسوم البيانية، وفهم النصوص في المشاهد، وOCR، وحل المشكلات العلمية والرياضية."
  },
  "OpenGVLab/InternVL2-Llama3-76B": {
    "description": "أظهر InternVL2 أداءً رائعًا في مجموعة متنوعة من مهام اللغة البصرية، بما في ذلك فهم الوثائق والرسوم البيانية، وفهم النصوص في المشاهد، وOCR، وحل المشكلات العلمية والرياضية."
  },
  "Phi-3-medium-128k-instruct": {
    "description": "نموذج Phi-3-medium نفسه، ولكن مع حجم سياق أكبر لـ RAG أو التوجيه القليل."
  },
  "Phi-3-medium-4k-instruct": {
    "description": "نموذج بحجم 14B، يثبت جودة أفضل من Phi-3-mini، مع التركيز على البيانات الكثيفة في التفكير عالية الجودة."
  },
  "Phi-3-mini-128k-instruct": {
    "description": "نموذج Phi-3-mini نفسه، ولكن مع حجم سياق أكبر لـ RAG أو التوجيه القليل."
  },
  "Phi-3-mini-4k-instruct": {
    "description": "أصغر عضو في عائلة Phi-3. مُحسّن لكل من الجودة وزمن الاستجابة المنخفض."
  },
  "Phi-3-small-128k-instruct": {
    "description": "نموذج Phi-3-small نفسه، ولكن مع حجم سياق أكبر لـ RAG أو التوجيه القليل."
  },
  "Phi-3-small-8k-instruct": {
    "description": "نموذج بحجم 7B، يثبت جودة أفضل من Phi-3-mini، مع التركيز على البيانات الكثيفة في التفكير عالية الجودة."
  },
  "Phi-3.5-mini-instruct": {
    "description": "النسخة المحدثة من نموذج Phi-3-mini."
  },
  "Phi-3.5-vision-instrust": {
    "description": "النسخة المحدثة من نموذج Phi-3-vision."
  },
  "Pro/OpenGVLab/InternVL2-8B": {
    "description": "أظهر InternVL2 أداءً رائعًا في مجموعة متنوعة من مهام اللغة البصرية، بما في ذلك فهم الوثائق والرسوم البيانية، وفهم النصوص في المشاهد، وOCR، وحل المشكلات العلمية والرياضية."
  },
  "Pro/Qwen/Qwen2-1.5B-Instruct": {
    "description": "Qwen2-1.5B-Instruct هو نموذج لغوي كبير تم تعديله وفقًا للتعليمات في سلسلة Qwen2، بحجم 1.5B. يعتمد هذا النموذج على بنية Transformer، ويستخدم تقنيات مثل دالة تنشيط SwiGLU، وتحويل QKV، والانتباه الجماعي. أظهر أداءً ممتازًا في فهم اللغة، والتوليد، والقدرات متعددة اللغات، والترميز، والرياضيات، والاستدلال في العديد من اختبارات المعايير، متجاوزًا معظم النماذج مفتوحة المصدر."
  },
  "Pro/Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-7B-Instruct هو نموذج لغوي كبير تم تعديله وفقًا للتعليمات في سلسلة Qwen2، بحجم 7B. يعتمد هذا النموذج على بنية Transformer، ويستخدم تقنيات مثل دالة تنشيط SwiGLU، وتحويل QKV، والانتباه الجماعي. يمكنه معالجة المدخلات الكبيرة. أظهر النموذج أداءً ممتازًا في فهم اللغة، والتوليد، والقدرات متعددة اللغات، والترميز، والرياضيات، والاستدلال في العديد من اختبارات المعايير، متجاوزًا معظم النماذج مفتوحة المصدر."
  },
  "Pro/Qwen/Qwen2-VL-7B-Instruct": {
    "description": "Qwen2-VL هو النسخة الأحدث من نموذج Qwen-VL، وقد حقق أداءً متقدمًا في اختبارات الفهم البصري."
  },
  "Pro/Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-Instruct هو أحد أحدث نماذج اللغة الكبيرة التي أصدرتها Alibaba Cloud. يتمتع هذا النموذج بقدرات محسنة بشكل ملحوظ في مجالات الترميز والرياضيات. كما يوفر دعمًا للغات متعددة، تغطي أكثر من 29 لغة، بما في ذلك الصينية والإنجليزية. أظهر النموذج تحسينات ملحوظة في اتباع التعليمات، وفهم البيانات الهيكلية، وتوليد المخرجات الهيكلية (خاصة JSON)."
  },
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder-7B-Instruct هو أحدث إصدار من سلسلة نماذج اللغة الكبيرة المحددة للشيفرة التي أصدرتها Alibaba Cloud. تم تحسين هذا النموذج بشكل كبير في توليد الشيفرة، والاستدلال، وإصلاح الأخطاء، من خلال تدريب على 55 تريليون توكن."
  },
  "Pro/THUDM/glm-4-9b-chat": {
    "description": "GLM-4-9B-Chat هو الإصدار مفتوح المصدر من نموذج GLM-4 الذي أطلقته Zhizhu AI. أظهر هذا النموذج أداءً ممتازًا في مجالات الدلالات، والرياضيات، والاستدلال، والشيفرة، والمعرفة. بالإضافة إلى دعم المحادثات متعددة الجولات، يتمتع GLM-4-9B-Chat أيضًا بميزات متقدمة مثل تصفح الويب، وتنفيذ الشيفرة، واستدعاء الأدوات المخصصة (Function Call)، والاستدلال على النصوص الطويلة. يدعم النموذج 26 لغة، بما في ذلك الصينية، والإنجليزية، واليابانية، والكورية، والألمانية. أظهر GLM-4-9B-Chat أداءً ممتازًا في العديد من اختبارات المعايير مثل AlignBench-v2 وMT-Bench وMMLU وC-Eval. يدعم النموذج طول سياق يصل إلى 128K، مما يجعله مناسبًا للأبحاث الأكاديمية والتطبيقات التجارية."
  },
  "Pro/google/gemma-2-9b-it": {
    "description": "Gemma هو أحد نماذج Google المتقدمة والخفيفة الوزن من سلسلة النماذج المفتوحة. إنه نموذج لغوي كبير يعتمد على فك الشيفرة فقط، يدعم اللغة الإنجليزية، ويقدم أوزان مفتوحة، ومتغيرات مدربة مسبقًا، ومتغيرات معدلة وفقًا للتعليمات. نموذج Gemma مناسب لمجموعة متنوعة من مهام توليد النصوص، بما في ذلك الأسئلة والأجوبة، والتلخيص، والاستدلال. تم تدريب هذا النموذج 9B على 8 تريليون توكن. حجمه النسبي الصغير يجعله مناسبًا للنشر في بيئات ذات موارد محدودة، مثل أجهزة الكمبيوتر المحمولة، وأجهزة الكمبيوتر المكتبية، أو البنية التحتية السحابية الخاصة بك، مما يتيح لمزيد من الأشخاص الوصول إلى نماذج الذكاء الاصطناعي المتقدمة وتعزيز الابتكار."
  },
  "Pro/meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "description": "Meta Llama 3.1 هو جزء من عائلة نماذج اللغة الكبيرة متعددة اللغات التي طورتها Meta، بما في ذلك متغيرات مدربة مسبقًا ومعدلة وفقًا للتعليمات بحجم 8B و70B و405B. تم تحسين هذا النموذج 8B وفقًا لمشاهدات المحادثات متعددة اللغات، وأظهر أداءً ممتازًا في العديد من اختبارات المعايير الصناعية. تم تدريب النموذج باستخدام أكثر من 15 تريليون توكن من البيانات العامة، واستخدم تقنيات مثل التعديل الخاضع للإشراف والتعلم المعزز من ردود الفعل البشرية لتحسين فائدة النموذج وأمانه. يدعم Llama 3.1 توليد النصوص وتوليد الشيفرة، مع تاريخ معرفة حتى ديسمبر 2023."
  },
  "Qwen/QwQ-32B-Preview": {
    "description": "QwQ-32B-Preview هو أحدث نموذج بحث تجريبي من Qwen، يركز على تعزيز قدرات الاستدلال للذكاء الاصطناعي. من خلال استكشاف آليات معقدة مثل خلط اللغة والاستدلال التكراري، تشمل المزايا الرئيسية القدرة القوية على التحليل الاستدلالي، والقدرات الرياضية والبرمجية. في الوقت نفسه، هناك أيضًا مشكلات في تبديل اللغة، ودورات الاستدلال، واعتبارات الأمان، واختلافات في القدرات الأخرى."
  },
  "Qwen/Qwen2-1.5B-Instruct": {
    "description": "Qwen2-1.5B-Instruct هو نموذج لغوي كبير تم تعديله وفقًا للتعليمات في سلسلة Qwen2، بحجم 1.5B. يعتمد هذا النموذج على بنية Transformer، ويستخدم تقنيات مثل دالة تنشيط SwiGLU، وتحويل QKV، والانتباه الجماعي. أظهر أداءً ممتازًا في فهم اللغة، والتوليد، والقدرات متعددة اللغات، والترميز، والرياضيات، والاستدلال في العديد من اختبارات المعايير، متجاوزًا معظم النماذج مفتوحة المصدر."
  },
  "Qwen/Qwen2-72B-Instruct": {
    "description": "Qwen2 هو نموذج لغوي عام متقدم، يدعم أنواع متعددة من التعليمات."
  },
  "Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-72B-Instruct هو نموذج لغوي كبير تم تعديله وفقًا للتعليمات في سلسلة Qwen2، بحجم 72B. يعتمد هذا النموذج على بنية Transformer، ويستخدم تقنيات مثل دالة تنشيط SwiGLU، وتحويل QKV، والانتباه الجماعي. يمكنه معالجة المدخلات الكبيرة. أظهر النموذج أداءً ممتازًا في فهم اللغة، والتوليد، والقدرات متعددة اللغات، والترميز، والرياضيات، والاستدلال في العديد من اختبارات المعايير، متجاوزًا معظم النماذج مفتوحة المصدر."
  },
  "Qwen/Qwen2-VL-72B-Instruct": {
    "description": "Qwen2-VL هو النسخة الأحدث من نموذج Qwen-VL، وقد حقق أداءً متقدمًا في اختبارات الفهم البصري."
  },
  "Qwen/Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5 هو سلسلة جديدة من نماذج اللغة الكبيرة، تهدف إلى تحسين معالجة المهام الإرشادية."
  },
  "Qwen/Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5 هو سلسلة جديدة من نماذج اللغة الكبيرة، تهدف إلى تحسين معالجة المهام الإرشادية."
  },
  "Qwen/Qwen2.5-72B-Instruct": {
    "description": "نموذج لغة كبير تم تطويره بواسطة فريق علي بابا السحابي للذكاء الاصطناعي"
  },
  "Qwen/Qwen2.5-72B-Instruct-128K": {
    "description": "Qwen2.5 هي سلسلة جديدة من نماذج اللغة الكبيرة، تتمتع بقدرة أكبر على الفهم والتوليد."
  },
  "Qwen/Qwen2.5-72B-Instruct-Turbo": {
    "description": "Qwen2.5 هو سلسلة جديدة من نماذج اللغة الكبيرة، مصممة لتحسين معالجة المهام التوجيهية."
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5 هو سلسلة جديدة من نماذج اللغة الكبيرة، تهدف إلى تحسين معالجة المهام الإرشادية."
  },
  "Qwen/Qwen2.5-7B-Instruct-Turbo": {
    "description": "Qwen2.5 هو سلسلة جديدة من نماذج اللغة الكبيرة، مصممة لتحسين معالجة المهام التوجيهية."
  },
  "Qwen/Qwen2.5-Coder-32B-Instruct": {
    "description": "يركز Qwen2.5-Coder على كتابة الكود."
  },
  "Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder-7B-Instruct هو أحدث إصدار من سلسلة نماذج اللغة الكبيرة المحددة للشيفرة التي أصدرتها Alibaba Cloud. تم تحسين هذا النموذج بشكل كبير في توليد الشيفرة، والاستدلال، وإصلاح الأخطاء، من خلال تدريب على 55 تريليون توكن."
  },
  "Qwen/Qwen2.5-Math-72B-Instruct": {
    "description": "Qwen2.5-Math يركز على حل المشكلات في مجال الرياضيات، ويقدم إجابات احترافية للأسئلة الصعبة."
  },
  "Qwen2-72B-Instruct": {
    "description": "Qwen2 هو أحدث سلسلة من نموذج Qwen، ويدعم سياقًا يصل إلى 128 ألف، مقارنةً بأفضل النماذج مفتوحة المصدر الحالية، يتفوق Qwen2-72B بشكل ملحوظ في فهم اللغة الطبيعية والمعرفة والترميز والرياضيات والقدرات متعددة اللغات."
  },
  "Qwen2-7B-Instruct": {
    "description": "Qwen2 هو أحدث سلسلة من نموذج Qwen، قادر على التفوق على النماذج مفتوحة المصدر ذات الحجم المماثل أو حتى النماذج الأكبر حجمًا، حقق Qwen2 7B مزايا ملحوظة في عدة تقييمات، خاصة في فهم الترميز والصينية."
  },
  "Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5-14B-Instruct هو نموذج لغوي كبير يحتوي على 14 مليار معلمة، يتميز بأداء ممتاز، تم تحسينه لمشاهد اللغة الصينية واللغات المتعددة، ويدعم التطبيقات مثل الأسئلة الذكية وتوليد المحتوى."
  },
  "Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5-32B-Instruct هو نموذج لغوي كبير يحتوي على 32 مليار معلمة، يتميز بأداء متوازن، تم تحسينه لمشاهد اللغة الصينية واللغات المتعددة، ويدعم التطبيقات مثل الأسئلة الذكية وتوليد المحتوى."
  },
  "Qwen2.5-72B-Instruct": {
    "description": "يدعم Qwen2.5-72B-Instruct سياقًا يصل إلى 16 ألف، وينتج نصوصًا طويلة تتجاوز 8 آلاف. يدعم استدعاء الوظائف والتفاعل السلس مع الأنظمة الخارجية، مما يعزز بشكل كبير من المرونة وقابلية التوسع. لقد زادت معرفة النموذج بشكل ملحوظ، كما تحسنت قدراته في الترميز والرياضيات بشكل كبير، ويدعم أكثر من 29 لغة."
  },
  "Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-Instruct هو نموذج لغوي كبير يحتوي على 7 مليارات معلمة، يدعم الاتصال الوظيفي مع الأنظمة الخارجية بسلاسة، مما يعزز المرونة وقابلية التوسع بشكل كبير. تم تحسينه لمشاهد اللغة الصينية واللغات المتعددة، ويدعم التطبيقات مثل الأسئلة الذكية وتوليد المحتوى."
  },
  "Qwen2.5-Coder-32B-Instruct": {
    "description": "Qwen2.5-Coder-32B-Instruct هو نموذج لغوي كبير مصمم خصيصًا لتوليد الشيفرات، وفهم الشيفرات، ومشاهد التطوير الفعالة، مع استخدام حجم 32B من المعلمات الرائدة في الصناعة، مما يلبي احتياجات البرمجة المتنوعة."
  },
  "SenseChat": {
    "description": "نموذج الإصدار الأساسي (V4)، بطول سياق 4K، يمتلك قدرات قوية وعامة."
  },
  "SenseChat-128K": {
    "description": "نموذج الإصدار الأساسي (V4)، بطول سياق 128K، يتفوق في مهام فهم وتوليد النصوص الطويلة."
  },
  "SenseChat-32K": {
    "description": "نموذج الإصدار الأساسي (V4)، بطول سياق 32K، يمكن استخدامه بمرونة في مختلف السيناريوهات."
  },
  "SenseChat-5": {
    "description": "أحدث إصدار من النموذج (V5.5)، بطول سياق 128K، مع تحسينات ملحوظة في القدرة على الاستدلال الرياضي، المحادثات باللغة الإنجليزية، اتباع التعليمات وفهم النصوص الطويلة، مما يجعله في مستوى GPT-4o."
  },
  "SenseChat-5-Cantonese": {
    "description": "بطول سياق 32K، يتفوق في فهم المحادثات باللغة الكانتونية مقارنة بـ GPT-4، ويضاهي GPT-4 Turbo في مجالات المعرفة، الاستدلال، الرياضيات وكتابة الأكواد."
  },
  "SenseChat-Character": {
    "description": "نموذج النسخة القياسية، بطول سياق 8K، بسرعة استجابة عالية."
  },
  "SenseChat-Character-Pro": {
    "description": "نموذج النسخة المتقدمة، بطول سياق 32K، مع تحسين شامل في القدرات، يدعم المحادثات باللغة الصينية والإنجليزية."
  },
  "SenseChat-Turbo": {
    "description": "مناسب للأسئلة السريعة، وسيناريوهات ضبط النموذج."
  },
  "Skylark2-lite-8k": {
    "description": "نموذج سكايلارك (Skylark) من الجيل الثاني، نموذج سكايلارك2-لايت يتميز بسرعات استجابة عالية، مناسب للسيناريوهات التي تتطلب استجابة في الوقت الحقيقي، وحساسة للتكاليف، وغير متطلبة لدقة نموذج عالية، بسعة سياق تبلغ 8k."
  },
  "Skylark2-pro-32k": {
    "description": "نموذج سكايلارك (Skylark) من الجيل الثاني، النسخة سكايلارك2-برو تتميز بدقة نموذج عالية، مناسبة لمهام توليد النصوص المعقدة، مثل إنشاء نصوص في مجالات احترافية، وكتابة الروايات، والترجمة عالية الجودة، بسعة سياق تبلغ 32k."
  },
  "Skylark2-pro-4k": {
    "description": "نموذج سكايلارك (Skylark) من الجيل الثاني، النسخة سكايلارك2-برو تتميز بدقة نموذج عالية، مناسبة لمهام توليد النصوص المعقدة، مثل إنشاء نصوص في مجالات احترافية، وكتابة الروايات، والترجمة عالية الجودة، بسعة سياق تبلغ 4k."
  },
  "Skylark2-pro-character-4k": {
    "description": "نموذج سكايلارك (Skylark) من الجيل الثاني، نموذج سكايلارك2-برو-شخصية يتميز بقدرات ممتازة في لعب الأدوار والدردشة، يجيد تجسيد شخصيات مختلفة بناءً على طلب المستخدم والتفاعل بشكل طبيعي، مناسب لبناء روبوتات الدردشة، والمساعدين الافتراضيين، وخدمة العملاء عبر الإنترنت، ويتميز بسرعة استجابة عالية."
  },
  "Skylark2-pro-turbo-8k": {
    "description": "نموذج سكايلارك (Skylark) من الجيل الثاني، سكايلارك2-برو-توربو-8k يقدم استدلالًا أسرع وتكاليف أقل، بسعة سياق تبلغ 8k."
  },
  "THUDM/chatglm3-6b": {
    "description": "ChatGLM3-6B هو نموذج مفتوح المصدر من سلسلة ChatGLM، تم تطويره بواسطة Zhizhu AI. يحتفظ هذا النموذج بخصائص الجيل السابق الممتازة، مثل سلاسة المحادثة وانخفاض عتبة النشر، بينما يقدم ميزات جديدة. تم تدريبه على بيانات تدريب أكثر تنوعًا، وعدد أكبر من خطوات التدريب، واستراتيجيات تدريب أكثر منطقية، مما يجعله نموذجًا ممتازًا بين النماذج المدربة مسبقًا التي تقل عن 10B. يدعم ChatGLM3-6B المحادثات متعددة الجولات، واستدعاء الأدوات، وتنفيذ الشيفرة، ومهام الوكلاء في سيناريوهات معقدة. بالإضافة إلى نموذج المحادثة، تم إصدار النموذج الأساسي ChatGLM-6B-Base ونموذج المحادثة الطويلة ChatGLM3-6B-32K. النموذج مفتوح بالكامل للأبحاث الأكاديمية، ويسمح بالاستخدام التجاري المجاني بعد التسجيل."
  },
  "THUDM/glm-4-9b-chat": {
    "description": "GLM-4 9B هو إصدار مفتوح المصدر، يوفر تجربة حوار محسنة لتطبيقات الحوار."
  },
  "TeleAI/TeleChat2": {
    "description": "نموذج TeleChat2 هو نموذج كبير تم تطويره ذاتيًا من قبل China Telecom، يدعم وظائف مثل الأسئلة والأجوبة الموسوعية، وتوليد الشيفرة، وتوليد النصوص الطويلة، ويقدم خدمات استشارية للمستخدمين، مما يمكنه من التفاعل مع المستخدمين، والإجابة على الأسئلة، والمساعدة في الإبداع، وتوفير المعلومات والمعرفة والإلهام بكفاءة وسهولة. أظهر النموذج أداءً ممتازًا في معالجة مشكلات الهلوسة، وتوليد النصوص الطويلة، وفهم المنطق."
  },
  "TeleAI/TeleMM": {
    "description": "نموذج TeleMM هو نموذج كبير لفهم متعدد الوسائط تم تطويره ذاتيًا من قبل China Telecom، يمكنه معالجة مدخلات متعددة الوسائط مثل النصوص والصور، ويدعم وظائف مثل فهم الصور، وتحليل الرسوم البيانية، مما يوفر خدمات فهم متعددة الوسائط للمستخدمين. يمكن للنموذج التفاعل مع المستخدمين بطرق متعددة الوسائط، وفهم المحتوى المدخل بدقة، والإجابة على الأسئلة، والمساعدة في الإبداع، وتوفير معلومات متعددة الوسائط ودعم الإلهام بكفاءة. أظهر أداءً ممتازًا في المهام متعددة الوسائط مثل الإدراك الدقيق، والاستدلال المنطقي."
  },
  "Tencent/Hunyuan-A52B-Instruct": {
    "description": "Hunyuan-Large هو أكبر نموذج MoE مفتوح المصدر في الصناعة، مع 389 مليار إجمالي عدد المعلمات و52 مليار عدد المعلمات النشطة."
  },
  "Vendor-A/Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-72B-Instruct هو نموذج لغوي كبير تم تعديله وفقًا للتعليمات في سلسلة Qwen2، بحجم 72B. يعتمد هذا النموذج على بنية Transformer، ويستخدم تقنيات مثل دالة تنشيط SwiGLU، وتحويل QKV، والانتباه الجماعي. يمكنه معالجة المدخلات الكبيرة. أظهر النموذج أداءً ممتازًا في فهم اللغة، والتوليد، والقدرات متعددة اللغات، والترميز، والرياضيات، والاستدلال في العديد من اختبارات المعايير، متجاوزًا معظم النماذج مفتوحة المصدر."
  },
  "Vendor-A/Qwen/Qwen2.5-72B-Instruct": {
    "description": "Qwen2.5-72B-Instruct هو أحد أحدث نماذج اللغة الكبيرة التي أصدرتها Alibaba Cloud. يتمتع هذا النموذج بقدرات محسنة بشكل ملحوظ في مجالات الترميز والرياضيات. كما يوفر دعمًا للغات متعددة، تغطي أكثر من 29 لغة، بما في ذلك الصينية والإنجليزية. أظهر النموذج تحسينات ملحوظة في اتباع التعليمات، وفهم البيانات الهيكلية، وتوليد المخرجات الهيكلية (خاصة JSON)."
  },
  "Yi-34B-Chat": {
    "description": "Yi-1.5-34B، مع الحفاظ على القدرات اللغوية العامة الممتازة للنموذج الأصلي، تم تدريبه بشكل إضافي على 500 مليار توكن عالي الجودة، مما أدى إلى تحسين كبير في المنطق الرياضي وقدرات الترميز."
  },
  "abab5.5-chat": {
    "description": "موجه لمشاهد الإنتاجية، يدعم معالجة المهام المعقدة وتوليد النصوص بكفاءة، مناسب للتطبيقات في المجالات المهنية."
  },
  "abab5.5s-chat": {
    "description": "مصمم لمشاهد الحوار باللغة الصينية، يوفر قدرة توليد حوار عالي الجودة باللغة الصينية، مناسب لمجموعة متنوعة من التطبيقات."
  },
  "abab6.5g-chat": {
    "description": "مصمم للحوار متعدد اللغات، يدعم توليد حوارات عالية الجودة بالإنجليزية والعديد من اللغات الأخرى."
  },
  "abab6.5s-chat": {
    "description": "مناسب لمجموعة واسعة من مهام معالجة اللغة الطبيعية، بما في ذلك توليد النصوص، وأنظمة الحوار، وغيرها."
  },
  "abab6.5t-chat": {
    "description": "محسن لمشاهد الحوار باللغة الصينية، يوفر قدرة توليد حوار سلس ومتوافق مع عادات التعبير الصينية."
  },
  "accounts/fireworks/models/firefunction-v1": {
    "description": "نموذج استدعاء الدوال مفتوح المصدر من Fireworks، يوفر قدرة تنفيذ تعليمات ممتازة وخصائص قابلة للتخصيص."
  },
  "accounts/fireworks/models/firefunction-v2": {
    "description": "Firefunction-v2 من شركة Fireworks هو نموذج استدعاء دوال عالي الأداء، تم تطويره بناءً على Llama-3، وتم تحسينه بشكل كبير، مناسب بشكل خاص لاستدعاء الدوال، والحوار، واتباع التعليمات."
  },
  "accounts/fireworks/models/firellava-13b": {
    "description": "fireworks-ai/FireLLaVA-13b هو نموذج لغوي بصري، يمكنه استقبال المدخلات من الصور والنصوص، تم تدريبه على بيانات عالية الجودة، مناسب للمهام متعددة الوسائط."
  },
  "accounts/fireworks/models/llama-v3-70b-instruct": {
    "description": "نموذج Llama 3 70B للتعليمات، مصمم للحوار متعدد اللغات وفهم اللغة الطبيعية، أداءه يتفوق على معظم النماذج المنافسة."
  },
  "accounts/fireworks/models/llama-v3-70b-instruct-hf": {
    "description": "نموذج Llama 3 70B للتعليمات (نسخة HF)، يتوافق مع نتائج التنفيذ الرسمية، مناسب لمهام اتباع التعليمات عالية الجودة."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct": {
    "description": "نموذج Llama 3 8B للتعليمات، تم تحسينه للحوار والمهام متعددة اللغات، يظهر أداءً ممتازًا وفعالًا."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct-hf": {
    "description": "نموذج Llama 3 8B للتعليمات (نسخة HF)، يتوافق مع نتائج التنفيذ الرسمية، يتمتع بتوافق عالٍ عبر المنصات."
  },
  "accounts/fireworks/models/llama-v3p1-405b-instruct": {
    "description": "نموذج Llama 3.1 405B للتعليمات، يتمتع بمعلمات ضخمة، مناسب لمهام معقدة واتباع التعليمات في سيناريوهات ذات حمل عالي."
  },
  "accounts/fireworks/models/llama-v3p1-70b-instruct": {
    "description": "نموذج Llama 3.1 70B للتعليمات، يوفر قدرة ممتازة على فهم اللغة الطبيعية وتوليدها، وهو الخيار المثالي لمهام الحوار والتحليل."
  },
  "accounts/fireworks/models/llama-v3p1-8b-instruct": {
    "description": "نموذج Llama 3.1 8B للتعليمات، تم تحسينه للحوار متعدد اللغات، قادر على تجاوز معظم النماذج المفتوحة والمغلقة في المعايير الصناعية الشائعة."
  },
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
    "description": "نموذج استدلال الصور المعدل من Meta ذو 11B معلمات. تم تحسين هذا النموذج للتعرف البصري، واستدلال الصور، ووصف الصور، والإجابة عن الأسئلة العامة المتعلقة بالصور. يستطيع النموذج فهم البيانات البصرية مثل الرسوم البيانية والرسوم، ويسد الفجوة بين الرؤية واللغة من خلال توليد أوصاف نصية لجزئيات الصور."
  },
  "accounts/fireworks/models/llama-v3p2-1b-instruct": {
    "description": "نموذج التوجيه Llama 3.2 1B هو نموذج متعدد اللغات خفيف الوزن قدمته Meta. يهدف هذا النموذج إلى زيادة الكفاءة، مع تحسينات ملحوظة في التأخير والتكلفة مقارنة بالنماذج الأكبر. تشمل حالات الاستخدام النموذجية لهذا النموذج الاسترجاع والتلخيص."
  },
  "accounts/fireworks/models/llama-v3p2-3b-instruct": {
    "description": "نموذج التوجيه Llama 3.2 3B هو نموذج متعدد اللغات خفيف الوزن قدمته Meta. يهدف هذا النموذج إلى زيادة الكفاءة، مع تحسينات ملحوظة في التأخير والتكلفة مقارنة بالنماذج الأكبر. تشمل حالات الاستخدام النموذجية لهذا النموذج الاستفسارات وإعادة كتابة الملاحظات والمساعدة في الكتابة."
  },
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
    "description": "نموذج استدلال الصور المعدل من Meta ذو 90B معلمات. تم تحسين هذا النموذج للتعرف البصري، واستدلال الصور، ووصف الصور، والإجابة عن الأسئلة العامة المتعلقة بالصور. يستطيع النموذج فهم البيانات البصرية مثل الرسوم البيانية والرسوم، ويسد الفجوة بين الرؤية واللغة من خلال توليد أوصاف نصية لجزئيات الصور."
  },
  "accounts/fireworks/models/mixtral-8x22b-instruct": {
    "description": "نموذج Mixtral MoE 8x22B للتعليمات، مع معلمات ضخمة وهيكل خبير متعدد، يدعم معالجة فعالة لمهام معقدة."
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct": {
    "description": "نموذج Mixtral MoE 8x7B للتعليمات، يوفر هيكل خبير متعدد لتقديم تعليمات فعالة واتباعها."
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
    "description": "نموذج Mixtral MoE 8x7B للتعليمات (نسخة HF)، الأداء يتوافق مع التنفيذ الرسمي، مناسب لمجموعة متنوعة من سيناريوهات المهام الفعالة."
  },
  "accounts/fireworks/models/mythomax-l2-13b": {
    "description": "نموذج MythoMax L2 13B، يجمع بين تقنيات الدمج الجديدة، بارع في السرد وأدوار الشخصيات."
  },
  "accounts/fireworks/models/phi-3-vision-128k-instruct": {
    "description": "نموذج Phi 3 Vision للتعليمات، نموذج متعدد الوسائط خفيف الوزن، قادر على معالجة معلومات بصرية ونصية معقدة، يتمتع بقدرة استدلال قوية."
  },
  "accounts/fireworks/models/qwen-qwq-32b-preview": {
    "description": "نموذج QwQ هو نموذج بحث تجريبي تم تطويره بواسطة فريق Qwen، يركز على تعزيز قدرات الاستدلال للذكاء الاصطناعي."
  },
  "accounts/fireworks/models/qwen2p5-72b-instruct": {
    "description": "Qwen2.5 هي سلسلة من نماذج اللغة التي طورتها مجموعة Qwen من علي بابا، تحتوي فقط على شريحة فك شفرات. توفر هذه النماذج أحجامًا مختلفة، بما في ذلك 0.5B، 1.5B، 3B، 7B، 14B، 32B و72B، وتأتي بنسخ أساسية (base) ونماذج توجيهية (instruct)."
  },
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
    "description": "Qwen2.5 Coder 32B Instruct هو أحدث إصدار من سلسلة نماذج اللغة الكبيرة المحددة للشيفرة التي أصدرتها Alibaba Cloud. تم تحسين هذا النموذج بشكل كبير في توليد الشيفرة، والاستدلال، وإصلاح الأخطاء، من خلال تدريب على 55 تريليون توكن."
  },
  "accounts/fireworks/models/starcoder-16b": {
    "description": "نموذج StarCoder 15.5B، يدعم مهام البرمجة المتقدمة، مع تعزيز القدرة على التعامل مع لغات متعددة، مناسب لتوليد وفهم الشيفرات المعقدة."
  },
  "accounts/fireworks/models/starcoder-7b": {
    "description": "نموذج StarCoder 7B، تم تدريبه على أكثر من 80 لغة برمجة، يتمتع بقدرة ممتازة على ملء البرمجة وفهم السياق."
  },
  "accounts/yi-01-ai/models/yi-large": {
    "description": "نموذج Yi-Large، يتمتع بقدرة معالجة لغوية ممتازة، يمكن استخدامه في جميع أنواع مهام توليد وفهم اللغة."
  },
  "ai21-jamba-1.5-large": {
    "description": "نموذج متعدد اللغات بحجم 398B (94B نشط)، يقدم نافذة سياق طويلة بحجم 256K، واستدعاء وظائف، وإخراج منظم، وتوليد مستند."
  },
  "ai21-jamba-1.5-mini": {
    "description": "نموذج متعدد اللغات بحجم 52B (12B نشط)، يقدم نافذة سياق طويلة بحجم 256K، واستدعاء وظائف، وإخراج منظم، وتوليد مستند."
  },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "description": "Claude 3.5 Sonnet يرفع المعايير في الصناعة، حيث يتفوق على نماذج المنافسين وClaude 3 Opus، ويظهر أداءً ممتازًا في تقييمات واسعة، مع سرعة وتكلفة تتناسب مع نماذجنا المتوسطة."
  },
  "anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "لقد رفع كلود 3.5 سونيت معايير الصناعة، حيث تفوق أداؤه على نماذج المنافسين ونموذج كلود 3 أوبس، وأظهر أداءً ممتازًا في تقييمات واسعة، مع الحفاظ على سرعة وتكلفة نماذجنا المتوسطة."
  },
  "anthropic.claude-3-haiku-20240307-v1:0": {
    "description": "Claude 3 Haiku هو أسرع وأصغر نموذج من Anthropic، يوفر سرعة استجابة شبه فورية. يمكنه بسرعة الإجابة على الاستفسارات والطلبات البسيطة. سيتمكن العملاء من بناء تجربة ذكاء اصطناعي سلسة تحاكي التفاعل البشري. يمكن لـ Claude 3 Haiku معالجة الصور وإرجاع إخراج نصي، مع نافذة سياقية تبلغ 200K."
  },
  "anthropic.claude-3-opus-20240229-v1:0": {
    "description": "Claude 3 Opus هو أقوى نموذج ذكاء اصطناعي من Anthropic، يتمتع بأداء متقدم في المهام المعقدة للغاية. يمكنه معالجة المطالبات المفتوحة والمشاهد غير المعروفة، مع سلاسة وفهم يشبه البشر. يعرض Claude 3 Opus حدود إمكانيات الذكاء الاصطناعي التوليدي. يمكن لـ Claude 3 Opus معالجة الصور وإرجاع إخراج نصي، مع نافذة سياقية تبلغ 200K."
  },
  "anthropic.claude-3-sonnet-20240229-v1:0": {
    "description": "Claude 3 Sonnet من Anthropic يحقق توازنًا مثاليًا بين الذكاء والسرعة - مناسب بشكل خاص لأعباء العمل المؤسسية. يقدم أكبر فائدة بأقل من تكلفة المنافسين، وقد تم تصميمه ليكون نموذجًا موثوقًا وعالي التحمل، مناسبًا لنشر الذكاء الاصطناعي على نطاق واسع. يمكن لـ Claude 3 Sonnet معالجة الصور وإرجاع إخراج نصي، مع نافذة سياقية تبلغ 200K."
  },
  "anthropic.claude-instant-v1": {
    "description": "نموذج سريع واقتصادي وما زال قويًا للغاية، يمكنه معالجة مجموعة من المهام بما في ذلك المحادثات اليومية، وتحليل النصوص، والتلخيص، والأسئلة والأجوبة على الوثائق."
  },
  "anthropic.claude-v2": {
    "description": "نموذج يظهر قدرة عالية في مجموعة واسعة من المهام، من المحادثات المعقدة وتوليد المحتوى الإبداعي إلى اتباع التعليمات التفصيلية."
  },
  "anthropic.claude-v2:1": {
    "description": "الإصدار المحدث من Claude 2، مع نافذة سياقية مضاعفة، وتحسينات في الاعتمادية ومعدل الهلوسة والدقة المستندة إلى الأدلة في الوثائق الطويلة وسياقات RAG."
  },
  "anthropic/claude-3-haiku": {
    "description": "Claude 3 Haiku هو أسرع وأصغر نموذج من Anthropic، مصمم لتحقيق استجابة شبه فورية. يتمتع بأداء توجيهي سريع ودقيق."
  },
  "anthropic/claude-3-opus": {
    "description": "Claude 3 Opus هو أقوى نموذج من Anthropic لمعالجة المهام المعقدة للغاية. يتميز بأداء ممتاز وذكاء وسلاسة وفهم."
  },
  "anthropic/claude-3.5-sonnet": {
    "description": "Claude 3.5 Sonnet يقدم قدرات تتجاوز Opus وسرعة أكبر من Sonnet، مع الحفاظ على نفس السعر. يتميز Sonnet بمهارات خاصة في البرمجة وعلوم البيانات ومعالجة الصور والمهام الوكيلة."
  },
  "aya": {
    "description": "Aya 23 هو نموذج متعدد اللغات أطلقته Cohere، يدعم 23 لغة، مما يسهل التطبيقات اللغوية المتنوعة."
  },
  "aya:35b": {
    "description": "Aya 23 هو نموذج متعدد اللغات أطلقته Cohere، يدعم 23 لغة، مما يسهل التطبيقات اللغوية المتنوعة."
  },
  "charglm-3": {
    "description": "CharGLM-3 مصمم خصيصًا للأدوار التفاعلية والمرافقة العاطفية، يدعم ذاكرة متعددة الجولات طويلة الأمد وحوارات مخصصة، ويستخدم على نطاق واسع."
  },
  "chatgpt-4o-latest": {
    "description": "ChatGPT-4o هو نموذج ديناميكي يتم تحديثه في الوقت الحقيقي للحفاظ على أحدث إصدار. يجمع بين فهم اللغة القوي وقدرات التوليد، مما يجعله مناسبًا لمجموعة واسعة من التطبيقات، بما في ذلك خدمة العملاء والتعليم والدعم الفني."
  },
  "claude-2.0": {
    "description": "Claude 2 يوفر تقدمًا في القدرات الأساسية للمؤسسات، بما في ذلك سياق يصل إلى 200K توكن، وتقليل كبير في معدل حدوث الهلوسة في النموذج، وإشعارات النظام، وميزة اختبار جديدة: استدعاء الأدوات."
  },
  "claude-2.1": {
    "description": "Claude 2 يوفر تقدمًا في القدرات الأساسية للمؤسسات، بما في ذلك سياق يصل إلى 200K توكن، وتقليل كبير في معدل حدوث الهلوسة في النموذج، وإشعارات النظام، وميزة اختبار جديدة: استدعاء الأدوات."
  },
  "claude-3-5-haiku-20241022": {
    "description": "Claude 3.5 Haiku هو أسرع نموذج من الجيل التالي من Anthropic. مقارنةً بـ Claude 3 Haiku، فإن Claude 3.5 Haiku قد حقق تحسينات في جميع المهارات، وتفوق في العديد من اختبارات الذكاء على أكبر نموذج من الجيل السابق، Claude 3 Opus."
  },
  "claude-3-5-sonnet-20240620": {
    "description": "Claude 3.5 Sonnet يوفر قدرات تتجاوز Opus وسرعة أكبر من Sonnet، مع الحفاظ على نفس السعر. Sonnet بارع بشكل خاص في البرمجة، وعلوم البيانات، ومعالجة الصور، ومهام الوكالة."
  },
  "claude-3-5-sonnet-20241022": {
    "description": "يقدم كلاف 3.5 سونيت قدرات تتجاوز أوبوس وسرعة أكبر من سونيت، مع الحفاظ على نفس الأسعار. سونيت متخصصة بشكل خاص في البرمجة، علوم البيانات، معالجة الصور، والمهام الوكيلة."
  },
  "claude-3-haiku-20240307": {
    "description": "Claude 3 Haiku هو أسرع وأصغر نموذج من Anthropic، مصمم لتحقيق استجابة شبه فورية. يتمتع بأداء توجيهي سريع ودقيق."
  },
  "claude-3-opus-20240229": {
    "description": "Claude 3 Opus هو أقوى نموذج من Anthropic لمعالجة المهام المعقدة للغاية. يظهر أداءً ممتازًا في الذكاء، والسلاسة، والفهم."
  },
  "claude-3-sonnet-20240229": {
    "description": "Claude 3 Sonnet يوفر توازنًا مثاليًا بين الذكاء والسرعة لحمولات العمل المؤسسية. يقدم أقصى فائدة بسعر أقل، موثوق ومناسب للنشر على نطاق واسع."
  },
  "code-raccoon-v1": {
    "description": "كود راكون هو مساعد ذكي لتطوير البرمجيات يعتمد على نموذج اللغة الكبير من SenseTime، يغطي مراحل تحليل متطلبات البرمجيات، وتصميم الهيكل، وكتابة الشيفرات، واختبار البرمجيات، لتلبية احتياجات المستخدمين في كتابة الشيفرات، وتعلم البرمجة، وغيرها من المتطلبات. يدعم كود راكون أكثر من 90 لغة برمجة رئيسية مثل Python وJava وJavaScript وC++ وGo وSQL، بالإضافة إلى IDEs الرئيسية مثل VS Code وIntelliJ IDEA. في التطبيقات العملية، يمكن أن يساعد كود راكون المطورين في زيادة كفاءة البرمجة بأكثر من 50%."
  },
  "codegeex-4": {
    "description": "CodeGeeX-4 هو مساعد برمجي قوي، يدعم مجموعة متنوعة من لغات البرمجة في الإجابة الذكية وإكمال الشيفرة، مما يعزز من كفاءة التطوير."
  },
  "codegeex4-all-9b": {
    "description": "CodeGeeX4-ALL-9B هو نموذج توليد كود متعدد اللغات، يدعم مجموعة شاملة من الوظائف بما في ذلك إكمال الشيفرات والتوليد، ومفسر الشيفرات، والبحث عبر الإنترنت، واستدعاء الوظائف، وأسئلة وأجوبة على مستوى المستودع، مما يغطي جميع سيناريوهات تطوير البرمجيات. إنه أحد أفضل نماذج توليد الشيفرات بأقل من 10 مليار معلمة."
  },
  "codegemma": {
    "description": "CodeGemma هو نموذج لغوي خفيف الوزن مخصص لمهام البرمجة المختلفة، يدعم التكرار السريع والتكامل."
  },
  "codegemma:2b": {
    "description": "CodeGemma هو نموذج لغوي خفيف الوزن مخصص لمهام البرمجة المختلفة، يدعم التكرار السريع والتكامل."
  },
  "codellama": {
    "description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة والنقاش، يجمع بين دعم مجموعة واسعة من لغات البرمجة، مناسب لبيئات المطورين."
  },
  "codellama/CodeLlama-34b-Instruct-hf": {
    "description": "Code Llama هو نموذج LLM يركز على توليد ومناقشة الشيفرة، يجمع بين دعم واسع للغات البرمجة، مناسب لبيئات المطورين."
  },
  "codellama:13b": {
    "description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة والنقاش، يجمع بين دعم مجموعة واسعة من لغات البرمجة، مناسب لبيئات المطورين."
  },
  "codellama:34b": {
    "description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة والنقاش، يجمع بين دعم مجموعة واسعة من لغات البرمجة، مناسب لبيئات المطورين."
  },
  "codellama:70b": {
    "description": "Code Llama هو نموذج لغوي كبير يركز على توليد الشيفرة والنقاش، يجمع بين دعم مجموعة واسعة من لغات البرمجة، مناسب لبيئات المطورين."
  },
  "codeqwen": {
    "description": "CodeQwen1.5 هو نموذج لغوي كبير تم تدريبه على مجموعة كبيرة من بيانات الشيفرة، مصمم لحل مهام البرمجة المعقدة."
  },
  "codestral": {
    "description": "Codestral هو أول نموذج شيفرة من Mistral AI، يوفر دعمًا ممتازًا لمهام توليد الشيفرة."
  },
  "codestral-latest": {
    "description": "Codestral هو نموذج توليد متقدم يركز على توليد الشيفرة، تم تحسينه لمهام الملء الوسيط وإكمال الشيفرة."
  },
  "cognitivecomputations/dolphin-mixtral-8x22b": {
    "description": "Dolphin Mixtral 8x22B هو نموذج مصمم للامتثال للتعليمات، والحوار، والبرمجة."
  },
  "cohere-command-r": {
    "description": "نموذج توليدي قابل للتوسع يستهدف RAG واستخدام الأدوات لتمكين الذكاء الاصطناعي على نطاق الإنتاج للمؤسسات."
  },
  "cohere-command-r-plus": {
    "description": "نموذج RAG محسّن من الطراز الأول مصمم للتعامل مع أحمال العمل على مستوى المؤسسات."
  },
  "command-r": {
    "description": "Command R هو نموذج LLM محسن لمهام الحوار والسياقات الطويلة، مناسب بشكل خاص للتفاعل الديناميكي وإدارة المعرفة."
  },
  "command-r-plus": {
    "description": "Command R+ هو نموذج لغوي كبير عالي الأداء، مصمم لمشاهد الأعمال الحقيقية والتطبيقات المعقدة."
  },
  "databricks/dbrx-instruct": {
    "description": "DBRX Instruct يوفر قدرة معالجة تعليمات موثوقة، يدعم تطبيقات متعددة الصناعات."
  },
  "deepseek-ai/DeepSeek-V2-Chat": {
    "description": "DeepSeek-V2 هو نموذج لغوي قوي وفعال من حيث التكلفة يعتمد على الخبراء المختلطين (MoE). تم تدريبه مسبقًا على مجموعة بيانات عالية الجودة تحتوي على 8.1 تريليون توكن، وتم تحسين قدراته من خلال التعديل الخاضع للإشراف (SFT) والتعلم المعزز (RL). مقارنةً بـ DeepSeek 67B، يوفر DeepSeek-V2 أداءً أقوى مع توفير 42.5% من تكاليف التدريب، وتقليل 93.3% من ذاكرة التخزين المؤقت KV، وزيادة الحد الأقصى لمعدل الإنتاج إلى 5.76 مرة. يدعم النموذج طول سياق يصل إلى 128k، ويظهر أداءً ممتازًا في اختبارات المعايير القياسية وتقييمات التوليد المفتوحة."
  },
  "deepseek-ai/DeepSeek-V2.5": {
    "description": "DeepSeek V2.5 يجمع بين الميزات الممتازة للإصدارات السابقة، ويعزز القدرات العامة والترميز."
  },
  "deepseek-ai/deepseek-llm-67b-chat": {
    "description": "DeepSeek 67B هو نموذج متقدم تم تدريبه للحوار المعقد."
  },
  "deepseek-chat": {
    "description": "نموذج مفتوح المصدر الجديد الذي يجمع بين القدرات العامة وقدرات البرمجة، لا يحتفظ فقط بالقدرات الحوارية العامة لنموذج الدردشة الأصلي وقدرات معالجة الشيفرة القوية لنموذج Coder، بل يتماشى أيضًا بشكل أفضل مع تفضيلات البشر. بالإضافة إلى ذلك، حقق DeepSeek-V2.5 تحسينات كبيرة في مهام الكتابة، واتباع التعليمات، وغيرها من المجالات."
  },
  "deepseek-coder-33B-instruct": {
    "description": "DeepSeek Coder 33B هو نموذج لغة برمجية، تم تدريبه على 20 تريليون بيانات، منها 87% كود و13% لغات صينية وإنجليزية. يقدم النموذج حجم نافذة 16K ومهام ملء الفراغ، مما يوفر إكمال الشيفرات على مستوى المشروع ووظائف ملء المقاطع."
  },
  "deepseek-coder-v2": {
    "description": "DeepSeek Coder V2 هو نموذج شيفرة مفتوح المصدر من نوع خبير مختلط، يقدم أداءً ممتازًا في مهام الشيفرة، ويضاهي GPT4-Turbo."
  },
  "deepseek-coder-v2:236b": {
    "description": "DeepSeek Coder V2 هو نموذج شيفرة مفتوح المصدر من نوع خبير مختلط، يقدم أداءً ممتازًا في مهام الشيفرة، ويضاهي GPT4-Turbo."
  },
  "deepseek-v2": {
    "description": "DeepSeek V2 هو نموذج لغوي فعال من نوع Mixture-of-Experts، مناسب لاحتياجات المعالجة الاقتصادية."
  },
  "deepseek-v2:236b": {
    "description": "DeepSeek V2 236B هو نموذج تصميم الشيفرة لـ DeepSeek، يوفر قدرة توليد شيفرة قوية."
  },
  "deepseek/deepseek-chat": {
    "description": "نموذج مفتوح المصدر جديد يجمع بين القدرات العامة وقدرات البرمجة، لا يحتفظ فقط بقدرات الحوار العامة لنموذج الدردشة الأصلي وقدرات معالجة الأكواد القوية لنموذج Coder، بل يتماشى أيضًا بشكل أفضل مع تفضيلات البشر. بالإضافة إلى ذلك، حقق DeepSeek-V2.5 تحسينات كبيرة في مهام الكتابة، واتباع التعليمات، وغيرها من المجالات."
  },
  "emohaa": {
    "description": "Emohaa هو نموذج نفسي، يتمتع بقدرات استشارية متخصصة، يساعد المستخدمين في فهم القضايا العاطفية."
  },
  "gemini-1.0-pro-001": {
    "description": "Gemini 1.0 Pro 001 (تعديل) يوفر أداءً مستقرًا وقابلًا للتعديل، وهو الخيار المثالي لحلول المهام المعقدة."
  },
  "gemini-1.0-pro-002": {
    "description": "Gemini 1.0 Pro 002 (تعديل) يوفر دعمًا ممتازًا متعدد الوسائط، مع التركيز على الحلول الفعالة للمهام المعقدة."
  },
  "gemini-1.0-pro-latest": {
    "description": "Gemini 1.0 Pro هو نموذج ذكاء اصطناعي عالي الأداء من Google، مصمم للتوسع في مجموعة واسعة من المهام."
  },
  "gemini-1.5-flash-001": {
    "description": "Gemini 1.5 Flash 001 هو نموذج متعدد الوسائط فعال، يدعم التوسع في التطبيقات الواسعة."
  },
  "gemini-1.5-flash-002": {
    "description": "جمني 1.5 فلاش 002 هو نموذج متعدد الوسائط فعال، يدعم توسيع التطبيقات على نطاق واسع."
  },
  "gemini-1.5-flash-8b": {
    "description": "جمني 1.5 فلاش 8B هو نموذج متعدد الوسائط عالي الكفاءة، يدعم مجموعة واسعة من التطبيقات."
  },
  "gemini-1.5-flash-8b-exp-0924": {
    "description": "جمني 1.5 فلاش 8B 0924 هو النموذج التجريبي الأحدث، حيث حقق تحسينات ملحوظة في الأداء في حالات الاستخدام النصية ومتعددة الوسائط."
  },
  "gemini-1.5-flash-exp-0827": {
    "description": "جيميني 1.5 فلاش 0827 يقدم قدرة معالجة متعددة الوسائط محسنة، مناسب لمجموعة متنوعة من سيناريوهات المهام المعقدة."
  },
  "gemini-1.5-flash-latest": {
    "description": "Gemini 1.5 Flash هو أحدث نموذج ذكاء اصطناعي متعدد الوسائط من Google، يتمتع بقدرات معالجة سريعة، ويدعم إدخال النصوص والصور والفيديو، مما يجعله مناسبًا للتوسع الفعال في مجموعة متنوعة من المهام."
  },
  "gemini-1.5-pro-001": {
    "description": "Gemini 1.5 Pro 001 هو حل ذكاء اصطناعي متعدد الوسائط قابل للتوسع، يدعم مجموعة واسعة من المهام المعقدة."
  },
  "gemini-1.5-pro-002": {
    "description": "جمني 1.5 برو 002 هو النموذج الأحدث الجاهز للإنتاج، حيث يقدم مخرجات ذات جودة أعلى، مع تحسينات ملحوظة خاصة في الرياضيات والسياقات الطويلة والمهام البصرية."
  },
  "gemini-1.5-pro-exp-0801": {
    "description": "جيميني 1.5 برو 0801 يوفر قدرة معالجة متعددة الوسائط ممتازة، مما يوفر مرونة أكبر لتطوير التطبيقات."
  },
  "gemini-1.5-pro-exp-0827": {
    "description": "جيميني 1.5 برو 0827 يدمج أحدث تقنيات التحسين، مما يوفر قدرة معالجة بيانات متعددة الوسائط أكثر كفاءة."
  },
  "gemini-1.5-pro-latest": {
    "description": "Gemini 1.5 Pro يدعم ما يصل إلى 2 مليون توكن، وهو الخيار المثالي للنماذج المتوسطة الحجم متعددة الوسائط، مناسب لدعم المهام المعقدة من جوانب متعددة."
  },
  "gemini-2.0-flash-exp": {
    "description": "جيميناي 2.0 فلاش إكسب هو أحدث نموذج ذكاء اصطناعي متعدد الوسائط من جوجل، يتمتع بميزات الجيل القادم، وسرعة فائقة، واستدعاء أدوات أصلية، وتوليد متعدد الوسائط."
  },
  "gemini-2.0-flash-thinking-exp-1219": {
    "description": "Gemini 2.0 Flash Exp هو أحدث نموذج ذكاء اصطناعي متعدد الوسائط التجريبي من Google، يتميز بخصائص الجيل التالي، وسرعة فائقة، واستدعاء أدوات أصلية، وتوليد متعدد الوسائط."
  },
  "gemini-exp-1114": {
    "description": "جيمني إكسب 1114 هو أحدث نموذج ذكاء اصطناعي متعدد الوسائط تجريبي من Google، يتميز بقدرة معالجة سريعة، ويدعم إدخالات النصوص والصور والفيديو، مما يجعله مناسبًا للتوسع الفعال في مهام متعددة."
  },
  "gemini-exp-1121": {
    "description": "جمني إكسب 1121 هو أحدث نموذج تجريبي متعدد الوسائط من جوجل، يتمتع بقدرة معالجة سريعة، ويدعم إدخال النصوص والصور والفيديو، مما يجعله مناسبًا للتوسع الفعال في مجموعة متنوعة من المهام."
  },
  "gemini-exp-1206": {
    "description": "جيميني إكسب 1206 هو أحدث نموذج ذكاء اصطناعي متعدد الوسائط من جوجل، مع تحسينات في الجودة مقارنةً بالإصدارات السابقة."
  },
  "gemma-7b-it": {
    "description": "Gemma 7B مناسب لمعالجة المهام المتوسطة والصغيرة، ويجمع بين الكفاءة من حيث التكلفة."
  },
  "gemma2": {
    "description": "Gemma 2 هو نموذج فعال أطلقته Google، يغطي مجموعة متنوعة من سيناريوهات التطبيقات من التطبيقات الصغيرة إلى معالجة البيانات المعقدة."
  },
  "gemma2-9b-it": {
    "description": "Gemma 2 9B هو نموذج محسن لمهام محددة ودمج الأدوات."
  },
  "gemma2:27b": {
    "description": "Gemma 2 هو نموذج فعال أطلقته Google، يغطي مجموعة متنوعة من سيناريوهات التطبيقات من التطبيقات الصغيرة إلى معالجة البيانات المعقدة."
  },
  "gemma2:2b": {
    "description": "Gemma 2 هو نموذج فعال أطلقته Google، يغطي مجموعة متنوعة من سيناريوهات التطبيقات من التطبيقات الصغيرة إلى معالجة البيانات المعقدة."
  },
  "generalv3": {
    "description": "Spark Pro هو نموذج لغوي كبير عالي الأداء تم تحسينه للحقول المهنية، يركز على الرياضيات، والبرمجة، والطب، والتعليم، ويدعم البحث عبر الإنترنت بالإضافة إلى المكونات الإضافية المدمجة مثل الطقس والتاريخ. يظهر النموذج المحسن أداءً ممتازًا وكفاءة في الإجابة على الأسئلة المعقدة، وفهم اللغة، وإنشاء نصوص عالية المستوى، مما يجعله الخيار المثالي لتطبيقات الاستخدام المهني."
  },
  "generalv3.5": {
    "description": "Spark3.5 Max هو الإصدار الأكثر شمولاً، يدعم البحث عبر الإنترنت والعديد من المكونات الإضافية المدمجة. تعزز قدراته الأساسية المحسنة، بالإضافة إلى إعدادات الأدوار النظامية ووظائف استدعاء الدوال، أداؤه بشكل استثنائي في مجموعة متنوعة من سيناريوهات التطبيقات المعقدة."
  },
  "glm-4": {
    "description": "GLM-4 هو الإصدار القديم الذي تم إصداره في يناير 2024، وقد تم استبداله الآن بـ GLM-4-0520 الأقوى."
  },
  "glm-4-0520": {
    "description": "GLM-4-0520 هو أحدث إصدار من النموذج، مصمم للمهام المعقدة والمتنوعة، ويظهر أداءً ممتازًا."
  },
  "glm-4-9b-chat": {
    "description": "يظهر GLM-4-9B-Chat أداءً عاليًا في مجالات متعددة مثل الدلالات والرياضيات والاستدلال والترميز والمعرفة. كما أنه مزود بقدرات تصفح الويب وتنفيذ الشيفرات واستدعاء الأدوات المخصصة واستدلال النصوص الطويلة. يدعم 26 لغة بما في ذلك اليابانية والكورية والألمانية."
  },
  "glm-4-air": {
    "description": "GLM-4-Air هو إصدار ذو قيمة عالية، يتمتع بأداء قريب من GLM-4، ويقدم سرعة عالية وسعرًا معقولًا."
  },
  "glm-4-airx": {
    "description": "GLM-4-AirX يقدم إصدارًا فعالًا من GLM-4-Air، حيث تصل سرعة الاستدلال إلى 2.6 مرة."
  },
  "glm-4-alltools": {
    "description": "GLM-4-AllTools هو نموذج وكيل متعدد الوظائف، تم تحسينه لدعم تخطيط التعليمات المعقدة واستدعاء الأدوات، مثل تصفح الإنترنت، وتفسير الشيفرة، وتوليد النصوص، مناسب لتنفيذ المهام المتعددة."
  },
  "glm-4-flash": {
    "description": "GLM-4-Flash هو الخيار المثالي لمعالجة المهام البسيطة، حيث يتمتع بأسرع سرعة وأفضل سعر."
  },
  "glm-4-flashx": {
    "description": "GLM-4-FlashX هو إصدار معزز من Flash، يتميز بسرعة استدلال فائقة."
  },
  "glm-4-long": {
    "description": "GLM-4-Long يدعم إدخالات نصية طويلة جدًا، مما يجعله مناسبًا للمهام الذاكرية ومعالجة الوثائق الكبيرة."
  },
  "glm-4-plus": {
    "description": "GLM-4-Plus كنموذج رائد ذكي، يتمتع بقدرات قوية في معالجة النصوص الطويلة والمهام المعقدة، مع تحسين شامل في الأداء."
  },
  "glm-4v": {
    "description": "GLM-4V يوفر قدرات قوية في فهم الصور والاستدلال، ويدعم مجموعة متنوعة من المهام البصرية."
  },
  "glm-4v-flash": {
    "description": "يتميز GLM-4V-Flash بتركيزه على فهم الصور الفردية بكفاءة، وهو مناسب لسيناريوهات تحليل الصور السريعة، مثل تحليل الصور في الوقت الفعلي أو معالجة الصور بكميات كبيرة."
  },
  "glm-4v-plus": {
    "description": "GLM-4V-Plus يتمتع بقدرة على فهم محتوى الفيديو والصور المتعددة، مما يجعله مناسبًا للمهام متعددة الوسائط."
  },
  "google/gemini-flash-1.5": {
    "description": "يقدم Gemini 1.5 Flash قدرات معالجة متعددة الوسائط محسّنة، مناسبة لمجموعة متنوعة من سيناريوهات المهام المعقدة."
  },
  "google/gemini-pro-1.5": {
    "description": "يجمع Gemini 1.5 Pro بين أحدث تقنيات التحسين، مما يوفر قدرة معالجة بيانات متعددة الوسائط بشكل أكثر كفاءة."
  },
  "google/gemma-2-27b-it": {
    "description": "Gemma 2 تستمر في مفهوم التصميم الخفيف والفعال."
  },
  "google/gemma-2-2b-it": {
    "description": "نموذج تحسين التعليمات الخفيف من Google"
  },
  "google/gemma-2-9b-it": {
    "description": "Gemma 2 هو سلسلة نماذج نصية مفتوحة المصدر خفيفة الوزن من Google."
  },
  "google/gemma-2-9b-it:free": {
    "description": "Gemma 2 هو سلسلة نماذج نصية مفتوحة المصدر خفيفة الوزن من Google."
  },
  "google/gemma-2b-it": {
    "description": "Gemma Instruct (2B) يوفر قدرة أساسية على معالجة التعليمات، مناسب للتطبيقات الخفيفة."
  },
  "gpt-3.5-turbo": {
    "description": "نموذج GPT 3.5 Turbo، مناسب لمجموعة متنوعة من مهام توليد وفهم النصوص، يشير حاليًا إلى gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-0125": {
    "description": "نموذج GPT 3.5 Turbo، مناسب لمجموعة متنوعة من مهام توليد وفهم النصوص، يشير حاليًا إلى gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-1106": {
    "description": "نموذج GPT 3.5 Turbo، مناسب لمجموعة متنوعة من مهام توليد وفهم النصوص، يشير حاليًا إلى gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-instruct": {
    "description": "نموذج GPT 3.5 Turbo، مناسب لمجموعة متنوعة من مهام توليد وفهم النصوص، يشير حاليًا إلى gpt-3.5-turbo-0125."
  },
  "gpt-35-turbo": {
    "description": "جي بي تي 3.5 توربو، نموذج فعال مقدم من OpenAI، مناسب للدردشة ومهام توليد النصوص، يدعم استدعاءات الوظائف المتوازية."
  },
  "gpt-35-turbo-16k": {
    "description": "جي بي تي 3.5 توربو 16k، نموذج توليد نصوص عالي السعة، مناسب للمهام المعقدة."
  },
  "gpt-4": {
    "description": "يوفر GPT-4 نافذة سياقية أكبر، مما يمكنه من معالجة إدخالات نصية أطول، مما يجعله مناسبًا للمواقف التي تتطلب دمج معلومات واسعة وتحليل البيانات."
  },
  "gpt-4-0125-preview": {
    "description": "نموذج GPT-4 Turbo الأحدث يتمتع بقدرات بصرية. الآن، يمكن استخدام الطلبات البصرية باستخدام نمط JSON واستدعاء الوظائف. GPT-4 Turbo هو إصدار معزز يوفر دعمًا فعالًا من حيث التكلفة للمهام متعددة الوسائط. يجد توازنًا بين الدقة والكفاءة، مما يجعله مناسبًا للتطبيقات التي تتطلب تفاعلات في الوقت الحقيقي."
  },
  "gpt-4-0613": {
    "description": "يوفر GPT-4 نافذة سياقية أكبر، مما يمكنه من معالجة إدخالات نصية أطول، مما يجعله مناسبًا للمواقف التي تتطلب دمج معلومات واسعة وتحليل البيانات."
  },
  "gpt-4-1106-preview": {
    "description": "نموذج GPT-4 Turbo الأحدث يتمتع بقدرات بصرية. الآن، يمكن استخدام الطلبات البصرية باستخدام نمط JSON واستدعاء الوظائف. GPT-4 Turbo هو إصدار معزز يوفر دعمًا فعالًا من حيث التكلفة للمهام متعددة الوسائط. يجد توازنًا بين الدقة والكفاءة، مما يجعله مناسبًا للتطبيقات التي تتطلب تفاعلات في الوقت الحقيقي."
  },
  "gpt-4-32k": {
    "description": "يوفر GPT-4 نافذة سياقية أكبر، مما يمكنه من معالجة إدخالات نصية أطول، مما يجعله مناسبًا للمواقف التي تتطلب دمج معلومات واسعة وتحليل البيانات."
  },
  "gpt-4-32k-0613": {
    "description": "يوفر GPT-4 نافذة سياقية أكبر، مما يمكنه من معالجة إدخالات نصية أطول، مما يجعله مناسبًا للمواقف التي تتطلب دمج معلومات واسعة وتحليل البيانات."
  },
  "gpt-4-turbo": {
    "description": "نموذج GPT-4 Turbo الأحدث يتمتع بقدرات بصرية. الآن، يمكن استخدام الطلبات البصرية باستخدام نمط JSON واستدعاء الوظائف. GPT-4 Turbo هو إصدار معزز يوفر دعمًا فعالًا من حيث التكلفة للمهام متعددة الوسائط. يجد توازنًا بين الدقة والكفاءة، مما يجعله مناسبًا للتطبيقات التي تتطلب تفاعلات في الوقت الحقيقي."
  },
  "gpt-4-turbo-2024-04-09": {
    "description": "نموذج GPT-4 Turbo الأحدث يتمتع بقدرات بصرية. الآن، يمكن استخدام الطلبات البصرية باستخدام نمط JSON واستدعاء الوظائف. GPT-4 Turbo هو إصدار معزز يوفر دعمًا فعالًا من حيث التكلفة للمهام متعددة الوسائط. يجد توازنًا بين الدقة والكفاءة، مما يجعله مناسبًا للتطبيقات التي تتطلب تفاعلات في الوقت الحقيقي."
  },
  "gpt-4-turbo-preview": {
    "description": "نموذج GPT-4 Turbo الأحدث يتمتع بقدرات بصرية. الآن، يمكن استخدام الطلبات البصرية باستخدام نمط JSON واستدعاء الوظائف. GPT-4 Turbo هو إصدار معزز يوفر دعمًا فعالًا من حيث التكلفة للمهام متعددة الوسائط. يجد توازنًا بين الدقة والكفاءة، مما يجعله مناسبًا للتطبيقات التي تتطلب تفاعلات في الوقت الحقيقي."
  },
  "gpt-4-vision-preview": {
    "description": "نموذج GPT-4 Turbo الأحدث يتمتع بقدرات بصرية. الآن، يمكن استخدام الطلبات البصرية باستخدام نمط JSON واستدعاء الوظائف. GPT-4 Turbo هو إصدار معزز يوفر دعمًا فعالًا من حيث التكلفة للمهام متعددة الوسائط. يجد توازنًا بين الدقة والكفاءة، مما يجعله مناسبًا للتطبيقات التي تتطلب تفاعلات في الوقت الحقيقي."
  },
  "gpt-4o": {
    "description": "ChatGPT-4o هو نموذج ديناميكي يتم تحديثه في الوقت الحقيقي للحفاظ على أحدث إصدار. يجمع بين فهم اللغة القوي وقدرات التوليد، مما يجعله مناسبًا لمجموعة واسعة من التطبيقات، بما في ذلك خدمة العملاء والتعليم والدعم الفني."
  },
  "gpt-4o-2024-05-13": {
    "description": "ChatGPT-4o هو نموذج ديناميكي يتم تحديثه في الوقت الحقيقي للحفاظ على أحدث إصدار. يجمع بين فهم اللغة القوي وقدرات التوليد، مما يجعله مناسبًا لمجموعة واسعة من التطبيقات، بما في ذلك خدمة العملاء والتعليم والدعم الفني."
  },
  "gpt-4o-2024-08-06": {
    "description": "ChatGPT-4o هو نموذج ديناميكي يتم تحديثه في الوقت الحقيقي للحفاظ على أحدث إصدار. يجمع بين فهم اللغة القوي وقدرات التوليد، مما يجعله مناسبًا لمجموعة واسعة من التطبيقات، بما في ذلك خدمة العملاء والتعليم والدعم الفني."
  },
  "gpt-4o-2024-11-20": {
    "description": "تشات جي بي تي-4o هو نموذج ديناميكي يتم تحديثه في الوقت الفعلي للحفاظ على أحدث إصدار. يجمع بين الفهم اللغوي القوي وقدرة التوليد، مما يجعله مناسبًا لتطبيقات واسعة النطاق، بما في ذلك خدمة العملاء والتعليم والدعم الفني."
  },
  "gpt-4o-mini": {
    "description": "نموذج GPT-4o mini هو أحدث نموذج أطلقته OpenAI بعد GPT-4 Omni، ويدعم إدخال الصور والنصوص وإخراج النصوص. كأحد نماذجهم المتقدمة الصغيرة، فهو أرخص بكثير من النماذج الرائدة الأخرى في الآونة الأخيرة، وأرخص بأكثر من 60% من GPT-3.5 Turbo. يحتفظ بذكاء متقدم مع قيمة ممتازة. حصل GPT-4o mini على 82% في اختبار MMLU، وهو حاليًا يتفوق على GPT-4 في تفضيلات الدردشة."
  },
  "grok-2-1212": {
    "description": "لقد تم تحسين هذا النموذج في الدقة، والامتثال للتعليمات، والقدرة على التعامل مع لغات متعددة."
  },
  "grok-2-vision-1212": {
    "description": "لقد تم تحسين هذا النموذج في الدقة، والامتثال للتعليمات، والقدرة على التعامل مع لغات متعددة."
  },
  "grok-beta": {
    "description": "يمتلك أداءً يعادل Grok 2، ولكنه يتمتع بكفاءة وسرعة ووظائف أعلى."
  },
  "grok-vision-beta": {
    "description": "أحدث نموذج لفهم الصور، يمكنه معالجة مجموعة متنوعة من المعلومات البصرية، بما في ذلك الوثائق، الرسوم البيانية، لقطات الشاشة، والصور."
  },
  "gryphe/mythomax-l2-13b": {
    "description": "MythoMax l2 13B هو نموذج لغوي يجمع بين الإبداع والذكاء من خلال دمج عدة نماذج رائدة."
  },
  "hunyuan-code": {
    "description": "نموذج توليد الشيفرة الأحدث من Hunyuan، تم تدريبه على نموذج أساسي من بيانات الشيفرة عالية الجودة بحجم 200B، مع تدريب عالي الجودة على بيانات SFT لمدة ستة أشهر، وزيادة طول نافذة السياق إلى 8K، ويحتل مرتبة متقدمة في مؤشرات التقييم التلقائي لتوليد الشيفرة في خمس لغات؛ كما أنه في الطليعة في تقييمات الشيفرة عالية الجودة عبر عشرة معايير في خمس لغات."
  },
  "hunyuan-functioncall": {
    "description": "نموذج Hunyuan الأحدث من نوع MOE FunctionCall، تم تدريبه على بيانات FunctionCall عالية الجودة، مع نافذة سياق تصل إلى 32K، ويحتل مرتبة متقدمة في مؤشرات التقييم عبر عدة أبعاد."
  },
  "hunyuan-lite": {
    "description": "تم الترقية إلى هيكل MOE، مع نافذة سياق تصل إلى 256k، متفوقًا على العديد من النماذج مفتوحة المصدر في تقييمات NLP، البرمجة، الرياضيات، والصناعات."
  },
  "hunyuan-pro": {
    "description": "نموذج نصوص طويلة MOE-32K بحجم تريليون من المعلمات. يحقق مستوى رائد مطلق في مختلف المعايير، مع القدرة على التعامل مع التعليمات المعقدة والاستدلال، ويتميز بقدرات رياضية معقدة، ويدعم استدعاء الوظائف، مع تحسينات رئيسية في مجالات الترجمة متعددة اللغات، المالية، القانونية، والرعاية الصحية."
  },
  "hunyuan-role": {
    "description": "نموذج Hunyuan الأحدث لتقمص الأدوار، تم تطويره من قبل Hunyuan مع تدريب دقيق، يعتمد على نموذج Hunyuan مع مجموعة بيانات سيناريوهات تقمص الأدوار، مما يوفر أداءً أفضل في سيناريوهات تقمص الأدوار."
  },
  "hunyuan-standard": {
    "description": "يستخدم استراتيجية توجيه أفضل، مع تخفيف مشكلات التوازن في الحمل وتوافق الخبراء. في مجال النصوص الطويلة، تصل نسبة مؤشر البحث إلى 99.9%. MOE-32K يقدم قيمة أفضل، مع تحقيق توازن بين الأداء والسعر، مما يسمح بمعالجة المدخلات النصية الطويلة."
  },
  "hunyuan-standard-256K": {
    "description": "يستخدم استراتيجية توجيه أفضل، مع تخفيف مشكلات التوازن في الحمل وتوافق الخبراء. في مجال النصوص الطويلة، تصل نسبة مؤشر البحث إلى 99.9%. MOE-256K يحقق اختراقًا إضافيًا في الطول والأداء، مما يوسع بشكل كبير طول المدخلات الممكنة."
  },
  "hunyuan-turbo": {
    "description": "نسخة المعاينة من الجيل الجديد من نموذج اللغة الكبير، يستخدم هيكل نموذج الخبراء المختلط (MoE) الجديد، مما يوفر كفاءة استدلال أسرع وأداء أقوى مقارنة بـ hunyuan-pro."
  },
  "hunyuan-vision": {
    "description": "نموذج Hunyuan الأحدث متعدد الوسائط، يدعم إدخال الصور والنصوص لتوليد محتوى نصي."
  },
  "internlm/internlm2_5-20b-chat": {
    "description": "نموذج مفتوح المصدر مبتكر InternLM2.5، يعزز الذكاء الحواري من خلال عدد كبير من المعلمات."
  },
  "internlm/internlm2_5-7b-chat": {
    "description": "InternLM2.5 يوفر حلول حوار ذكية في عدة سيناريوهات."
  },
  "internlm2-pro-chat": {
    "description": "نموذج النسخة القديمة الذي لا زلنا نحافظ عليه، يتوفر بخيارات متعددة من عدد المعلمات 7 مليار و 20 مليار."
  },
  "internlm2.5-latest": {
    "description": "سلسلة نماذجنا الأحدث، تتمتع بأداء استدلال ممتاز، تدعم طول سياق يصل إلى 1 مليون، بالإضافة إلى قدرة أقوى على اتباع التعليمات واستدعاء الأدوات."
  },
  "learnlm-1.5-pro-experimental": {
    "description": "LearnLM هو نموذج لغوي تجريبي محدد المهام، تم تدريبه ليتماشى مع مبادئ علوم التعلم، يمكنه اتباع التعليمات النظامية في سيناريوهات التعليم والتعلم، ويعمل كمدرب خبير."
  },
  "lite": {
    "description": "سبارك لايت هو نموذج لغوي كبير خفيف الوزن، يتميز بتأخير منخفض للغاية وكفاءة عالية في المعالجة، وهو مجاني تمامًا ومفتوح، ويدعم وظيفة البحث عبر الإنترنت في الوقت الحقيقي. تجعل خصائص استجابته السريعة منه مثاليًا لتطبيقات الاستدلال على الأجهزة ذات القدرة الحاسوبية المنخفضة وضبط النماذج، مما يوفر للمستخدمين قيمة ممتازة من حيث التكلفة وتجربة ذكية، خاصة في مجالات الأسئلة والأجوبة المعرفية، وتوليد المحتوى، وسيناريوهات البحث."
  },
  "llama-3.1-70b-instruct": {
    "description": "نموذج Llama 3.1 70B للتعليمات، يتمتع بـ 70B من المعلمات، قادر على تقديم أداء ممتاز في مهام توليد النصوص الكبيرة والتعليمات."
  },
  "llama-3.1-70b-versatile": {
    "description": "Llama 3.1 70B يوفر قدرة استدلال ذكائي أقوى، مناسب للتطبيقات المعقدة، يدعم معالجة حسابية ضخمة ويضمن الكفاءة والدقة."
  },
  "llama-3.1-8b-instant": {
    "description": "Llama 3.1 8B هو نموذج عالي الأداء، يوفر قدرة سريعة على توليد النصوص، مما يجعله مثاليًا لمجموعة من التطبيقات التي تتطلب كفاءة كبيرة وتكلفة فعالة."
  },
  "llama-3.1-8b-instruct": {
    "description": "نموذج Llama 3.1 8B للتعليمات، يتمتع بـ 8B من المعلمات، يدعم تنفيذ مهام التعليمات بكفاءة، ويوفر قدرة ممتازة على توليد النصوص."
  },
  "llama-3.1-sonar-huge-128k-online": {
    "description": "نموذج Llama 3.1 Sonar Huge Online، يتمتع بـ 405B من المعلمات، يدعم طول سياق حوالي 127,000 علامة، مصمم لتطبيقات دردشة معقدة عبر الإنترنت."
  },
  "llama-3.1-sonar-large-128k-chat": {
    "description": "نموذج Llama 3.1 Sonar Large Chat، يتمتع بـ 70B من المعلمات، يدعم طول سياق حوالي 127,000 علامة، مناسب لمهام دردشة غير متصلة معقدة."
  },
  "llama-3.1-sonar-large-128k-online": {
    "description": "نموذج Llama 3.1 Sonar Large Online، يتمتع بـ 70B من المعلمات، يدعم طول سياق حوالي 127,000 علامة، مناسب لمهام دردشة عالية السعة ومتنوعة."
  },
  "llama-3.1-sonar-small-128k-chat": {
    "description": "نموذج Llama 3.1 Sonar Small Chat، يتمتع بـ 8B من المعلمات، مصمم للدردشة غير المتصلة، يدعم طول سياق حوالي 127,000 علامة."
  },
  "llama-3.1-sonar-small-128k-online": {
    "description": "نموذج Llama 3.1 Sonar Small Online، يتمتع بـ 8B من المعلمات، يدعم طول سياق حوالي 127,000 علامة، مصمم للدردشة عبر الإنترنت، قادر على معالجة تفاعلات نصية متنوعة بكفاءة."
  },
  "llama-3.2-11b-vision-instruct": {
    "description": "قدرة استدلال الصور التي تبرز في الصور عالية الدقة، مناسبة لتطبيقات الفهم البصري."
  },
  "llama-3.2-11b-vision-preview": {
    "description": "Llama 3.2 مصمم للتعامل مع المهام التي تجمع بين البيانات البصرية والنصية. يظهر أداءً ممتازًا في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة والاستدلال البصري."
  },
  "llama-3.2-90b-vision-instruct": {
    "description": "قدرة استدلال الصور المتقدمة المناسبة لتطبيقات الوكلاء في الفهم البصري."
  },
  "llama-3.2-90b-vision-preview": {
    "description": "Llama 3.2 مصمم للتعامل مع المهام التي تجمع بين البيانات البصرية والنصية. يظهر أداءً ممتازًا في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة والاستدلال البصري."
  },
  "llama-3.3-70b-versatile": {
    "description": "ميتّا لاما 3.3 هو نموذج لغة كبير متعدد اللغات (LLM) يضم 70 مليار (إدخال نص/إخراج نص) من النموذج المدرب مسبقًا والمعدل وفقًا للتعليمات. تم تحسين نموذج لاما 3.3 المعدل وفقًا للتعليمات للاستخدامات الحوارية متعددة اللغات ويتفوق على العديد من النماذج المتاحة مفتوحة المصدر والمغلقة في المعايير الصناعية الشائعة."
  },
  "llama3-70b-8192": {
    "description": "Meta Llama 3 70B يوفر قدرة معالجة معقدة لا مثيل لها، مصمم خصيصًا للمشاريع ذات المتطلبات العالية."
  },
  "llama3-8b-8192": {
    "description": "Meta Llama 3 8B يوفر أداء استدلال عالي الجودة، مناسب لمتطلبات التطبيقات متعددة السيناريوهات."
  },
  "llama3-groq-70b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 70B Tool Use يوفر قدرة قوية على استدعاء الأدوات، يدعم معالجة فعالة للمهام المعقدة."
  },
  "llama3-groq-8b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 8B Tool Use هو نموذج محسن للاستخدام الفعال للأدوات، يدعم الحسابات المتوازية السريعة."
  },
  "llama3.1": {
    "description": "Llama 3.1 هو النموذج الرائد الذي أطلقته Meta، يدعم ما يصل إلى 405B من المعلمات، ويمكن تطبيقه في مجالات الحوار المعقد، والترجمة متعددة اللغات، وتحليل البيانات."
  },
  "llama3.1:405b": {
    "description": "Llama 3.1 هو النموذج الرائد الذي أطلقته Meta، يدعم ما يصل إلى 405B من المعلمات، ويمكن تطبيقه في مجالات الحوار المعقد، والترجمة متعددة اللغات، وتحليل البيانات."
  },
  "llama3.1:70b": {
    "description": "Llama 3.1 هو النموذج الرائد الذي أطلقته Meta، يدعم ما يصل إلى 405B من المعلمات، ويمكن تطبيقه في مجالات الحوار المعقد، والترجمة متعددة اللغات، وتحليل البيانات."
  },
  "llava": {
    "description": "LLaVA هو نموذج متعدد الوسائط يجمع بين مشفرات بصرية وVicuna، يستخدم لفهم بصري ولغوي قوي."
  },
  "llava-v1.5-7b-4096-preview": {
    "description": "LLaVA 1.5 7B يوفر قدرة معالجة بصرية مدمجة، من خلال إدخال المعلومات البصرية لتوليد مخرجات معقدة."
  },
  "llava:13b": {
    "description": "LLaVA هو نموذج متعدد الوسائط يجمع بين مشفرات بصرية وVicuna، يستخدم لفهم بصري ولغوي قوي."
  },
  "llava:34b": {
    "description": "LLaVA هو نموذج متعدد الوسائط يجمع بين مشفرات بصرية وVicuna، يستخدم لفهم بصري ولغوي قوي."
  },
  "mathstral": {
    "description": "MathΣtral مصمم للبحث العلمي والاستدلال الرياضي، يوفر قدرة حسابية فعالة وتفسير النتائج."
  },
  "max-32k": {
    "description": "سبارك ماكس 32K مزود بقدرة معالجة سياق كبيرة، مع فهم أقوى للسياق وقدرة على الاستدلال المنطقي، يدعم إدخال نصوص تصل إلى 32K توكن، مما يجعله مناسبًا لقراءة الوثائق الطويلة، والأسئلة والأجوبة المعرفية الخاصة، وغيرها من السيناريوهات."
  },
  "meta-llama-3-70b-instruct": {
    "description": "نموذج قوي بحجم 70 مليار معلمة يتفوق في التفكير، والترميز، وتطبيقات اللغة الواسعة."
  },
  "meta-llama-3-8b-instruct": {
    "description": "نموذج متعدد الاستخدامات بحجم 8 مليار معلمة، مُحسّن لمهام الحوار وتوليد النصوص."
  },
  "meta-llama-3.1-405b-instruct": {
    "description": "نموذج Llama 3.1 المُعدل للتعليمات، مُحسّن لاستخدامات الحوار متعددة اللغات ويتفوق على العديد من نماذج الدردشة المفتوحة والمغلقة المتاحة في المعايير الصناعية الشائعة."
  },
  "meta-llama-3.1-70b-instruct": {
    "description": "نموذج Llama 3.1 المُعدل للتعليمات، مُحسّن لاستخدامات الحوار متعددة اللغات ويتفوق على العديد من نماذج الدردشة المفتوحة والمغلقة المتاحة في المعايير الصناعية الشائعة."
  },
  "meta-llama-3.1-8b-instruct": {
    "description": "نموذج Llama 3.1 المُعدل للتعليمات، مُحسّن لاستخدامات الحوار متعددة اللغات ويتفوق على العديد من نماذج الدردشة المفتوحة والمغلقة المتاحة في المعايير الصناعية الشائعة."
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "description": "LLaMA-2 Chat (13B) يوفر قدرة ممتازة على معالجة اللغة وتجربة تفاعلية رائعة."
  },
  "meta-llama/Llama-2-70b-hf": {
    "description": "يوفر LLaMA-2 قدرة معالجة لغوية ممتازة وتجربة تفاعلية رائعة."
  },
  "meta-llama/Llama-3-70b-chat-hf": {
    "description": "LLaMA-3 Chat (70B) هو نموذج دردشة قوي، يدعم احتياجات الحوار المعقدة."
  },
  "meta-llama/Llama-3-8b-chat-hf": {
    "description": "LLaMA-3 Chat (8B) يوفر دعمًا متعدد اللغات، ويغطي مجموعة واسعة من المعرفة في المجالات."
  },
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
    "description": "تم تصميم LLaMA 3.2 لمعالجة المهام التي تجمع بين البيانات البصرية والنصية. إنه يبرز في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة واستدلال الرؤية."
  },
  "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
    "description": "تم تصميم LLaMA 3.2 لمعالجة المهام التي تجمع بين البيانات البصرية والنصية. إنه يبرز في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة واستدلال الرؤية."
  },
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
    "description": "تم تصميم LLaMA 3.2 لمعالجة المهام التي تجمع بين البيانات البصرية والنصية. إنه يبرز في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة واستدلال الرؤية."
  },
  "meta-llama/Llama-Vision-Free": {
    "description": "تم تصميم LLaMA 3.2 لمعالجة المهام التي تجمع بين البيانات البصرية والنصية. إنه يبرز في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة واستدلال الرؤية."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite": {
    "description": "Llama 3 70B Instruct Lite مناسب للبيئات التي تتطلب أداءً عاليًا وزمن استجابة منخفض."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo": {
    "description": "Llama 3 70B Instruct Turbo يوفر قدرة ممتازة على فهم اللغة وتوليدها، مناسب لأكثر المهام الحسابية تطلبًا."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
    "description": "Llama 3 8B Instruct Lite مناسب للبيئات ذات الموارد المحدودة، ويوفر أداءً متوازنًا ممتازًا."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo": {
    "description": "Llama 3 8B Instruct Turbo هو نموذج لغوي كبير عالي الأداء، يدعم مجموعة واسعة من سيناريوهات التطبيق."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct": {
    "description": "LLaMA 3.1 405B هو نموذج قوي للتدريب المسبق وضبط التعليمات."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
    "description": "نموذج Llama 3.1 Turbo 405B يوفر دعمًا كبيرًا للسياق لمعالجة البيانات الكبيرة، ويظهر أداءً بارزًا في تطبيقات الذكاء الاصطناعي على نطاق واسع."
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct": {
    "description": "LLaMA 3.1 70B يوفر دعمًا فعالًا للحوار متعدد اللغات."
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
    "description": "نموذج Llama 3.1 70B تم ضبطه بدقة، مناسب للتطبيقات ذات الحمل العالي، تم تكميمه إلى FP8 لتوفير قدرة حسابية ودقة أعلى، مما يضمن أداءً ممتازًا في السيناريوهات المعقدة."
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "description": "LLaMA 3.1 يوفر دعمًا متعدد اللغات، وهو واحد من النماذج الرائدة في الصناعة."
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
    "description": "نموذج Llama 3.1 8B يستخدم FP8 للتكميم، يدعم ما يصل إلى 131,072 علامة سياق، وهو من بين الأفضل في النماذج المفتوحة المصدر، مناسب للمهام المعقدة، ويظهر أداءً ممتازًا في العديد من المعايير الصناعية."
  },
  "meta-llama/llama-3-70b-instruct": {
    "description": "Llama 3 70B Instruct تم تحسينه لمشاهد الحوار عالية الجودة، ويظهر أداءً ممتازًا في مختلف التقييمات البشرية."
  },
  "meta-llama/llama-3-8b-instruct": {
    "description": "Llama 3 8B Instruct تم تحسينه لمشاهد الحوار عالية الجودة، ويظهر أداءً أفضل من العديد من النماذج المغلقة."
  },
  "meta-llama/llama-3.1-405b-instruct": {
    "description": "Llama 3.1 405B Instruct هو أحدث إصدار من Meta، تم تحسينه لتوليد حوارات عالية الجودة، متجاوزًا العديد من النماذج المغلقة الرائدة."
  },
  "meta-llama/llama-3.1-70b-instruct": {
    "description": "Llama 3.1 70B Instruct مصمم للحوار عالي الجودة، ويظهر أداءً بارزًا في التقييمات البشرية، مما يجعله مناسبًا بشكل خاص للمشاهد التفاعلية العالية."
  },
  "meta-llama/llama-3.1-8b-instruct": {
    "description": "Llama 3.1 8B Instruct هو أحدث إصدار من Meta، تم تحسينه لمشاهد الحوار عالية الجودة، ويظهر أداءً أفضل من العديد من النماذج المغلقة الرائدة."
  },
  "meta-llama/llama-3.1-8b-instruct:free": {
    "description": "LLaMA 3.1 يوفر دعمًا متعدد اللغات، وهو واحد من النماذج الرائدة في الصناعة في مجال التوليد."
  },
  "meta-llama/llama-3.2-11b-vision-instruct": {
    "description": "تم تصميم LLaMA 3.2 لمعالجة المهام التي تجمع بين البيانات البصرية والنصية. إنه يتفوق في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة والاستدلال البصري."
  },
  "meta-llama/llama-3.2-90b-vision-instruct": {
    "description": "تم تصميم LLaMA 3.2 لمعالجة المهام التي تجمع بين البيانات البصرية والنصية. إنه يتفوق في مهام وصف الصور والأسئلة البصرية، متجاوزًا الفجوة بين توليد اللغة والاستدلال البصري."
  },
  "meta.llama3-1-405b-instruct-v1:0": {
    "description": "نموذج Meta Llama 3.1 405B Instruct هو أكبر وأقوى نموذج في مجموعة نماذج Llama 3.1 Instruct، وهو نموذج متقدم للغاية لتوليد البيانات والحوار، ويمكن استخدامه كأساس للتدريب المستمر أو التخصيص في مجالات معينة. توفر Llama 3.1 نماذج لغوية كبيرة متعددة اللغات (LLMs) وهي مجموعة من النماذج المدربة مسبقًا والمعدلة وفقًا للتعليمات، بما في ذلك أحجام 8B و70B و405B (إدخال/إخراج نصي). تم تحسين نماذج النص المعدلة وفقًا للتعليمات (8B و70B و405B) لحالات الاستخدام الحوارية متعددة اللغات، وقد تفوقت في العديد من اختبارات المعايير الصناعية الشائعة على العديد من نماذج الدردشة مفتوحة المصدر المتاحة. تم تصميم Llama 3.1 للاستخدام التجاري والبحثي في عدة لغات. نماذج النص المعدلة وفقًا للتعليمات مناسبة للدردشة الشبيهة بالمساعد، بينما يمكن للنماذج المدربة مسبقًا التكيف مع مجموعة متنوعة من مهام توليد اللغة الطبيعية. تدعم نماذج Llama 3.1 أيضًا تحسين نماذج أخرى باستخدام مخرجاتها، بما في ذلك توليد البيانات الاصطناعية والتنقيح. Llama 3.1 هو نموذج لغوي ذاتي التكرار يستخدم بنية المحولات المحسّنة. تستخدم النسخ المعدلة التعلم المعزز مع التغذية الراجعة البشرية (RLHF) لتلبية تفضيلات البشر فيما يتعلق بالمساعدة والأمان."
  },
  "meta.llama3-1-70b-instruct-v1:0": {
    "description": "الإصدار المحدث من Meta Llama 3.1 70B Instruct، يتضمن طول سياق موسع يبلغ 128K، ودعم لغات متعددة، وقدرات استدلال محسنة. توفر Llama 3.1 نماذج لغوية كبيرة متعددة اللغات (LLMs) وهي مجموعة من النماذج التوليدية المدربة مسبقًا والمعدلة للتعليمات، بما في ذلك أحجام 8B و70B و405B (إدخال/إخراج نص). تم تحسين نماذج النص المعدلة للتعليمات (8B و70B و405B) لحالات الاستخدام متعددة اللغات، وتفوقت في اختبارات المعايير الصناعية الشائعة على العديد من نماذج الدردشة مفتوحة المصدر المتاحة. تم تصميم Llama 3.1 للاستخدام التجاري والبحثي في لغات متعددة. نماذج النص المعدلة للتعليمات مناسبة للدردشة الشبيهة بالمساعد، بينما يمكن للنماذج المدربة مسبقًا التكيف مع مجموعة متنوعة من مهام توليد اللغة الطبيعية. تدعم نماذج Llama 3.1 أيضًا تحسين نماذج أخرى باستخدام مخرجات نموذجها، بما في ذلك توليد البيانات الاصطناعية والتنقيح. Llama 3.1 هو نموذج لغوي ذاتي التكرار يستخدم بنية المحولات المحسنة. تستخدم النسخ المعدلة التعلم الموجه بالإشراف (SFT) والتعلم المعزز مع التغذية الراجعة البشرية (RLHF) لتلبية تفضيلات البشر فيما يتعلق بالمساعدة والأمان."
  },
  "meta.llama3-1-8b-instruct-v1:0": {
    "description": "الإصدار المحدث من Meta Llama 3.1 8B Instruct، يتضمن طول سياق موسع يبلغ 128K، ودعم لغات متعددة، وقدرات استدلال محسنة. توفر Llama 3.1 نماذج لغوية كبيرة متعددة اللغات (LLMs) وهي مجموعة من النماذج التوليدية المدربة مسبقًا والمعدلة للتعليمات، بما في ذلك أحجام 8B و70B و405B (إدخال/إخراج نص). تم تحسين نماذج النص المعدلة للتعليمات (8B و70B و405B) لحالات الاستخدام متعددة اللغات، وتفوقت في اختبارات المعايير الصناعية الشائعة على العديد من نماذج الدردشة مفتوحة المصدر المتاحة. تم تصميم Llama 3.1 للاستخدام التجاري والبحثي في لغات متعددة. نماذج النص المعدلة للتعليمات مناسبة للدردشة الشبيهة بالمساعد، بينما يمكن للنماذج المدربة مسبقًا التكيف مع مجموعة متنوعة من مهام توليد اللغة الطبيعية. تدعم نماذج Llama 3.1 أيضًا تحسين نماذج أخرى باستخدام مخرجات نموذجها، بما في ذلك توليد البيانات الاصطناعية والتنقيح. Llama 3.1 هو نموذج لغوي ذاتي التكرار يستخدم بنية المحولات المحسنة. تستخدم النسخ المعدلة التعلم الموجه بالإشراف (SFT) والتعلم المعزز مع التغذية الراجعة البشرية (RLHF) لتلبية تفضيلات البشر فيما يتعلق بالمساعدة والأمان."
  },
  "meta.llama3-70b-instruct-v1:0": {
    "description": "Meta Llama 3 هو نموذج لغوي كبير مفتوح (LLM) موجه للمطورين والباحثين والشركات، يهدف إلى مساعدتهم في بناء وتجربة وتوسيع أفكارهم في الذكاء الاصطناعي بشكل مسؤول. كجزء من نظام الابتكار المجتمعي العالمي، فهو مثالي لإنشاء المحتوى، والذكاء الاصطناعي الحواري، وفهم اللغة، والبحث والتطوير، وتطبيقات الأعمال."
  },
  "meta.llama3-8b-instruct-v1:0": {
    "description": "Meta Llama 3 هو نموذج لغوي كبير مفتوح (LLM) موجه للمطورين والباحثين والشركات، يهدف إلى مساعدتهم في بناء وتجربة وتوسيع أفكارهم في الذكاء الاصطناعي بشكل مسؤول. كجزء من نظام الابتكار المجتمعي العالمي، فهو مثالي للأجهزة ذات القدرة الحاسوبية والموارد المحدودة، والأجهزة الطرفية، وأوقات التدريب الأسرع."
  },
  "microsoft/WizardLM-2-8x22B": {
    "description": "WizardLM 2 هو نموذج لغوي تقدمه Microsoft AI، يتميز بأداء ممتاز في المحادثات المعقدة، واللغات المتعددة، والاستدلال، ومساعدات الذكاء."
  },
  "microsoft/wizardlm 2-7b": {
    "description": "WizardLM 2 7B هو أحدث نموذج خفيف الوزن وسريع من Microsoft AI، ويقترب أداؤه من 10 أضعاف النماذج الرائدة المفتوحة المصدر الحالية."
  },
  "microsoft/wizardlm-2-8x22b": {
    "description": "WizardLM-2 8x22B هو نموذج Wizard المتقدم من Microsoft، يظهر أداءً تنافسيًا للغاية."
  },
  "minicpm-v": {
    "description": "MiniCPM-V هو نموذج متعدد الوسائط من الجيل الجديد تم إطلاقه بواسطة OpenBMB، ويتميز بقدرات استثنائية في التعرف على النصوص وفهم الوسائط المتعددة، ويدعم مجموعة واسعة من سيناريوهات الاستخدام."
  },
  "ministral-3b-latest": {
    "description": "Ministral 3B هو نموذج حافة عالمي المستوى من Mistral."
  },
  "ministral-8b-latest": {
    "description": "Ministral 8B هو نموذج حافة ذات قيمة ممتازة من Mistral."
  },
  "mistral": {
    "description": "Mistral هو نموذج 7B أطلقته Mistral AI، مناسب لاحتياجات معالجة اللغة المتغيرة."
  },
  "mistral-large": {
    "description": "Mixtral Large هو النموذج الرائد من Mistral، يجمع بين قدرات توليد الشيفرة، والرياضيات، والاستدلال، ويدعم نافذة سياق تصل إلى 128k."
  },
  "mistral-large-latest": {
    "description": "Mistral Large هو النموذج الرائد، يتفوق في المهام متعددة اللغات، والاستدلال المعقد، وتوليد الشيفرة، وهو الخيار المثالي للتطبيقات الراقية."
  },
  "mistral-nemo": {
    "description": "Mistral Nemo تم تطويره بالتعاون بين Mistral AI وNVIDIA، وهو نموذج 12B عالي الأداء."
  },
  "mistral-small": {
    "description": "يمكن استخدام Mistral Small في أي مهمة تعتمد على اللغة تتطلب كفاءة عالية وزمن استجابة منخفض."
  },
  "mistral-small-latest": {
    "description": "Mistral Small هو خيار فعال من حيث التكلفة وسريع وموثوق، مناسب لمهام الترجمة، والتلخيص، وتحليل المشاعر."
  },
  "mistralai/Mistral-7B-Instruct-v0.1": {
    "description": "Mistral (7B) Instruct معروف بأدائه العالي، مناسب لمهام لغوية متعددة."
  },
  "mistralai/Mistral-7B-Instruct-v0.2": {
    "description": "Mistral 7B هو نموذج تم ضبطه حسب الطلب، يوفر إجابات محسنة للمهام."
  },
  "mistralai/Mistral-7B-Instruct-v0.3": {
    "description": "Mistral (7B) Instruct v0.3 يوفر قدرة حسابية فعالة وفهم اللغة الطبيعية، مناسب لمجموعة واسعة من التطبيقات."
  },
  "mistralai/Mistral-7B-v0.1": {
    "description": "Mistral 7B هو نموذج مضغوط ولكنه عالي الأداء، متفوق في المعالجة الجماعية والمهام البسيطة مثل التصنيف وتوليد النصوص، مع قدرة استدلال جيدة."
  },
  "mistralai/Mixtral-8x22B-Instruct-v0.1": {
    "description": "Mixtral-8x22B Instruct (141B) هو نموذج لغوي كبير للغاية، يدعم احتياجات معالجة عالية جدًا."
  },
  "mistralai/Mixtral-8x7B-Instruct-v0.1": {
    "description": "Mixtral 8x7B هو نموذج خبير مختلط مدرب مسبقًا، يستخدم لمهام النص العامة."
  },
  "mistralai/Mixtral-8x7B-v0.1": {
    "description": "Mixtral 8x7B هو نموذج خبير متفرق، يستفيد من معلمات متعددة لزيادة سرعة الاستدلال، مناسب لمعالجة المهام متعددة اللغات وتوليد الأكواد."
  },
  "mistralai/mistral-7b-instruct": {
    "description": "Mistral 7B Instruct هو نموذج صناعي عالي الأداء يجمع بين تحسين السرعة ودعم السياقات الطويلة."
  },
  "mistralai/mistral-nemo": {
    "description": "Mistral Nemo هو نموذج ببارامترات 7.3B يدعم عدة لغات ويتميز بأداء برمجي عالي."
  },
  "mixtral": {
    "description": "Mixtral هو نموذج خبير من Mistral AI، يتمتع بأوزان مفتوحة المصدر، ويوفر دعمًا في توليد الشيفرة وفهم اللغة."
  },
  "mixtral-8x7b-32768": {
    "description": "Mixtral 8x7B يوفر قدرة حسابية متوازية عالية التحمل، مناسب للمهام المعقدة."
  },
  "mixtral:8x22b": {
    "description": "Mixtral هو نموذج خبير من Mistral AI، يتمتع بأوزان مفتوحة المصدر، ويوفر دعمًا في توليد الشيفرة وفهم اللغة."
  },
  "moonshot-v1-128k": {
    "description": "Moonshot V1 128K هو نموذج يتمتع بقدرة معالجة سياقات طويلة جدًا، مناسب لتوليد نصوص طويلة جدًا، يلبي احتياجات المهام المعقدة، قادر على معالجة ما يصل إلى 128,000 توكن، مما يجعله مثاليًا للبحث، والأكاديميات، وتوليد الوثائق الكبيرة."
  },
  "moonshot-v1-32k": {
    "description": "Moonshot V1 32K يوفر قدرة معالجة سياقات متوسطة الطول، قادر على معالجة 32,768 توكن، مناسب بشكل خاص لتوليد مجموعة متنوعة من الوثائق الطويلة والحوار المعقد، ويستخدم في إنشاء المحتوى، وتوليد التقارير، وأنظمة الحوار."
  },
  "moonshot-v1-8k": {
    "description": "Moonshot V1 8K مصمم خصيصًا لتوليد مهام النصوص القصيرة، يتمتع بأداء معالجة فعال، قادر على معالجة 8,192 توكن، مما يجعله مثاليًا للحوار القصير، والتدوين السريع، وتوليد المحتوى السريع."
  },
  "nousresearch/hermes-2-pro-llama-3-8b": {
    "description": "Hermes 2 Pro Llama 3 8B هو إصدار مطور من Nous Hermes 2، ويحتوي على أحدث مجموعات البيانات المطورة داخليًا."
  },
  "nvidia/Llama-3.1-Nemotron-70B-Instruct": {
    "description": "Llama 3.1 Nemotron 70B هو نموذج لغوي كبير مُخصص من NVIDIA، يهدف إلى تحسين استجابة LLM لمساعدة استفسارات المستخدمين."
  },
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": {
    "description": "Llama 3.1 Nemotron 70B هو نموذج لغوي كبير مخصص من NVIDIA، يهدف إلى تحسين استجابة LLM لمساعدة استفسارات المستخدمين. لقد أظهر النموذج أداءً ممتازًا في اختبارات المعايير مثل Arena Hard وAlpacaEval 2 LC وGPT-4-Turbo MT-Bench، حيث احتل المرتبة الأولى في جميع اختبارات المحاذاة التلقائية الثلاثة حتى 1 أكتوبر 2024. تم تدريب النموذج باستخدام RLHF (خاصة REINFORCE) وLlama-3.1-Nemotron-70B-Reward وHelpSteer2-Preference على أساس نموذج Llama-3.1-70B-Instruct."
  },
  "o1": {
    "description": "يركز على الاستدلال المتقدم وحل المشكلات المعقدة، بما في ذلك المهام الرياضية والعلمية. مثالي للتطبيقات التي تتطلب فهمًا عميقًا للسياق وإدارة سير العمل."
  },
  "o1-2024-12-17": {
    "description": "o1 هو نموذج الاستدلال الجديد من OpenAI، يدعم إدخال النصوص والصور وإخراج النصوص، وهو مناسب للمهام المعقدة التي تتطلب معرفة عامة واسعة. يحتوي هذا النموذج على 200K من السياق وتاريخ انتهاء المعرفة في أكتوبر 2023."
  },
  "o1-mini": {
    "description": "o1-mini هو نموذج استدلال سريع وفعال من حيث التكلفة مصمم لتطبيقات البرمجة والرياضيات والعلوم. يحتوي هذا النموذج على 128K من السياق وتاريخ انتهاء المعرفة في أكتوبر 2023."
  },
  "o1-preview": {
    "description": "o1 هو نموذج استدلال جديد من OpenAI، مناسب للمهام المعقدة التي تتطلب معرفة عامة واسعة. يحتوي هذا النموذج على 128K من السياق وتاريخ انتهاء المعرفة في أكتوبر 2023."
  },
  "open-codestral-mamba": {
    "description": "Codestral Mamba هو نموذج لغة Mamba 2 يركز على توليد الشيفرة، ويوفر دعمًا قويًا لمهام الشيفرة المتقدمة والاستدلال."
  },
  "open-mistral-7b": {
    "description": "Mistral 7B هو نموذج مدمج ولكنه عالي الأداء، يتفوق في معالجة الدفعات والمهام البسيطة، مثل التصنيف وتوليد النصوص، ويتميز بقدرة استدلال جيدة."
  },
  "open-mistral-nemo": {
    "description": "Mistral Nemo هو نموذج 12B تم تطويره بالتعاون مع Nvidia، يوفر أداء استدلال وترميز ممتاز، سهل التكامل والاستبدال."
  },
  "open-mixtral-8x22b": {
    "description": "Mixtral 8x22B هو نموذج خبير أكبر، يركز على المهام المعقدة، ويوفر قدرة استدلال ممتازة وإنتاجية أعلى."
  },
  "open-mixtral-8x7b": {
    "description": "Mixtral 8x7B هو نموذج خبير نادر، يستخدم عدة معلمات لزيادة سرعة الاستدلال، مناسب لمعالجة المهام متعددة اللغات وتوليد الشيفرة."
  },
  "openai/gpt-4o": {
    "description": "ChatGPT-4o هو نموذج ديناميكي يتم تحديثه في الوقت الحقيقي للحفاظ على أحدث إصدار. يجمع بين فهم اللغة القوي وقدرة التوليد، مما يجعله مناسبًا لمجموعة واسعة من التطبيقات، بما في ذلك خدمة العملاء والتعليم والدعم الفني."
  },
  "openai/gpt-4o-mini": {
    "description": "GPT-4o mini هو أحدث نموذج من OpenAI تم إطلاقه بعد GPT-4 Omni، ويدعم إدخال النصوص والصور وإخراج النصوص. كأحد نماذجهم المتقدمة الصغيرة، فهو أرخص بكثير من النماذج الرائدة الأخرى في الآونة الأخيرة، وأرخص بأكثر من 60% من GPT-3.5 Turbo. يحتفظ بذكاء متقدم مع قيمة ممتازة. حصل GPT-4o mini على 82% في اختبار MMLU، وهو حاليًا يتفوق على GPT-4 في تفضيلات الدردشة."
  },
  "openai/o1": {
    "description": "o1 هو نموذج الاستدلال الجديد من OpenAI، يدعم إدخال النصوص والصور وإخراج النصوص، وهو مناسب للمهام المعقدة التي تتطلب معرفة عامة واسعة. يحتوي هذا النموذج على 200K من السياق وتاريخ انتهاء المعرفة في أكتوبر 2023."
  },
  "openai/o1-mini": {
    "description": "o1-mini هو نموذج استدلال سريع وفعال من حيث التكلفة مصمم لتطبيقات البرمجة والرياضيات والعلوم. يحتوي هذا النموذج على 128K من السياق وتاريخ انتهاء المعرفة في أكتوبر 2023."
  },
  "openai/o1-preview": {
    "description": "o1 هو نموذج استدلال جديد من OpenAI، مناسب للمهام المعقدة التي تتطلب معرفة عامة واسعة. يحتوي هذا النموذج على 128K من السياق وتاريخ انتهاء المعرفة في أكتوبر 2023."
  },
  "openchat/openchat-7b": {
    "description": "OpenChat 7B هو مكتبة نماذج لغوية مفتوحة المصدر تم تحسينها باستخدام استراتيجية \"C-RLFT (تعزيز التعلم الشرطي)\"."
  },
  "openrouter/auto": {
    "description": "استنادًا إلى طول السياق، والموضوع، والتعقيد، سيتم إرسال طلبك إلى Llama 3 70B Instruct، أو Claude 3.5 Sonnet (التعديل الذاتي) أو GPT-4o."
  },
  "phi3": {
    "description": "Phi-3 هو نموذج مفتوح خفيف الوزن أطلقته Microsoft، مناسب للتكامل الفعال واستدلال المعرفة على نطاق واسع."
  },
  "phi3:14b": {
    "description": "Phi-3 هو نموذج مفتوح خفيف الوزن أطلقته Microsoft، مناسب للتكامل الفعال واستدلال المعرفة على نطاق واسع."
  },
  "pixtral-12b-2409": {
    "description": "نموذج Pixtral يظهر قدرات قوية في فهم الرسوم البيانية والصور، والإجابة على الأسئلة المتعلقة بالمستندات، والاستدلال متعدد الوسائط، واتباع التعليمات، مع القدرة على إدخال الصور بدقة طبيعية ونسبة عرض إلى ارتفاع، بالإضافة إلى معالجة عدد غير محدود من الصور في نافذة سياق طويلة تصل إلى 128K توكن."
  },
  "pixtral-large-latest": {
    "description": "بيكسترا لارج هو نموذج متعدد الوسائط مفتوح المصدر يحتوي على 124 مليار معلمة، مبني على نموذج ميسترال لارج 2. هذا هو النموذج الثاني في عائلتنا متعددة الوسائط، ويظهر مستوى متقدم من القدرة على فهم الصور."
  },
  "pro-128k": {
    "description": "سبارك برو 128K مزود بقدرة معالجة سياق كبيرة جدًا، قادر على معالجة ما يصل إلى 128K من معلومات السياق، مما يجعله مناسبًا بشكل خاص للتحليل الشامل ومعالجة الروابط المنطقية طويلة الأمد في المحتوى الطويل، ويمكنه تقديم منطق سلس ومتسق ودعم متنوع للاقتباسات في الاتصالات النصية المعقدة."
  },
  "qwen-coder-plus-latest": {
    "description": "نموذج كود Qwen الشامل."
  },
  "qwen-coder-turbo-latest": {
    "description": "نموذج Qwen للبرمجة."
  },
  "qwen-long": {
    "description": "نموذج Qwen العملاق للغة، يدعم سياقات نصية طويلة، بالإضافة إلى وظائف الحوار المستندة إلى الوثائق الطويلة والعديد من الوثائق."
  },
  "qwen-math-plus-latest": {
    "description": "نموذج Qwen الرياضي مصمم خصيصًا لحل المسائل الرياضية."
  },
  "qwen-math-turbo-latest": {
    "description": "نموذج Qwen الرياضي مصمم خصيصًا لحل المسائل الرياضية."
  },
  "qwen-max": {
    "description": "نموذج لغة ضخم من توغي بمستوى مئات المليارات، يدعم إدخال لغات مختلفة مثل الصينية والإنجليزية. هو النموذج الذي يقف خلف إصدار توغي 2.5."
  },
  "qwen-max-latest": {
    "description": "نموذج لغة ضخم من Qwen بمستوى تريليونات، يدعم إدخال لغات مختلفة مثل الصينية والإنجليزية، وهو النموذج API وراء إصدار Qwen 2.5."
  },
  "qwen-plus": {
    "description": "نموذج لغة ضخم من توغي، نسخة معززة، يدعم إدخال لغات مختلفة مثل الصينية والإنجليزية."
  },
  "qwen-plus-latest": {
    "description": "نسخة محسنة من نموذج لغة Qwen الضخم، تدعم إدخال لغات مختلفة مثل الصينية والإنجليزية."
  },
  "qwen-turbo": {
    "description": "نموذج لغة ضخم من توغي، يدعم إدخال لغات مختلفة مثل الصينية والإنجليزية."
  },
  "qwen-turbo-latest": {
    "description": "نموذج لغة ضخم من Qwen، يدعم إدخال لغات مختلفة مثل الصينية والإنجليزية."
  },
  "qwen-vl-chat-v1": {
    "description": "نموذج Qwen العملاق للغة البصرية يدعم طرق تفاعل مرنة، بما في ذلك الصور المتعددة، والأسئلة والأجوبة المتعددة، والإبداع."
  },
  "qwen-vl-max-latest": {
    "description": "نموذج اللغة البصرية الكبير Qwen. مقارنةً بالنسخة المحسّنة، تعزز مرة أخرى من قدرة الاستدلال البصري وقدرة اتباع التعليمات، مما يوفر مستوى أعلى من الإدراك البصري والمعرفة."
  },
  "qwen-vl-plus-latest": {
    "description": "نسخة محسّنة من نموذج اللغة البصرية الكبير Qwen. تعزز بشكل كبير من قدرة التعرف على التفاصيل وقدرة التعرف على النصوص، وتدعم دقة تصل إلى أكثر من مليون بكسل وأبعاد صور بأي نسبة عرض إلى ارتفاع."
  },
  "qwen-vl-v1": {
    "description": "نموذج تم تدريبه باستخدام نموذج Qwen-7B اللغوي، مع إضافة نموذج الصور، بدقة إدخال الصور 448."
  },
  "qwen/qwen-2-7b-instruct:free": {
    "description": "Qwen2 هو سلسلة جديدة من نماذج اللغة الكبيرة، تتمتع بقدرات فهم وتوليد أقوى."
  },
  "qwen2": {
    "description": "Qwen2 هو نموذج لغوي كبير من الجيل الجديد من Alibaba، يدعم أداءً ممتازًا لتلبية احتياجات التطبيقات المتنوعة."
  },
  "qwen2.5": {
    "description": "Qwen2.5 هو الجيل الجديد من نماذج اللغة الكبيرة من Alibaba، يدعم احتياجات التطبيقات المتنوعة بأداء ممتاز."
  },
  "qwen2.5-14b-instruct": {
    "description": "نموذج Qwen 2.5 مفتوح المصدر بحجم 14B."
  },
  "qwen2.5-32b-instruct": {
    "description": "نموذج Qwen 2.5 مفتوح المصدر بحجم 32B."
  },
  "qwen2.5-72b-instruct": {
    "description": "نموذج Qwen 2.5 مفتوح المصدر بحجم 72B."
  },
  "qwen2.5-7b-instruct": {
    "description": "نموذج Qwen 2.5 مفتوح المصدر بحجم 7B."
  },
  "qwen2.5-coder-1.5b-instruct": {
    "description": "نموذج كود تونغي، النسخة مفتوحة المصدر."
  },
  "qwen2.5-coder-32b-instruct": {
    "description": "الإصدار المفتوح من نموذج كود Qwen الشامل."
  },
  "qwen2.5-coder-7b-instruct": {
    "description": "نسخة مفتوحة المصدر من نموذج Qwen للبرمجة."
  },
  "qwen2.5-math-1.5b-instruct": {
    "description": "نموذج Qwen-Math لديه قدرة قوية على حل المسائل الرياضية."
  },
  "qwen2.5-math-72b-instruct": {
    "description": "نموذج Qwen-Math يتمتع بقدرات قوية في حل المسائل الرياضية."
  },
  "qwen2.5-math-7b-instruct": {
    "description": "نموذج Qwen-Math يتمتع بقدرات قوية في حل المسائل الرياضية."
  },
  "qwen2.5:0.5b": {
    "description": "Qwen2.5 هو الجيل الجديد من نماذج اللغة الكبيرة من Alibaba، يدعم احتياجات التطبيقات المتنوعة بأداء ممتاز."
  },
  "qwen2.5:1.5b": {
    "description": "Qwen2.5 هو الجيل الجديد من نماذج اللغة الكبيرة من Alibaba، يدعم احتياجات التطبيقات المتنوعة بأداء ممتاز."
  },
  "qwen2.5:72b": {
    "description": "Qwen2.5 هو الجيل الجديد من نماذج اللغة الكبيرة من Alibaba، يدعم احتياجات التطبيقات المتنوعة بأداء ممتاز."
  },
  "qwen2:0.5b": {
    "description": "Qwen2 هو نموذج لغوي كبير من الجيل الجديد من Alibaba، يدعم أداءً ممتازًا لتلبية احتياجات التطبيقات المتنوعة."
  },
  "qwen2:1.5b": {
    "description": "Qwen2 هو نموذج لغوي كبير من الجيل الجديد من Alibaba، يدعم أداءً ممتازًا لتلبية احتياجات التطبيقات المتنوعة."
  },
  "qwen2:72b": {
    "description": "Qwen2 هو نموذج لغوي كبير من الجيل الجديد من Alibaba، يدعم أداءً ممتازًا لتلبية احتياجات التطبيقات المتنوعة."
  },
  "qwq": {
    "description": "QwQ هو نموذج بحث تجريبي يركز على تحسين قدرات الاستدلال للذكاء الاصطناعي."
  },
  "qwq-32b-preview": {
    "description": "نموذج QwQ هو نموذج بحث تجريبي تم تطويره بواسطة فريق Qwen، يركز على تعزيز قدرات الاستدلال للذكاء الاصطناعي."
  },
  "solar-1-mini-chat": {
    "description": "Solar Mini هو نموذج LLM مدمج، يتفوق على GPT-3.5، ويتميز بقدرات متعددة اللغات، ويدعم الإنجليزية والكورية، ويقدم حلولًا فعالة وصغيرة الحجم."
  },
  "solar-1-mini-chat-ja": {
    "description": "Solar Mini (Ja) يوسع قدرات Solar Mini، ويركز على اللغة اليابانية، مع الحفاظ على الكفاءة والأداء الممتاز في استخدام الإنجليزية والكورية."
  },
  "solar-pro": {
    "description": "Solar Pro هو نموذج LLM عالي الذكاء تم إطلاقه من قبل Upstage، يركز على قدرة اتباع التعليمات على وحدة معالجة الرسوميات الواحدة، وسجل IFEval فوق 80. حاليًا يدعم اللغة الإنجليزية، ومن المقرر إصدار النسخة الرسمية في نوفمبر 2024، مع توسيع دعم اللغات وطول السياق."
  },
  "step-1-128k": {
    "description": "يوفر توازنًا بين الأداء والتكلفة، مناسب لمجموعة متنوعة من السيناريوهات."
  },
  "step-1-256k": {
    "description": "يمتلك قدرة معالجة سياق طويلة جدًا، مناسب بشكل خاص لتحليل الوثائق الطويلة."
  },
  "step-1-32k": {
    "description": "يدعم حوارات متوسطة الطول، مناسب لمجموعة متنوعة من تطبيقات السيناريو."
  },
  "step-1-8k": {
    "description": "نموذج صغير، مناسب للمهام الخفيفة."
  },
  "step-1-flash": {
    "description": "نموذج عالي السرعة، مناسب للحوار في الوقت الحقيقي."
  },
  "step-1.5v-mini": {
    "description": "يمتلك هذا النموذج قدرة قوية على فهم الفيديو."
  },
  "step-1v-32k": {
    "description": "يدعم المدخلات البصرية، يعزز تجربة التفاعل متعدد الوسائط."
  },
  "step-1v-8k": {
    "description": "نموذج بصري صغير، مناسب للمهام الأساسية المتعلقة بالنصوص والصور."
  },
  "step-2-16k": {
    "description": "يدعم تفاعلات سياق كبيرة، مناسب لمشاهد الحوار المعقدة."
  },
  "taichu_llm": {
    "description": "نموذج اللغة الكبير TaiChu يتمتع بقدرات قوية في فهم اللغة، بالإضافة إلى إنشاء النصوص، والإجابة على الأسئلة، وبرمجة الأكواد، والحسابات الرياضية، والاستدلال المنطقي، وتحليل المشاعر، وتلخيص النصوص. يجمع بشكل مبتكر بين التدريب المسبق على البيانات الضخمة والمعرفة الغنية من مصادر متعددة، من خلال تحسين تقنيات الخوارزميات باستمرار واستيعاب المعرفة الجديدة من البيانات النصية الضخمة، مما يحقق تطورًا مستمرًا في أداء النموذج. يوفر للمستخدمين معلومات وخدمات أكثر سهولة وتجربة أكثر ذكاءً."
  },
  "togethercomputer/StripedHyena-Nous-7B": {
    "description": "StripedHyena Nous (7B) يوفر قدرة حسابية معززة من خلال استراتيجيات فعالة وهندسة نموذجية."
  },
  "upstage/SOLAR-10.7B-Instruct-v1.0": {
    "description": "Upstage SOLAR Instruct v1 (11B) مناسب لمهام التعليمات الدقيقة، يوفر قدرة معالجة لغوية ممتازة."
  },
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnet يرفع المعايير الصناعية، حيث يتفوق على نماذج المنافسين وClaude 3 Opus، ويظهر أداءً ممتازًا في تقييمات واسعة، مع سرعة وتكلفة تتناسب مع نماذجنا المتوسطة."
  },
  "wizardlm2": {
    "description": "WizardLM 2 هو نموذج لغوي تقدمه Microsoft AI، يتميز بأداء ممتاز في الحوار المعقد، واللغات المتعددة، والاستدلال، والمساعدين الذكيين."
  },
  "wizardlm2:8x22b": {
    "description": "WizardLM 2 هو نموذج لغوي تقدمه Microsoft AI، يتميز بأداء ممتاز في الحوار المعقد، واللغات المتعددة، والاستدلال، والمساعدين الذكيين."
  },
  "yi-large": {
    "description": "نموذج جديد بمليارات المعلمات، يوفر قدرة قوية على الإجابة وتوليد النصوص."
  },
  "yi-large-fc": {
    "description": "يدعم ويعزز قدرة استدعاء الأدوات على نموذج yi-large، مناسب لمجموعة متنوعة من سيناريوهات الأعمال التي تتطلب بناء وكيل أو سير عمل."
  },
  "yi-large-preview": {
    "description": "الإصدار الأولي، يوصى باستخدام yi-large (الإصدار الجديد)."
  },
  "yi-large-rag": {
    "description": "خدمة متقدمة تعتمد على نموذج yi-large القوي، تجمع بين تقنيات الاسترجاع والتوليد لتوفير إجابات دقيقة، وخدمة استرجاع المعلومات من الإنترنت في الوقت الحقيقي."
  },
  "yi-large-turbo": {
    "description": "عالية الكفاءة، أداء ممتاز. يتم ضبطها بدقة عالية لتحقيق توازن بين الأداء وسرعة الاستدلال والتكلفة."
  },
  "yi-lightning": {
    "description": "نموذج جديد عالي الأداء، يضمن إنتاج جودة عالية مع زيادة كبيرة في سرعة الاستدلال."
  },
  "yi-lightning-lite": {
    "description": "نسخة خفيفة الوزن، يُوصى باستخدام yi-lightning."
  },
  "yi-medium": {
    "description": "نموذج متوسط الحجم تم تحسينه، يتمتع بقدرات متوازنة، وكفاءة عالية في التكلفة. تم تحسين قدرة اتباع التعليمات بشكل عميق."
  },
  "yi-medium-200k": {
    "description": "نافذة سياق طويلة تصل إلى 200K، توفر قدرة عميقة على فهم وتوليد النصوص الطويلة."
  },
  "yi-spark": {
    "description": "نموذج صغير ولكنه قوي، خفيف وسريع. يوفر قدرة معززة على العمليات الرياضية وكتابة الشيفرات."
  },
  "yi-vision": {
    "description": "نموذج لمهام الرؤية المعقدة، يوفر قدرة عالية على فهم وتحليل الصور."
  }
}
