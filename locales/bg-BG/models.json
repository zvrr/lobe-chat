{
  "01-ai/Yi-1.5-34B-Chat-16K": {
    "description": "Yi-1.5 34B предлага отлични резултати в индустриалните приложения с богат набор от обучителни примери."
  },
  "01-ai/Yi-1.5-9B-Chat-16K": {
    "description": "Yi-1.5 9B поддържа 16K токена, предоставяйки ефективни и плавни способности за генериране на език."
  },
  "360gpt-pro": {
    "description": "360GPT Pro, като важен член на серията AI модели на 360, отговаря на разнообразни приложения на естествения език с ефективни способности за обработка на текст, поддържайки разбиране на дълги текстове и многостепенни диалози."
  },
  "360gpt-turbo": {
    "description": "360GPT Turbo предлага мощни изчислителни и диалогови способности, с отлична семантична разбираемост и ефективност на генериране, идеално решение за интелигентни асистенти за предприятия и разработчици."
  },
  "360gpt-turbo-responsibility-8k": {
    "description": "360GPT Turbo Responsibility 8K акцентира на семантичната безопасност и отговорността, проектиран специално за приложения с високи изисквания за безопасност на съдържанието, осигурявайки точност и стабилност на потребителското изживяване."
  },
  "360gpt2-pro": {
    "description": "360GPT2 Pro е усъвършенстван модел за обработка на естествен език, пуснат от компания 360, с изключителни способности за генериране и разбиране на текст, особено в областта на генерирането и творчеството, способен да обработва сложни езикови трансформации и ролеви игри."
  },
  "4.0Ultra": {
    "description": "Spark4.0 Ultra е най-мощната версия в серията Starfire, която подобрява разбирането и обобщаването на текстовото съдържание, докато надгражда свързаните търсения. Това е всестранно решение за повишаване на производителността в офиса и точно отговаряне на нуждите, водещо в индустрията интелигентно решение."
  },
  "@cf/meta/llama-3-8b-instruct-awq": {},
  "@cf/openchat/openchat-3.5-0106": {},
  "@cf/qwen/qwen1.5-14b-chat-awq": {},
  "@hf/google/gemma-7b-it": {},
  "@hf/meta-llama/meta-llama-3-8b-instruct": {
    "description": "Поколение след поколение, Meta Llama 3 демонстрира най-съвременна производителност в широк спектър от индустриални оценки и предлага нови възможности, включително подобрено разсъждение."
  },
  "@hf/mistral/mistral-7b-instruct-v0.2": {},
  "@hf/nexusflow/starling-lm-7b-beta": {},
  "@hf/nousresearch/hermes-2-pro-mistral-7b": {},
  "@hf/thebloke/deepseek-coder-6.7b-instruct-awq": {},
  "@hf/thebloke/neural-chat-7b-v3-1-awq": {},
  "@hf/thebloke/openhermes-2.5-mistral-7b-awq": {},
  "@hf/thebloke/zephyr-7b-beta-awq": {},
  "Baichuan2-Turbo": {
    "description": "Използва технологии за подобряване на търсенето, за да свърже голям модел с областни знания и знания от интернет. Поддържа качване на различни документи като PDF, Word и вход на уебсайтове, с бърз и цялостен достъп до информация, предоставяйки точни и професионални резултати."
  },
  "Baichuan3-Turbo": {
    "description": "Оптимизиран за често срещани корпоративни сценарии, с значително подобрени резултати и висока цена-качество. В сравнение с модела Baichuan2, генерирането на съдържание е увеличено с 20%, отговорите на знания с 17%, а способността за ролеви игри с 40%. Общите резултати са по-добри от тези на GPT3.5."
  },
  "Baichuan3-Turbo-128k": {
    "description": "С 128K свръхдълъг контекстен прозорец, оптимизиран за често срещани корпоративни сценарии, с значително подобрени резултати и висока цена-качество. В сравнение с модела Baichuan2, генерирането на съдържание е увеличено с 20%, отговорите на знания с 17%, а способността за ролеви игри с 40%. Общите резултати са по-добри от тези на GPT3.5."
  },
  "Baichuan4": {
    "description": "Моделът е с най-добри способности в страната, надминаващ чуждестранните водещи модели в задачи като енциклопедични знания, дълги текстове и генериране на съдържание. Също така притежава водещи в индустрията мултимодални способности и отлични резултати в множество авторитетни тестови стандарти."
  },
  "Baichuan4-Air": {
    "description": "Моделът е лидер в страната по способности, надминавайки чуждестранните основни модели в задачи на китайски език, като знания, дълги текстове и генериране на творби. Също така притежава водещи в индустрията мултимодални способности и отлични резултати в множество авторитетни оценки."
  },
  "Baichuan4-Turbo": {
    "description": "Моделът е лидер в страната по способности, надминавайки чуждестранните основни модели в задачи на китайски език, като знания, дълги текстове и генериране на творби. Също така притежава водещи в индустрията мултимодални способности и отлични резултати в множество авторитетни оценки."
  },
  "ERNIE-3.5-128K": {
    "description": "Флагманският модел на Baidu, разработен самостоятелно, е мащабен езиков модел, който обхваща огромно количество китайски и английски текстове. Той притежава мощни общи способности и може да отговори на почти всички изисквания за диалогови въпроси и отговори, генериране на съдържание и приложения с плъгини; поддържа автоматично свързване с плъгина за търсене на Baidu, осигурявайки актуалност на информацията за отговорите."
  },
  "ERNIE-3.5-8K": {
    "description": "Флагманският модел на Baidu, разработен самостоятелно, е мащабен езиков модел, който обхваща огромно количество китайски и английски текстове. Той притежава мощни общи способности и може да отговори на почти всички изисквания за диалогови въпроси и отговори, генериране на съдържание и приложения с плъгини; поддържа автоматично свързване с плъгина за търсене на Baidu, осигурявайки актуалност на информацията за отговорите."
  },
  "ERNIE-3.5-8K-Preview": {
    "description": "Флагманският модел на Baidu, разработен самостоятелно, е мащабен езиков модел, който обхваща огромно количество китайски и английски текстове. Той притежава мощни общи способности и може да отговори на почти всички изисквания за диалогови въпроси и отговори, генериране на съдържание и приложения с плъгини; поддържа автоматично свързване с плъгина за търсене на Baidu, осигурявайки актуалност на информацията за отговорите."
  },
  "ERNIE-4.0-8K-Latest": {
    "description": "Флагманският модел на Baidu за изключително големи езикови модели, разработен самостоятелно, е напълно обновен в сравнение с ERNIE 3.5 и е широко приложим в сложни задачи в различни области; поддържа автоматично свързване с плъгина за търсене на Baidu, осигурявайки актуалност на информацията за отговори."
  },
  "ERNIE-4.0-8K-Preview": {
    "description": "Флагманският модел на Baidu за изключително големи езикови модели, разработен самостоятелно, е напълно обновен в сравнение с ERNIE 3.5 и е широко приложим в сложни задачи в различни области; поддържа автоматично свързване с плъгина за търсене на Baidu, осигурявайки актуалност на информацията за отговори."
  },
  "ERNIE-4.0-Turbo-128K": {
    "description": "Флагманският модел на Baidu, изграден на собствена технология, с изключителни резултати и широко приложение в сложни задачи в различни области; поддържа автоматично свързване с плъгини за търсене на Baidu, осигурявайки актуалност на информацията за отговори. В сравнение с ERNIE 4.0, показва по-добра производителност."
  },
  "ERNIE-4.0-Turbo-8K-Latest": {
    "description": "Патентованият флагмански модул на Baidu, изключително мащабен езиков модел, показващ отлични резултати и широко приложение в сложни сценарии. Поддържа автоматично свързване с плъгини на Baidu Search, гарантирайки актуалността на информацията. В сравнение с ERNIE 4.0, той представя по-добри резултати."
  },
  "ERNIE-4.0-Turbo-8K-Preview": {
    "description": "Флагманският модел на Baidu за изключително големи езикови модели, разработен самостоятелно, показва отлични резултати и е широко приложим в сложни задачи в различни области; поддържа автоматично свързване с плъгина за търсене на Baidu, осигурявайки актуалност на информацията за отговори. В сравнение с ERNIE 4.0, представянето му е по-добро."
  },
  "ERNIE-Character-8K": {
    "description": "Специализиран модел на Baidu за големи езикови модели, разработен самостоятелно, подходящ за приложения като NPC в игри, клиентски разговори и ролеви игри, с по-изразителен и последователен стил на персонажите, по-силна способност за следване на инструкции и по-добра производителност при извеждане."
  },
  "ERNIE-Lite-Pro-128K": {
    "description": "Лек модел на Baidu за големи езикови модели, разработен самостоятелно, който съчетава отлични резултати с производителност при извеждане, с по-добри резултати в сравнение с ERNIE Lite, подходящ за използване с AI ускорителни карти с ниска изчислителна мощ."
  },
  "ERNIE-Speed-128K": {
    "description": "Най-новият модел на Baidu за големи езикови модели с висока производителност, разработен самостоятелно, с отлични общи способности, подходящ за основен модел за фина настройка, за по-добро справяне с конкретни проблеми, като същевременно предлага отлична производителност при извеждане."
  },
  "ERNIE-Speed-Pro-128K": {
    "description": "Най-новият модел на Baidu за големи езикови модели с висока производителност, разработен самостоятелно, с отлични общи способности, по-добри резултати в сравнение с ERNIE Speed, подходящ за основен модел за фина настройка, за по-добро справяне с конкретни проблеми, като същевременно предлага отлична производителност при извеждане."
  },
  "Gryphe/MythoMax-L2-13b": {
    "description": "MythoMax-L2 (13B) е иновативен модел, подходящ за приложения в множество области и сложни задачи."
  },
  "Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Hermes 2 Mixtral 8x7B DPO е високо гъвкава многомоделна комбинация, предназначена да предостави изключителен креативен опит."
  },
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) е модел с висока точност за инструкции, подходящ за сложни изчисления."
  },
  "NousResearch/Nous-Hermes-2-Yi-34B": {
    "description": "Nous Hermes-2 Yi (34B) предлага оптимизирани езикови изходи и разнообразни възможности за приложение."
  },
  "OpenGVLab/InternVL2-26B": {
    "description": "InternVL2 демонстрира изключителни резултати в различни визуално-языкови задачи, включително разбиране на документи и графики, разбиране на текст в сцени, OCR, решаване на научни и математически проблеми."
  },
  "OpenGVLab/InternVL2-Llama3-76B": {
    "description": "InternVL2 демонстрира изключителни резултати в различни визуално-языкови задачи, включително разбиране на документи и графики, разбиране на текст в сцени, OCR, решаване на научни и математически проблеми."
  },
  "Phi-3-medium-128k-instruct": {
    "description": "Същият модел Phi-3-medium, но с по-голям размер на контекста за RAG или малко подканване."
  },
  "Phi-3-medium-4k-instruct": {
    "description": "Модел с 14B параметри, предлагащ по-добро качество от Phi-3-mini, с акцент върху висококачествени, плътни на разсъждения данни."
  },
  "Phi-3-mini-128k-instruct": {
    "description": "Същият модел Phi-3-mini, но с по-голям размер на контекста за RAG или малко подканване."
  },
  "Phi-3-mini-4k-instruct": {
    "description": "Най-малкият член на семейството Phi-3. Оптимизиран както за качество, така и за ниска латентност."
  },
  "Phi-3-small-128k-instruct": {
    "description": "Същият модел Phi-3-small, но с по-голям размер на контекста за RAG или малко подканване."
  },
  "Phi-3-small-8k-instruct": {
    "description": "Модел с 7B параметри, предлагащ по-добро качество от Phi-3-mini, с акцент върху висококачествени, плътни на разсъждения данни."
  },
  "Phi-3.5-mini-instruct": {
    "description": "Актуализирана версия на модела Phi-3-mini."
  },
  "Phi-3.5-vision-instrust": {
    "description": "Актуализирана версия на модела Phi-3-vision."
  },
  "Pro/OpenGVLab/InternVL2-8B": {
    "description": "InternVL2 демонстрира изключителни резултати в различни визуално-языкови задачи, включително разбиране на документи и графики, разбиране на текст в сцени, OCR, решаване на научни и математически проблеми."
  },
  "Pro/Qwen/Qwen2-VL-7B-Instruct": {
    "description": "Qwen2-VL е най-новата итерация на модела Qwen-VL, който е постигнал водещи резултати в тестовете за визуално разбиране."
  },
  "Qwen/Qwen1.5-110B-Chat": {
    "description": "Като тестова версия на Qwen2, Qwen1.5 използва големи данни за постигане на по-точни диалогови функции."
  },
  "Qwen/Qwen1.5-72B-Chat": {
    "description": "Qwen 1.5 Chat (72B) предлага бързи отговори и естествени диалогови способности, подходящи за многоезични среди."
  },
  "Qwen/Qwen2-72B-Instruct": {
    "description": "Qwen2 е напреднал универсален езиков модел, поддържащ множество типове инструкции."
  },
  "Qwen/Qwen2-VL-72B-Instruct": {
    "description": "Qwen2-VL е най-новата итерация на модела Qwen-VL, който е постигнал водещи резултати в тестовете за визуално разбиране."
  },
  "Qwen/Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5 е нова серия от големи езикови модели, проектирана да оптимизира обработката на инструкции."
  },
  "Qwen/Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5 е нова серия от големи езикови модели, проектирана да оптимизира обработката на инструкции."
  },
  "Qwen/Qwen2.5-72B-Instruct": {
    "description": "Голям езиков модел, разработен от екипа на Alibaba Cloud Tongyi Qianwen"
  },
  "Qwen/Qwen2.5-72B-Instruct-128K": {
    "description": "Qwen2.5 е нова серия от големи езикови модели с по-силни способности за разбиране и генериране."
  },
  "Qwen/Qwen2.5-72B-Instruct-Turbo": {
    "description": "Qwen2.5 е нова серия от големи езикови модели, проектирана да оптимизира обработката на инструкти."
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5 е нова серия от големи езикови модели, проектирана да оптимизира обработката на инструкции."
  },
  "Qwen/Qwen2.5-7B-Instruct-Turbo": {
    "description": "Qwen2.5 е нова серия от големи езикови модели, проектирана да оптимизира обработката на инструкти."
  },
  "Qwen/Qwen2.5-Coder-32B-Instruct": {
    "description": "Qwen2.5-Coder се фокусира върху писането на код."
  },
  "Qwen/Qwen2.5-Math-72B-Instruct": {
    "description": "Qwen2.5-Math се фокусира върху решаването на математически проблеми, предоставяйки професионални отговори на трудни задачи."
  },
  "SenseChat": {
    "description": "Основна версия на модела (V4), с контекстна дължина 4K, с мощни общи способности."
  },
  "SenseChat-128K": {
    "description": "Основна версия на модела (V4), с контекстна дължина 128K, показваща отлични резултати в задачи за разбиране и генериране на дълги текстове."
  },
  "SenseChat-32K": {
    "description": "Основна версия на модела (V4), с контекстна дължина 32K, гъвкаво приложима в различни сцени."
  },
  "SenseChat-5": {
    "description": "Най-новата версия на модела (V5.5), с контекстна дължина 128K, значително подобрена способност в области като математическо разсъждение, английски разговори, следване на инструкции и разбиране на дълги текстове, сравнима с GPT-4o."
  },
  "SenseChat-5-Cantonese": {
    "description": "С контекстна дължина 32K, надминава GPT-4 в разбирането на разговори на кантонски, сравним с GPT-4 Turbo в множество области като знания, разсъждение, математика и писане на код."
  },
  "SenseChat-Character": {
    "description": "Стандартна версия на модела, с контекстна дължина 8K, с висока скорост на отговор."
  },
  "SenseChat-Character-Pro": {
    "description": "Премиум версия на модела, с контекстна дължина 32K, с напълно подобрени способности, поддържаща разговори на китайски/английски."
  },
  "SenseChat-Turbo": {
    "description": "Подходящ за бързи въпроси и отговори, сцени на фино настройване на модела."
  },
  "THUDM/glm-4-9b-chat": {
    "description": "GLM-4 9B е отворен код версия, предоставяща оптимизирано изживяване в разговорните приложения."
  },
  "Tencent/Hunyuan-A52B-Instruct": {
    "description": "Hunyuan-Large е най-голямата отворена трансформаторна архитектура MoE в индустрията, с общо 3890 милиарда параметри и 52 милиарда активни параметри."
  },
  "abab5.5-chat": {
    "description": "Насочена към производствени сценарии, поддържаща обработка на сложни задачи и ефективно генериране на текст, подходяща за професионални приложения."
  },
  "abab5.5s-chat": {
    "description": "Специално проектирана за диалогови сценарии на китайски, предлагаща висококачествено генериране на диалози на китайски, подходяща за множество приложения."
  },
  "abab6.5g-chat": {
    "description": "Специално проектирана за многоезични диалогови системи, поддържаща висококачествено генериране на диалози на английски и много други езици."
  },
  "abab6.5s-chat": {
    "description": "Подходяща за широк спектър от задачи за обработка на естествен език, включително генериране на текст, диалогови системи и др."
  },
  "abab6.5t-chat": {
    "description": "Оптимизирана за диалогови сценарии на китайски, предлагаща плавно и съответстващо на китайските изразни навици генериране на диалози."
  },
  "accounts/fireworks/models/firefunction-v1": {
    "description": "Fireworks отворен модел за извикване на функции, предлагащ отлични способности за изпълнение на инструкции и отворени, персонализируеми характеристики."
  },
  "accounts/fireworks/models/firefunction-v2": {
    "description": "Fireworks компанията представя Firefunction-v2, модел за извикване на функции с изключителна производителност, разработен на базата на Llama-3 и оптимизиран за функции, диалози и следване на инструкции."
  },
  "accounts/fireworks/models/firellava-13b": {
    "description": "fireworks-ai/FireLLaVA-13b е визуален езиков модел, който може да приема изображения и текстови входове, обучен с висококачествени данни, подходящ за мултимодални задачи."
  },
  "accounts/fireworks/models/llama-v3-70b-instruct": {
    "description": "Llama 3 70B модел за инструкции, специално оптимизиран за многоезични диалози и разбиране на естествен език, с производителност, превъзхождаща повечето конкурентни модели."
  },
  "accounts/fireworks/models/llama-v3-70b-instruct-hf": {
    "description": "Llama 3 70B модел за инструкции (HF версия), с резултати, съвпадащи с официалната реализация, подходящ за висококачествени задачи за следване на инструкции."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct": {
    "description": "Llama 3 8B модел за инструкции, оптимизиран за диалози и многоезични задачи, с изключителна производителност и ефективност."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct-hf": {
    "description": "Llama 3 8B модел за инструкции (HF версия), с резултати, съвпадащи с официалната реализация, предлагаща висока последователност и съвместимост между платформите."
  },
  "accounts/fireworks/models/llama-v3p1-405b-instruct": {
    "description": "Llama 3.1 405B модел за инструкции, с огромен брой параметри, подходящ за сложни задачи и следване на инструкции в сценарии с високо натоварване."
  },
  "accounts/fireworks/models/llama-v3p1-70b-instruct": {
    "description": "Llama 3.1 70B модел за инструкции, предлагащ изключителни способности за разбиране и генериране на естествен език, идеален за диалогови и аналитични задачи."
  },
  "accounts/fireworks/models/llama-v3p1-8b-instruct": {
    "description": "Llama 3.1 8B модел за инструкции, оптимизиран за многоезични диалози, способен да надмине повечето отворени и затворени модели на общи индустриални стандарти."
  },
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
    "description": "Моделът за разсъждение по изображения с 11B параметри на Meta е оптимизиран за визуално разпознаване, разсъждение по изображения, описание на изображения и отговаряне на общи въпроси относно изображения. Моделът може да разбира визуални данни, като графики и таблици, и свързва визуалните данни с текстовите описания на детайлите на изображенията."
  },
  "accounts/fireworks/models/llama-v3p2-1b-instruct": {
    "description": "Моделът Llama 3.2 1B е лека многоезична разработка от Meta. Този модел е проектиран да подобри ефективността, предоставяйки значителни подобрения в забавянето и разходите в сравнение с по-големи модели. Примерни случаи на ползване включват извличане и обобщение."
  },
  "accounts/fireworks/models/llama-v3p2-3b-instruct": {
    "description": "Моделът Llama 3.2 3B е лека многоезична разработка от Meta. Този модел е проектиран да подобри ефективността, предоставяйки значителни подобрения в забавянето и разходите в сравнение с по-големи модели. Примерни случаи на ползване включват заявки, пренаписване на подканвания и подпомагане на писането."
  },
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
    "description": "Моделът за разсъждение по изображения с 90B параметри на Meta е оптимизиран за визуално разпознаване, разсъждение по изображения, описание на изображения и отговаряне на общи въпроси относно изображения. Моделът може да разбира визуални данни, като графики и таблици, и свързва визуалните данни с текстовите описания на детайлите на изображенията."
  },
  "accounts/fireworks/models/mixtral-8x22b-instruct": {
    "description": "Mixtral MoE 8x22B модел за инструкции, с голям брой параметри и архитектура с множество експерти, осигуряваща всестранна поддръжка за ефективна обработка на сложни задачи."
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct": {
    "description": "Mixtral MoE 8x7B модел за инструкции, архитектура с множество експерти, предлагаща ефективно следване и изпълнение на инструкции."
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
    "description": "Mixtral MoE 8x7B модел за инструкции (HF версия), с производителност, съвпадаща с официалната реализация, подходящ за множество ефективни сценарии."
  },
  "accounts/fireworks/models/mythomax-l2-13b": {
    "description": "MythoMax L2 13B модел, комбиниращ новаторски технологии за интеграция, специализиран в разказване на истории и ролеви игри."
  },
  "accounts/fireworks/models/phi-3-vision-128k-instruct": {
    "description": "Phi 3 Vision модел за инструкции, лек мултимодален модел, способен да обработва сложна визуална и текстова информация, с високи способности за разсъждение."
  },
  "accounts/fireworks/models/qwen2p5-72b-instruct": {
    "description": "Qwen2.5 е серия от езикови модели, разработени от екипа на Alibaba Cloud Qwen, които съдържат само декодери. Тези модели предлагат различни размери, включително 0.5B, 1.5B, 3B, 7B, 14B, 32B и 72B, и разполагат с базови (base) и инструкти (instruct) варианти."
  },
  "accounts/fireworks/models/starcoder-16b": {
    "description": "StarCoder 15.5B модел, поддържащ напреднали програмни задачи, с подобрени многоезични способности, подходящ за сложна генерация и разбиране на код."
  },
  "accounts/fireworks/models/starcoder-7b": {
    "description": "StarCoder 7B модел, обучен за над 80 програмни езика, с отлични способности за попълване на код и разбиране на контекста."
  },
  "accounts/yi-01-ai/models/yi-large": {
    "description": "Yi-Large модел, предлагащ изключителни способности за многоезична обработка, подходящ за различни задачи по генериране и разбиране на език."
  },
  "ai21-jamba-1.5-large": {
    "description": "Многоезичен модел с 398B параметри (94B активни), предлагащ контекстен прозорец с дължина 256K, извикване на функции, структурирани изходи и генериране на основа."
  },
  "ai21-jamba-1.5-mini": {
    "description": "Многоезичен модел с 52B параметри (12B активни), предлагащ контекстен прозорец с дължина 256K, извикване на функции, структурирани изходи и генериране на основа."
  },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "description": "Claude 3.5 Sonnet повишава индустриалните стандарти, с производителност, надвишаваща конкурентните модели и Claude 3 Opus, с отлични резултати в широки оценки, като същевременно предлага скорост и разходи на нашите модели от средно ниво."
  },
  "anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnet повишава индустриалните стандарти, с производителност, надминаваща конкурентните модели и Claude 3 Opus, показвайки отлични резултати в широки оценки, като същевременно предлага скорост и разходи, характерни за нашите модели от среден клас."
  },
  "anthropic.claude-3-haiku-20240307-v1:0": {
    "description": "Claude 3 Haiku е най-бързият и компактен модел на Anthropic, предлагащ почти мигновена скорост на отговор. Той може бързо да отговаря на прости запитвания и заявки. Клиентите ще могат да изградят безпроблемно AI изживяване, имитиращо човешко взаимодействие. Claude 3 Haiku може да обработва изображения и да връща текстови изходи, с контекстуален прозорец от 200K."
  },
  "anthropic.claude-3-opus-20240229-v1:0": {
    "description": "Claude 3 Opus е най-мощният AI модел на Anthropic, с най-съвременна производителност при високо сложни задачи. Той може да обработва отворени подсказки и непознати сценарии, с отлична плавност и човешко разбиране. Claude 3 Opus демонстрира предимствата на генериращия AI. Claude 3 Opus може да обработва изображения и да връща текстови изходи, с контекстуален прозорец от 200K."
  },
  "anthropic.claude-3-sonnet-20240229-v1:0": {
    "description": "Claude 3 Sonnet на Anthropic постига идеален баланс между интелигентност и скорост - особено подходящ за корпоративни работни натоварвания. Той предлага максимална полезност на цена под конкурентите и е проектиран да бъде надежден и издръжлив основен модел, подходящ за мащабируеми AI внедрения. Claude 3 Sonnet може да обработва изображения и да връща текстови изходи, с контекстуален прозорец от 200K."
  },
  "anthropic.claude-instant-v1": {
    "description": "Бърз, икономичен и все пак много способен модел, който може да обработва редица задачи, включително ежедневни разговори, текстов анализ, обобщение и въпроси и отговори на документи."
  },
  "anthropic.claude-v2": {
    "description": "Anthropic демонстрира висока способност в широк спектър от задачи, от сложни разговори и генериране на креативно съдържание до следване на подробни инструкции."
  },
  "anthropic.claude-v2:1": {
    "description": "Актуализирана версия на Claude 2, с двойно по-голям контекстуален прозорец и подобрения в надеждността, процента на халюцинации и точността, основана на доказателства, в контексти с дълги документи и RAG."
  },
  "anthropic/claude-3-haiku": {
    "description": "Claude 3 Haiku е най-бързият и компактен модел на Anthropic, проектиран за почти мигновени отговори. Той предлага бърза и точна насочена производителност."
  },
  "anthropic/claude-3-opus": {
    "description": "Claude 3 Opus е най-мощният модел на Anthropic, предназначен за обработка на изключително сложни задачи. Той се отличава с изключителна производителност, интелигентност, гладкост и разбиране."
  },
  "anthropic/claude-3.5-sonnet": {
    "description": "Claude 3.5 Sonnet предлага способности, надхвърлящи Opus, и по-бърза скорост в сравнение с Sonnet, като същевременно запазва същата цена. Sonnet е особено силен в програмирането, науката за данни, визуалната обработка и агентските задачи."
  },
  "aya": {
    "description": "Aya 23 е многозначен модел, представен от Cohere, поддържащ 23 езика, предоставяйки удобство за многоезични приложения."
  },
  "aya:35b": {
    "description": "Aya 23 е многозначен модел, представен от Cohere, поддържащ 23 езика, предоставяйки удобство за многоезични приложения."
  },
  "charglm-3": {
    "description": "CharGLM-3 е проектиран за ролеви игри и емоционално придружаване, поддържаща дълга многократна памет и персонализиран диалог, с широко приложение."
  },
  "chatgpt-4o-latest": {
    "description": "ChatGPT-4o е динамичен модел, който се актуализира в реално време, за да поддържа най-новата версия. Той комбинира мощно разбиране на езика и генериране на текст, подходящ за мащабни приложения, включително обслужване на клиенти, образование и техническа поддръжка."
  },
  "claude-2.0": {
    "description": "Claude 2 предлага напредък в ключовите способности за бизнеса, включително водещи в индустрията 200K токена контекст, значително намаляване на честотата на илюзии на модела, системни подсказки и нова тестова функция: извикване на инструменти."
  },
  "claude-2.1": {
    "description": "Claude 2 предлага напредък в ключовите способности за бизнеса, включително водещи в индустрията 200K токена контекст, значително намаляване на честотата на илюзии на модела, системни подсказки и нова тестова функция: извикване на инструменти."
  },
  "claude-3-5-haiku-20241022": {
    "description": "Claude 3.5 Haiku е най-бързият следващ модел на Anthropic. В сравнение с Claude 3 Haiku, Claude 3.5 Haiku е подобрен във всички умения и надминава предишния най-голям модел Claude 3 Opus в много интелектуални тестове."
  },
  "claude-3-5-sonnet-20240620": {
    "description": "Claude 3.5 Sonnet предлага способности, надминаващи Opus и по-бърза скорост от Sonnet, като същевременно поддържа същата цена. Sonnet е особено силен в програмирането, науката за данни, визуалната обработка и задачи с агенти."
  },
  "claude-3-5-sonnet-20241022": {
    "description": "Claude 3.5 Sonnet предлага възможности, които надминават Opus и скорости, които са по-бързи от Sonnet, като същевременно поддържа същата цена като Sonnet. Sonnet е специално силен в програмирането, науката за данни, визуалната обработка и задачи, свързани с代理."
  },
  "claude-3-haiku-20240307": {
    "description": "Claude 3 Haiku е най-бързият и компактен модел на Anthropic, проектиран за почти мигновени отговори. Той предлага бърза и точна насочена производителност."
  },
  "claude-3-opus-20240229": {
    "description": "Claude 3 Opus е най-мощният модел на Anthropic за обработка на високо сложни задачи. Той показва изключителна производителност, интелигентност, гладкост и разбиране."
  },
  "claude-3-sonnet-20240229": {
    "description": "Claude 3 Sonnet предлага идеален баланс между интелигентност и скорост за корпоративни работни натоварвания. Той предлага максимална полезност на по-ниска цена, надежден и подходящ за мащабно внедряване."
  },
  "codegeex-4": {
    "description": "CodeGeeX-4 е мощен AI помощник за програмиране, който поддържа интелигентни въпроси и отговори и автоматично допълване на код за различни програмни езици, повишавайки ефективността на разработката."
  },
  "codegemma": {
    "description": "CodeGemma е лек езиков модел, специализиран в различни програмни задачи, поддържащ бърза итерация и интеграция."
  },
  "codegemma:2b": {
    "description": "CodeGemma е лек езиков модел, специализиран в различни програмни задачи, поддържащ бърза итерация и интеграция."
  },
  "codellama": {
    "description": "Code Llama е LLM, фокусиран върху генерирането и обсъждането на код, комбиниращ широк спектър от поддръжка на програмни езици, подходящ за среда на разработчици."
  },
  "codellama:13b": {
    "description": "Code Llama е LLM, фокусиран върху генерирането и обсъждането на код, комбиниращ широк спектър от поддръжка на програмни езици, подходящ за среда на разработчици."
  },
  "codellama:34b": {
    "description": "Code Llama е LLM, фокусиран върху генерирането и обсъждането на код, комбиниращ широк спектър от поддръжка на програмни езици, подходящ за среда на разработчици."
  },
  "codellama:70b": {
    "description": "Code Llama е LLM, фокусиран върху генерирането и обсъждането на код, комбиниращ широк спектър от поддръжка на програмни езици, подходящ за среда на разработчици."
  },
  "codeqwen": {
    "description": "CodeQwen1.5 е голям езиков модел, обучен на основата на обширни кодови данни, специално проектиран за решаване на сложни програмни задачи."
  },
  "codestral": {
    "description": "Codestral е първият кодов модел на Mistral AI, предоставящ отлична поддръжка за задачи по генериране на код."
  },
  "codestral-latest": {
    "description": "Codestral е авангарден генеративен модел, фокусиран върху генерирането на код, оптимизиран за междинно попълване и задачи за допълване на код."
  },
  "cognitivecomputations/dolphin-mixtral-8x22b": {
    "description": "Dolphin Mixtral 8x22B е модел, проектиран за следване на инструкции, диалози и програмиране."
  },
  "cohere-command-r": {
    "description": "Command R е мащабируем генеративен модел, насочен към RAG и използване на инструменти, за да позволи AI на производствено ниво за предприятия."
  },
  "cohere-command-r-plus": {
    "description": "Command R+ е модел, оптимизиран за RAG, проектиран да се справя с натоварвания на ниво предприятие."
  },
  "command-r": {
    "description": "Command R е LLM, оптимизиран за диалогови и дълги контекстуални задачи, особено подходящ за динамично взаимодействие и управление на знания."
  },
  "command-r-plus": {
    "description": "Command R+ е високопроизводителен голям езиков модел, проектиран за реални бизнес сценарии и сложни приложения."
  },
  "databricks/dbrx-instruct": {
    "description": "DBRX Instruct предлага висока надеждност в обработката на инструкции, поддържаща приложения в множество индустрии."
  },
  "deepseek-ai/DeepSeek-V2.5": {
    "description": "DeepSeek V2.5 обединява отличителните характеристики на предишните версии, подобрявайки общите и кодиращите способности."
  },
  "deepseek-ai/deepseek-llm-67b-chat": {
    "description": "DeepSeek 67B е напреднал модел, обучен за диалози с висока сложност."
  },
  "deepseek-chat": {
    "description": "Новооткритият отворен модел, който съчетава общи и кодови способности, не само запазва общата диалогова способност на оригиналния Chat модел и мощната способност за обработка на код на Coder модела, но също така по-добре се съгласува с човешките предпочитания. Освен това, DeepSeek-V2.5 постигна значителни подобрения в писателските задачи, следването на инструкции и много други области."
  },
  "deepseek-coder-v2": {
    "description": "DeepSeek Coder V2 е отворен хибриден експертен кодов модел, който се представя отлично в кодовите задачи, сравним с GPT4-Turbo."
  },
  "deepseek-coder-v2:236b": {
    "description": "DeepSeek Coder V2 е отворен хибриден експертен кодов модел, който се представя отлично в кодовите задачи, сравним с GPT4-Turbo."
  },
  "deepseek-v2": {
    "description": "DeepSeek V2 е ефективен модел на Mixture-of-Experts, подходящ за икономически ефективни нужди от обработка."
  },
  "deepseek-v2:236b": {
    "description": "DeepSeek V2 236B е кодовият модел на DeepSeek, предоставящ мощни способности за генериране на код."
  },
  "deepseek/deepseek-chat": {
    "description": "Новооткритият отворен модел, който съчетава общи и кодови способности, не само запазва общата диалогова способност на оригиналния Chat модел и мощната способност за обработка на код на Coder модела, но също така по-добре се съобразява с човешките предпочитания. Освен това, DeepSeek-V2.5 постигна значителни подобрения в задачи по писане, следване на инструкции и много други."
  },
  "emohaa": {
    "description": "Emohaa е психологически модел с професионални консултантски способности, помагащ на потребителите да разберат емоционалните проблеми."
  },
  "gemini-1.0-pro-001": {
    "description": "Gemini 1.0 Pro 001 (Тунинг) предлага стабилна и настройваема производителност, идеален избор за решения на сложни задачи."
  },
  "gemini-1.0-pro-002": {
    "description": "Gemini 1.0 Pro 002 (Тунинг) предлага отлична поддръжка на многомодални данни, фокусирайки се върху ефективното решаване на сложни задачи."
  },
  "gemini-1.0-pro-latest": {
    "description": "Gemini 1.0 Pro е високопроизводителен AI модел на Google, проектиран за разширяване на широк спектър от задачи."
  },
  "gemini-1.5-flash-001": {
    "description": "Gemini 1.5 Flash 001 е ефективен многомодален модел, който поддържа разширяване на широк спектър от приложения."
  },
  "gemini-1.5-flash-002": {
    "description": "Gemini 1.5 Flash 002 е ефективен мултимодален модел, който поддържа разширения за широко приложение."
  },
  "gemini-1.5-flash-8b": {
    "description": "Gemini 1.5 Flash 8B е ефективен многомодален модел, който поддържа разширения за широко приложение."
  },
  "gemini-1.5-flash-8b-exp-0924": {
    "description": "Gemini 1.5 Flash 8B 0924 е най-новият експериментален модел, който показва значителни подобрения в производителността както в текстови, така и в мултимодални приложения."
  },
  "gemini-1.5-flash-latest": {
    "description": "Gemini 1.5 Flash е най-новият многомодален AI модел на Google, който предлага бърза обработка и поддържа текстови, изображенчески и видео входове, подходящ за ефективно разширяване на множество задачи."
  },
  "gemini-1.5-pro-001": {
    "description": "Gemini 1.5 Pro 001 е разширяемо многомодално AI решение, което поддържа широк спектър от сложни задачи."
  },
  "gemini-1.5-pro-002": {
    "description": "Gemini 1.5 Pro 002 е най-новият модел, готов за производство, който предлага по-високо качество на изхода, особено в математически, дълги контексти и визуални задачи."
  },
  "gemini-1.5-pro-latest": {
    "description": "Gemini 1.5 Pro поддържа до 2 милиона токена и е идеален избор за среден многомодален модел, подходящ за многостранна поддръжка на сложни задачи."
  },
  "gemini-exp-1114": {
    "description": "Gemini Exp 1114 е най-новият експериментален многомодален AI модел на Google, който предлага бърза обработка и поддържа вход от текст, изображения и видео, подходящ за ефективно разширение на множество задачи."
  },
  "gemma-7b-it": {
    "description": "Gemma 7B е подходяща за обработка на средни и малки задачи, съчетаваща икономичност."
  },
  "gemma2": {
    "description": "Gemma 2 е ефективен модел, представен от Google, обхващащ множество приложения от малки до сложни обработки на данни."
  },
  "gemma2-9b-it": {
    "description": "Gemma 2 9B е модел, оптимизиран за специфични задачи и интеграция на инструменти."
  },
  "gemma2:27b": {
    "description": "Gemma 2 е ефективен модел, представен от Google, обхващащ множество приложения от малки до сложни обработки на данни."
  },
  "gemma2:2b": {
    "description": "Gemma 2 е ефективен модел, представен от Google, обхващащ множество приложения от малки до сложни обработки на данни."
  },
  "generalv3": {
    "description": "Spark Pro е високопроизводителен голям езиков модел, оптимизиран за професионални области, фокусирайки се върху математика, програмиране, медицина, образование и др., и поддържа свързано търсене и вградени плъгини за времето, датата и др. Оптимизираният модел показва отлични резултати и висока производителност в сложни отговори на знания, разбиране на езика и високо ниво на текстово генериране, което го прави идеален избор за професионални приложения."
  },
  "generalv3.5": {
    "description": "Spark3.5 Max е най-пълната версия, поддържаща свързано търсене и множество вградени плъгини. Неговите напълно оптимизирани основни способности, системни роли и функции за извикване на функции осигуряват изключителни резултати в различни сложни приложения."
  },
  "glm-4": {
    "description": "GLM-4 е старата флагманска версия, пусната през януари 2024 г., която в момента е заменена от по-силната GLM-4-0520."
  },
  "glm-4-0520": {
    "description": "GLM-4-0520 е най-новата версия на модела, проектирана за високо сложни и разнообразни задачи, с отлични резултати."
  },
  "glm-4-air": {
    "description": "GLM-4-Air е икономичен вариант, с производителност близка до GLM-4, предлагаща бързина и достъпна цена."
  },
  "glm-4-airx": {
    "description": "GLM-4-AirX предлага ефективна версия на GLM-4-Air, с скорост на извеждане до 2.6 пъти."
  },
  "glm-4-alltools": {
    "description": "GLM-4-AllTools е многофункционален интелигентен модел, оптимизиран за поддръжка на сложни инструкции и извиквания на инструменти, като уеб браузинг, обяснение на код и генериране на текст, подходящ за изпълнение на множество задачи."
  },
  "glm-4-flash": {
    "description": "GLM-4-Flash е идеалният избор за обработка на прости задачи, с най-бърза скорост и най-добра цена."
  },
  "glm-4-flashx": {
    "description": "GLM-4-FlashX е подобрена версия на Flash с изключително бърза скорост на извеждане."
  },
  "glm-4-long": {
    "description": "GLM-4-Long поддържа извеждане на много дълги текстове, подходящ за задачи, свързани с памет и обработка на големи документи."
  },
  "glm-4-plus": {
    "description": "GLM-4-Plus, като флагман с висока интелигентност, разполага с мощни способности за обработка на дълги текстове и сложни задачи, с цялостно подобрена производителност."
  },
  "glm-4v": {
    "description": "GLM-4V предлага мощни способности за разбиране и разсъждение на изображения, поддържаща множество визуални задачи."
  },
  "glm-4v-plus": {
    "description": "GLM-4V-Plus разполага с разбиране на видео съдържание и множество изображения, подходящ за мултимодални задачи."
  },
  "google/gemini-flash-1.5": {
    "description": "Gemini 1.5 Flash предлага оптимизирани мултимодални обработващи способности, подходящи за различни сложни задачи."
  },
  "google/gemini-pro-1.5": {
    "description": "Gemini 1.5 Pro комбинира най-новите оптимизационни технологии, предоставяйки по-ефективна обработка на мултимодални данни."
  },
  "google/gemma-2-27b-it": {
    "description": "Gemma 2 продължава концепцията за лекота и ефективност."
  },
  "google/gemma-2-2b-it": {
    "description": "Лек модел за настройка на инструкции от Google."
  },
  "google/gemma-2-9b-it": {
    "description": "Gemma 2 е серия от леки отворени текстови модели на Google."
  },
  "google/gemma-2-9b-it:free": {
    "description": "Gemma 2 е лека отворена текстова моделна серия на Google."
  },
  "google/gemma-2b-it": {
    "description": "Gemma Instruct (2B) предлага основни способности за обработка на инструкции, подходящи за леки приложения."
  },
  "gpt-3.5-turbo": {
    "description": "GPT 3.5 Turbo, подходящ за различни задачи по генериране и разбиране на текст, в момента сочи към gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-0125": {
    "description": "GPT 3.5 Turbo, подходящ за различни задачи по генериране и разбиране на текст, в момента сочи към gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-1106": {
    "description": "GPT 3.5 Turbo, подходящ за различни задачи по генериране и разбиране на текст, в момента сочи към gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-instruct": {
    "description": "GPT 3.5 Turbo, подходящ за различни задачи по генериране и разбиране на текст, в момента сочи към gpt-3.5-turbo-0125."
  },
  "gpt-4": {
    "description": "GPT-4 предлага по-голям контекстуален прозорец, способен да обработва по-дълги текстови входове, подходящ за сценарии, изискващи интеграция на обширна информация и анализ на данни."
  },
  "gpt-4-0125-preview": {
    "description": "Най-новият модел GPT-4 Turbo разполага с визуални функции. Сега визуалните заявки могат да се използват с JSON формат и извиквания на функции. GPT-4 Turbo е подобрена версия, която предлага икономически ефективна поддръжка за мултимодални задачи. Той намира баланс между точност и ефективност, подходящ за приложения, изискващи взаимодействие в реално време."
  },
  "gpt-4-0613": {
    "description": "GPT-4 предлага по-голям контекстуален прозорец, способен да обработва по-дълги текстови входове, подходящ за сценарии, изискващи интеграция на обширна информация и анализ на данни."
  },
  "gpt-4-1106-preview": {
    "description": "Най-новият модел GPT-4 Turbo разполага с визуални функции. Сега визуалните заявки могат да се използват с JSON формат и извиквания на функции. GPT-4 Turbo е подобрена версия, която предлага икономически ефективна поддръжка за мултимодални задачи. Той намира баланс между точност и ефективност, подходящ за приложения, изискващи взаимодействие в реално време."
  },
  "gpt-4-1106-vision-preview": {
    "description": "Най-новият модел GPT-4 Turbo разполага с визуални функции. Сега визуалните заявки могат да се използват с JSON формат и извиквания на функции. GPT-4 Turbo е подобрена версия, която предлага икономически ефективна поддръжка за мултимодални задачи. Той намира баланс между точност и ефективност, подходящ за приложения, изискващи взаимодействие в реално време."
  },
  "gpt-4-32k": {
    "description": "GPT-4 предлага по-голям контекстуален прозорец, способен да обработва по-дълги текстови входове, подходящ за сценарии, изискващи интеграция на обширна информация и анализ на данни."
  },
  "gpt-4-32k-0613": {
    "description": "GPT-4 предлага по-голям контекстуален прозорец, способен да обработва по-дълги текстови входове, подходящ за сценарии, изискващи интеграция на обширна информация и анализ на данни."
  },
  "gpt-4-turbo": {
    "description": "Най-новият модел GPT-4 Turbo разполага с визуални функции. Сега визуалните заявки могат да се използват с JSON формат и извиквания на функции. GPT-4 Turbo е подобрена версия, която предлага икономически ефективна поддръжка за мултимодални задачи. Той намира баланс между точност и ефективност, подходящ за приложения, изискващи взаимодействие в реално време."
  },
  "gpt-4-turbo-2024-04-09": {
    "description": "Най-новият модел GPT-4 Turbo разполага с визуални функции. Сега визуалните заявки могат да се използват с JSON формат и извиквания на функции. GPT-4 Turbo е подобрена версия, която предлага икономически ефективна поддръжка за мултимодални задачи. Той намира баланс между точност и ефективност, подходящ за приложения, изискващи взаимодействие в реално време."
  },
  "gpt-4-turbo-preview": {
    "description": "Най-новият модел GPT-4 Turbo разполага с визуални функции. Сега визуалните заявки могат да се използват с JSON формат и извиквания на функции. GPT-4 Turbo е подобрена версия, която предлага икономически ефективна поддръжка за мултимодални задачи. Той намира баланс между точност и ефективност, подходящ за приложения, изискващи взаимодействие в реално време."
  },
  "gpt-4-vision-preview": {
    "description": "Най-новият модел GPT-4 Turbo разполага с визуални функции. Сега визуалните заявки могат да се използват с JSON формат и извиквания на функции. GPT-4 Turbo е подобрена версия, която предлага икономически ефективна поддръжка за мултимодални задачи. Той намира баланс между точност и ефективност, подходящ за приложения, изискващи взаимодействие в реално време."
  },
  "gpt-4o": {
    "description": "ChatGPT-4o е динамичен модел, който се актуализира в реално време, за да поддържа най-новата версия. Той комбинира мощно разбиране на езика и генериране на текст, подходящ за мащабни приложения, включително обслужване на клиенти, образование и техническа поддръжка."
  },
  "gpt-4o-2024-05-13": {
    "description": "ChatGPT-4o е динамичен модел, който се актуализира в реално време, за да поддържа най-новата версия. Той комбинира мощно разбиране на езика и генериране на текст, подходящ за мащабни приложения, включително обслужване на клиенти, образование и техническа поддръжка."
  },
  "gpt-4o-2024-08-06": {
    "description": "ChatGPT-4o е динамичен модел, който се актуализира в реално време, за да поддържа най-новата версия. Той комбинира мощно разбиране на езика и генериране на текст, подходящ за мащабни приложения, включително обслужване на клиенти, образование и техническа поддръжка."
  },
  "gpt-4o-mini": {
    "description": "GPT-4o mini е най-новият модел на OpenAI, след GPT-4 Omni, който поддържа текстово и визуално въвеждане и генерира текст. Като най-напредналият им малък модел, той е значително по-евтин от другите нови модели и е с над 60% по-евтин от GPT-3.5 Turbo. Запазва най-съвременната интелигентност, като същевременно предлага значителна стойност за парите. GPT-4o mini получи 82% на теста MMLU и в момента е с по-висок рейтинг от GPT-4 по предпочитания за чат."
  },
  "grok-beta": {
    "description": "С производителност, сравнима с Grok 2, но с по-висока ефективност, скорост и функции."
  },
  "grok-vision-beta": {
    "description": "Най-новият модел за разбиране на изображения, способен да обработва разнообразна визуална информация, включително документи, графики, екранни снимки и снимки."
  },
  "gryphe/mythomax-l2-13b": {
    "description": "MythoMax l2 13B е езиков модел, който комбинира креативност и интелигентност, обединявайки множество водещи модели."
  },
  "hunyuan-code": {
    "description": "Най-новият модел за генериране на код на HunYuan, обучен с 200B висококачествени данни за код, с шестмесечно обучение на данни за SFT с високо качество, увеличен контекстен прозорец до 8K, и водещи резултати в автоматичните оценъчни показатели за генериране на код на пет основни езика; в комплексната оценка на кодови задачи на пет основни езика, представянето е в първата група."
  },
  "hunyuan-functioncall": {
    "description": "Най-новият модел на HunYuan с MOE архитектура за извикване на функции, обучен с висококачествени данни за извикване на функции, с контекстен прозорец от 32K, водещ в множество измерения на оценъчните показатели."
  },
  "hunyuan-lite": {
    "description": "Актуализиран до MOE структура, контекстният прозорец е 256k, водещ в множество оценъчни набори в NLP, код, математика и индустрия, пред много от отворените модели."
  },
  "hunyuan-pro": {
    "description": "Модел с параметри от триллион MOE-32K за дълги текстове. Постига абсолютни водещи нива в различни бенчмаркове, с комплексни инструкции и разсъждения, притежаващи сложни математически способности, поддържа функция за извикване, с акцент върху оптимизацията в области като многоезичен превод, финанси, право и медицина."
  },
  "hunyuan-role": {
    "description": "Най-новият модел за ролеви игри на HunYuan, официално настроен и обучен от HunYuan, базиран на модела HunYuan и данни от набори за ролеви игри, с по-добри основни резултати в ролевите игри."
  },
  "hunyuan-standard": {
    "description": "Използва по-добра стратегия за маршрутизиране, като същевременно облекчава проблемите с балансирането на натоварването и сближаването на експертите. За дълги текстове, показателят за откритие достига 99.9%. MOE-32K предлага по-добра цена-качество, балансирайки ефективността и цената, и позволява обработка на дълги текстови входове."
  },
  "hunyuan-standard-256K": {
    "description": "Използва по-добра стратегия за маршрутизиране, като същевременно облекчава проблемите с балансирането на натоварването и сближаването на експертите. За дълги текстове, показателят за откритие достига 99.9%. MOE-256K прави допълнителен пробив в дължината и ефективността, значително разширявайки допустимата дължина на входа."
  },
  "hunyuan-turbo": {
    "description": "Предварителна версия на новото поколение голям езиков модел на HunYuan, използваща нова структура на смесен експертен модел (MoE), с по-бърза скорост на извеждане и по-силни резултати в сравнение с hunyuan-pro."
  },
  "hunyuan-vision": {
    "description": "Най-новият мултимодален модел на HunYuan, поддържащ генериране на текстово съдържание от изображения и текстови входове."
  },
  "internlm/internlm2_5-20b-chat": {
    "description": "Иновативният отворен модел InternLM2.5 повишава интелигентността на диалога чрез голям брой параметри."
  },
  "internlm/internlm2_5-7b-chat": {
    "description": "InternLM2.5 предлага интелигентни решения за диалог в множество сценарии."
  },
  "internlm2-pro-chat": {
    "description": "По-стара версия на модела, която все още поддържаме, с налични параметри от 7B и 20B."
  },
  "internlm2.5-latest": {
    "description": "Нашата най-нова серия модели с изключителни способности за извеждане, поддържаща контекстна дължина от 1M и по-силни способности за следване на инструкции и извикване на инструменти."
  },
  "jamba-1.5-large": {},
  "jamba-1.5-mini": {},
  "lite": {
    "description": "Spark Lite е лек модел на голям език, с изключително ниска латентност и ефективна обработка, напълно безплатен и отворен, поддържащ функции за онлайн търсене в реално време. Неговите бързи отговори го правят отличен за приложения на нискомощни устройства и фина настройка на модели, предоставяйки на потребителите отлична рентабилност и интелигентно изживяване, особено в контекста на въпроси и отговори, генериране на съдържание и търсене."
  },
  "llama-3.1-70b-instruct": {
    "description": "Llama 3.1 70B Instruct модел, с 70B параметри, способен да предоставя изключителна производителност в задачи за генериране на текст и инструкции."
  },
  "llama-3.1-70b-versatile": {
    "description": "Llama 3.1 70B предлага по-мощни способности за разсъждение на AI, подходящи за сложни приложения, поддържащи множество изчислителни обработки и осигуряващи ефективност и точност."
  },
  "llama-3.1-8b-instant": {
    "description": "Llama 3.1 8B е модел с висока производителност, предлагащ бързи способности за генериране на текст, особено подходящ за приложения, изискващи мащабна ефективност и икономичност."
  },
  "llama-3.1-8b-instruct": {
    "description": "Llama 3.1 8B Instruct модел, с 8B параметри, поддържащ ефективно изпълнение на задачи с визуални указания, предлагащ качествени способности за генериране на текст."
  },
  "llama-3.1-sonar-huge-128k-online": {
    "description": "Llama 3.1 Sonar Huge Online модел, с 405B параметри, поддържащ контекстова дължина от около 127,000 маркера, проектиран за сложни онлайн чат приложения."
  },
  "llama-3.1-sonar-large-128k-chat": {
    "description": "Llama 3.1 Sonar Large Chat модел, с 70B параметри, поддържащ контекстова дължина от около 127,000 маркера, подходящ за сложни офлайн чат задачи."
  },
  "llama-3.1-sonar-large-128k-online": {
    "description": "Llama 3.1 Sonar Large Online модел, с 70B параметри, поддържащ контекстова дължина от около 127,000 маркера, подходящ за задачи с висока капацитет и разнообразие в чата."
  },
  "llama-3.1-sonar-small-128k-chat": {
    "description": "Llama 3.1 Sonar Small Chat модел, с 8B параметри, проектиран за офлайн чат, поддържащ контекстова дължина от около 127,000 маркера."
  },
  "llama-3.1-sonar-small-128k-online": {
    "description": "Llama 3.1 Sonar Small Online модел, с 8B параметри, поддържащ контекстова дължина от около 127,000 маркера, проектиран за онлайн чат, способен да обработва ефективно различни текстови взаимодействия."
  },
  "llama-3.2-11b-vision-instruct": {
    "description": "Изключителни способности за визуално разсъждение върху изображения с висока разделителна способност, подходящи за приложения за визуално разбиране."
  },
  "llama-3.2-11b-vision-preview": {
    "description": "Llama 3.2 е проектиран да обработва задачи, свързващи визуални и текстови данни. Той показва отлични резултати в задачи като описание на изображения и визуални въпроси и отговори, преодолявайки пропастта между генерирането на език и визуалното разсъждение."
  },
  "llama-3.2-90b-vision-instruct": {
    "description": "Разширени способности за визуално разсъждение, подходящи за приложения на визуални агенти."
  },
  "llama-3.2-90b-vision-preview": {
    "description": "Llama 3.2 е проектиран да обработва задачи, свързващи визуални и текстови данни. Той показва отлични резултати в задачи като описание на изображения и визуални въпроси и отговори, преодолявайки пропастта между генерирането на език и визуалното разсъждение."
  },
  "llama3-70b-8192": {
    "description": "Meta Llama 3 70B предлага ненадмината способност за обработка на сложност, проектирана за високи изисквания."
  },
  "llama3-8b-8192": {
    "description": "Meta Llama 3 8B предлага качествени способности за разсъждение, подходящи за множество приложения."
  },
  "llama3-groq-70b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 70B Tool Use предлага мощни способности за извикване на инструменти, поддържащи ефективна обработка на сложни задачи."
  },
  "llama3-groq-8b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 8B Tool Use е модел, оптимизиран за ефективна употреба на инструменти, поддържащ бързо паралелно изчисление."
  },
  "llama3.1": {
    "description": "Llama 3.1 е водещ модел, представен от Meta, поддържащ до 405B параметри, приложим в области като сложни диалози, многоезичен превод и анализ на данни."
  },
  "llama3.1:405b": {
    "description": "Llama 3.1 е водещ модел, представен от Meta, поддържащ до 405B параметри, приложим в области като сложни диалози, многоезичен превод и анализ на данни."
  },
  "llama3.1:70b": {
    "description": "Llama 3.1 е водещ модел, представен от Meta, поддържащ до 405B параметри, приложим в области като сложни диалози, многоезичен превод и анализ на данни."
  },
  "llava": {
    "description": "LLaVA е многомодален модел, комбиниращ визуален кодер и Vicuna, предназначен за мощно визуално и езиково разбиране."
  },
  "llava-v1.5-7b-4096-preview": {
    "description": "LLaVA 1.5 7B предлага интегрирани способности за визуална обработка, генерирайки сложни изходи чрез визуална информация."
  },
  "llava:13b": {
    "description": "LLaVA е многомодален модел, комбиниращ визуален кодер и Vicuna, предназначен за мощно визуално и езиково разбиране."
  },
  "llava:34b": {
    "description": "LLaVA е многомодален модел, комбиниращ визуален кодер и Vicuna, предназначен за мощно визуално и езиково разбиране."
  },
  "mathstral": {
    "description": "MathΣtral е проектиран за научни изследвания и математически разсъждения, предоставяйки ефективни изчислителни способности и интерпретация на резултати."
  },
  "max-32k": {
    "description": "Spark Max 32K е конфигуриран с голяма способност за обработка на контекст, с по-силно разбиране на контекста и логическо разсъждение, поддържащ текстови входове до 32K токена, подходящ за четене на дълги документи, частни въпроси и отговори и други сценарии."
  },
  "meta-llama-3-70b-instruct": {
    "description": "Мощен модел с 70 милиарда параметри, отличаващ се в разсъждения, кодиране и широки езикови приложения."
  },
  "meta-llama-3-8b-instruct": {
    "description": "Универсален модел с 8 милиарда параметри, оптимизиран за диалогови и текстови генериращи задачи."
  },
  "meta-llama-3.1-405b-instruct": {
    "description": "Моделите на Llama 3.1, настроени за инструкции, са оптимизирани за многоезични диалогови случаи на употреба и надминават много от наличните модели с отворен код и затворени чат модели на общи индустриални стандарти."
  },
  "meta-llama-3.1-70b-instruct": {
    "description": "Моделите на Llama 3.1, настроени за инструкции, са оптимизирани за многоезични диалогови случаи на употреба и надминават много от наличните модели с отворен код и затворени чат модели на общи индустриални стандарти."
  },
  "meta-llama-3.1-8b-instruct": {
    "description": "Моделите на Llama 3.1, настроени за инструкции, са оптимизирани за многоезични диалогови случаи на употреба и надминават много от наличните модели с отворен код и затворени чат модели на общи индустриални стандарти."
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "description": "LLaMA-2 Chat (13B) предлага отлични способности за обработка на език и изключителен интерактивен опит."
  },
  "meta-llama/Llama-2-70b-hf": {
    "description": "LLaMA-2 предлага отлични способности за обработка на език и невероятно потребителско изживяване."
  },
  "meta-llama/Llama-3-70b-chat-hf": {
    "description": "LLaMA-3 Chat (70B) е мощен чат модел, поддържащ сложни изисквания за диалог."
  },
  "meta-llama/Llama-3-8b-chat-hf": {
    "description": "LLaMA-3 Chat (8B) предлага многоезична поддръжка, обхващаща богати области на знание."
  },
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2 е проектирана да обработва задачи, комбиниращи визуални и текстови данни. Тя демонстрира отлични резултати в задачи като описание на изображения и визуални въпроси и отговори, преодолявайки пропастта между генерирането на езици и визуалното разсъждение."
  },
  "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
    "description": "LLaMA 3.2 е проектирана да обработва задачи, комбиниращи визуални и текстови данни. Тя демонстрира отлични резултати в задачи като описание на изображения и визуални въпроси и отговори, преодолявайки пропастта между генерирането на езици и визуалното разсъждение."
  },
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2 е проектирана да обработва задачи, комбиниращи визуални и текстови данни. Тя демонстрира отлични резултати в задачи като описание на изображения и визуални въпроси и отговори, преодолявайки пропастта между генерирането на езици и визуалното разсъждение."
  },
  "meta-llama/Llama-Vision-Free": {
    "description": "LLaMA 3.2 е проектирана да обработва задачи, комбиниращи визуални и текстови данни. Тя демонстрира отлични резултати в задачи като описание на изображения и визуални въпроси и отговори, преодолявайки пропастта между генерирането на езици и визуалното разсъждение."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite": {
    "description": "Llama 3 70B Instruct Lite е подходящ за среди, изискващи висока производителност и ниска латентност."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo": {
    "description": "Llama 3 70B Instruct Turbo предлага изключителни способности за разбиране и генериране на език, подходящи за най-строги изчислителни задачи."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
    "description": "Llama 3 8B Instruct Lite е подходящ за среди с ограничени ресурси, предлагащи отличен баланс на производителност."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo": {
    "description": "Llama 3 8B Instruct Turbo е високоефективен голям езиков модел, поддържащ широк спектър от приложения."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct": {
    "description": "LLaMA 3.1 405B е мощен модел за предварително обучение и настройка на инструкции."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
    "description": "405B Llama 3.1 Turbo моделът предлага огромна контекстова поддръжка за обработка на големи данни, с изключителна производителност в приложения с изкуствен интелект с много голям мащаб."
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct": {
    "description": "LLaMA 3.1 70B предлага ефективна поддръжка за многоезични диалози."
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
    "description": "Llama 3.1 70B моделът е прецизно настроен за приложения с високо натоварване, квантован до FP8, осигурявайки по-ефективна изчислителна мощ и точност, гарантиращи изключителна производителност в сложни сценарии."
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "description": "LLaMA 3.1 предлага многоезична поддръжка и е един от водещите генеративни модели в индустрията."
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
    "description": "Llama 3.1 8B моделът използва FP8 квантоване, поддържа до 131,072 контекстови маркера и е сред най-добрите отворени модели, подходящи за сложни задачи, с производителност, превъзхождаща много индустриални стандарти."
  },
  "meta-llama/llama-3-70b-instruct": {
    "description": "Llama 3 70B Instruct е оптимизирана за висококачествени диалогови сценарии и показва отлични резултати в различни човешки оценки."
  },
  "meta-llama/llama-3-8b-instruct": {
    "description": "Llama 3 8B Instruct е оптимизирана за висококачествени диалогови сценарии, с представяне, надминаващо много затворени модели."
  },
  "meta-llama/llama-3.1-405b-instruct": {
    "description": "Llama 3.1 405B Instruct е най-новата версия на Meta, оптимизирана за генериране на висококачествени диалози, надминаваща много водещи затворени модели."
  },
  "meta-llama/llama-3.1-70b-instruct": {
    "description": "Llama 3.1 70B Instruct е проектиран за висококачествени диалози и показва отлични резултати в човешките оценки, особено подходящ за сценарии с висока интерактивност."
  },
  "meta-llama/llama-3.1-8b-instruct": {
    "description": "Llama 3.1 8B Instruct е най-новата версия, пусната от Meta, оптимизирана за висококачествени диалогови сценарии, с представяне, надминаващо много водещи затворени модели."
  },
  "meta-llama/llama-3.1-8b-instruct:free": {
    "description": "LLaMA 3.1 предлага поддръжка на множество езици и е един от водещите генеративни модели в индустрията."
  },
  "meta-llama/llama-3.2-11b-vision-instruct": {
    "description": "LLaMA 3.2 е проектиран да обработва задачи, свързващи визуални и текстови данни. Той показва отлични резултати в задачи като описание на изображения и визуални въпроси, преодолявайки пропастта между генерирането на език и визуалното разсъждение."
  },
  "meta-llama/llama-3.2-90b-vision-instruct": {
    "description": "LLaMA 3.2 е проектиран да обработва задачи, свързващи визуални и текстови данни. Той показва отлични резултати в задачи като описание на изображения и визуални въпроси, преодолявайки пропастта между генерирането на език и визуалното разсъждение."
  },
  "meta.llama3-1-405b-instruct-v1:0": {
    "description": "Meta Llama 3.1 405B Instruct е най-голямата и най-мощната версия на модела Llama 3.1 Instruct. Това е високо напреднал модел за диалогово разсъждение и генериране на синтетични данни, който може да се използва и като основа за професионално продължително предварително обучение или фино настройване в специфични области. Многоезичният голям езиков модел (LLMs), предоставен от Llama 3.1, е набор от предварително обучени, коригирани по инструкции генеративни модели, включително размери 8B, 70B и 405B (текстов вход/изход). Текстовите модели, коригирани по инструкции (8B, 70B, 405B), са оптимизирани за многоезични диалогови случаи и надминават много налични отворени чат модели в общи индустриални бенчмаркове. Llama 3.1 е проектиран за търговски и изследователски цели на множество езици. Моделите, коригирани по инструкции, са подходящи за чатове, подобни на асистенти, докато предварително обучените модели могат да се адаптират към различни задачи за генериране на естествен език. Моделите на Llama 3.1 също поддържат използването на изхода на модела за подобряване на други модели, включително генериране на синтетични данни и рафиниране. Llama 3.1 е саморегресивен езиков модел, използващ оптимизирана трансформаторна архитектура. Коригираните версии използват супервизирано фино настройване (SFT) и обучение с човешка обратна връзка (RLHF), за да отговорят на предпочитанията на хората за полезност и безопасност."
  },
  "meta.llama3-1-70b-instruct-v1:0": {
    "description": "Актуализирана версия на Meta Llama 3.1 70B Instruct, включваща разширен контекстуален прозорец от 128K, многоезичност и подобрени способности за разсъждение. Многоезичният голям езиков модел (LLMs) на Llama 3.1 е набор от предварително обучени, коригирани за инструкции генериращи модели, включващи размери 8B, 70B и 405B (текстово въвеждане/изход). Текстовите модели, коригирани за инструкции (8B, 70B, 405B), са оптимизирани за многоезични диалогови случаи и надминават много налични отворени чат модели в общи индустриални бенчмаркове. Llama 3.1 е проектиран за търговски и изследователски цели на множество езици. Текстовите модели, коригирани за инструкции, са подходящи за чат, подобен на асистент, докато предварително обучените модели могат да се адаптират за различни задачи по генериране на естествен език. Моделите на Llama 3.1 също поддържат използването на изхода на модела за подобряване на други модели, включително генериране на синтетични данни и рафиниране. Llama 3.1 е саморегресивен езиков модел, използващ оптимизирана архитектура на трансформатор. Коригираните версии използват наблюдавано фино настройване (SFT) и обучение с подсилване с човешка обратна връзка (RLHF), за да отговорят на предпочитанията на хората за полезност и безопасност."
  },
  "meta.llama3-1-8b-instruct-v1:0": {
    "description": "Актуализирана версия на Meta Llama 3.1 8B Instruct, включваща разширен контекстуален прозорец от 128K, многоезичност и подобрени способности за разсъждение. Многоезичният голям езиков модел (LLMs) на Llama 3.1 е набор от предварително обучени, коригирани за инструкции генериращи модели, включващи размери 8B, 70B и 405B (текстово въвеждане/изход). Текстовите модели, коригирани за инструкции (8B, 70B, 405B), са оптимизирани за многоезични диалогови случаи и надминават много налични отворени чат модели в общи индустриални бенчмаркове. Llama 3.1 е проектиран за търговски и изследователски цели на множество езици. Текстовите модели, коригирани за инструкции, са подходящи за чат, подобен на асистент, докато предварително обучените модели могат да се адаптират за различни задачи по генериране на естествен език. Моделите на Llama 3.1 също поддържат използването на изхода на модела за подобряване на други модели, включително генериране на синтетични данни и рафиниране. Llama 3.1 е саморегресивен езиков модел, използващ оптимизирана архитектура на трансформатор. Коригираните версии използват наблюдавано фино настройване (SFT) и обучение с подсилване с човешка обратна връзка (RLHF), за да отговорят на предпочитанията на хората за полезност и безопасност."
  },
  "meta.llama3-70b-instruct-v1:0": {
    "description": "Meta Llama 3 е отворен голям езиков модел (LLM), насочен към разработчици, изследователи и предприятия, предназначен да им помогне да изградят, експериментират и отговорно разширят своите идеи за генеративен ИИ. Като част от основната система на глобалната общност за иновации, той е особено подходящ за създаване на съдържание, диалогов ИИ, разбиране на езика, научноизследователска и развойна дейност и бизнес приложения."
  },
  "meta.llama3-8b-instruct-v1:0": {
    "description": "Meta Llama 3 е отворен голям езиков модел (LLM), насочен към разработчици, изследователи и предприятия, предназначен да им помогне да изградят, експериментират и отговорно разширят своите идеи за генеративен ИИ. Като част от основната система на глобалната общност за иновации, той е особено подходящ за устройства с ограничени изчислителни ресурси и по-бързо време за обучение."
  },
  "microsoft/wizardlm 2-7b": {
    "description": "WizardLM 2 7B е най-новият бърз и лек модел на Microsoft AI, с производителност, близка до 10 пъти на съществуващите водещи отворени модели."
  },
  "microsoft/wizardlm-2-8x22b": {
    "description": "WizardLM-2 8x22B е най-напредналият Wizard модел на Microsoft AI, показващ изключителна конкурентоспособност."
  },
  "minicpm-v": {
    "description": "MiniCPM-V е новото поколение мултимодален голям модел, представен от OpenBMB, който притежава изключителни способности за OCR разпознаване и мултимодално разбиране, поддържащ широк спектър от приложения."
  },
  "ministral-3b-latest": {
    "description": "Ministral 3B е световен лидер сред моделите на Mistral."
  },
  "ministral-8b-latest": {
    "description": "Ministral 8B е модел на Mistral с отлична цена-качество."
  },
  "mistral": {
    "description": "Mistral е 7B модел, представен от Mistral AI, подходящ за променливи нужди в обработката на език."
  },
  "mistral-large": {
    "description": "Mixtral Large е флагманският модел на Mistral, комбиниращ способности за генериране на код, математика и разсъждение, поддържащ контекстен прозорец от 128k."
  },
  "mistral-large-latest": {
    "description": "Mistral Large е флагманският модел, специализиран в многоезични задачи, сложни разсъждения и генериране на код, идеален за висококачествени приложения."
  },
  "mistral-nemo": {
    "description": "Mistral Nemo е 12B модел, разработен в сътрудничество между Mistral AI и NVIDIA, предлагащ ефективна производителност."
  },
  "mistral-small": {
    "description": "Mistral Small може да се използва за всяка езикова задача, която изисква висока ефективност и ниска латентност."
  },
  "mistral-small-latest": {
    "description": "Mistral Small е икономически ефективен, бърз и надежден вариант, подходящ за случаи на употреба като превод, резюме и анализ на настроението."
  },
  "mistralai/Mistral-7B-Instruct-v0.1": {
    "description": "Mistral (7B) Instruct е известен с високата си производителност, подходящ за множество езикови задачи."
  },
  "mistralai/Mistral-7B-Instruct-v0.2": {
    "description": "Mistral 7B е модел с фино настройване по заявка, предлагащ оптимизирани отговори за задачи."
  },
  "mistralai/Mistral-7B-Instruct-v0.3": {
    "description": "Mistral (7B) Instruct v0.3 предлага ефективна изчислителна мощ и разбиране на естествения език, подходяща за широк спектър от приложения."
  },
  "mistralai/Mistral-7B-v0.1": {
    "description": "Mistral 7B е компактен, но високопроизводителен модел, специализиран в обработка на партиди и основни задачи, като класификация и генериране на текст с добри способности за разсъждение."
  },
  "mistralai/Mixtral-8x22B-Instruct-v0.1": {
    "description": "Mixtral-8x22B Instruct (141B) е супер голям езиков модел, поддържащ изключително високи изисквания за обработка."
  },
  "mistralai/Mixtral-8x7B-Instruct-v0.1": {
    "description": "Mixtral 8x7B е предварително обучен модел на разредени смесени експерти, предназначен за универсални текстови задачи."
  },
  "mistralai/Mixtral-8x7B-v0.1": {
    "description": "Mixtral 8x7B е модел с рядък експерт, който използва множество параметри, за да подобри скоростта на разсъждение, подходящ за обработка на многоезични и генериращи код задачи."
  },
  "mistralai/mistral-7b-instruct": {
    "description": "Mistral 7B Instruct е високопроизводителен индустриален стандартен модел, оптимизиран за бързина и поддръжка на дълги контексти."
  },
  "mistralai/mistral-nemo": {
    "description": "Mistral Nemo е модел с 7.3B параметри, предлагащ многоезична поддръжка и висока производителност."
  },
  "mixtral": {
    "description": "Mixtral е експертен модел на Mistral AI, с отворени тегла, предоставящ поддръжка в генерирането на код и разбиране на езика."
  },
  "mixtral-8x7b-32768": {
    "description": "Mixtral 8x7B предлага висока толерантност на грешки при паралелно изчисление, подходяща за сложни задачи."
  },
  "mixtral:8x22b": {
    "description": "Mixtral е експертен модел на Mistral AI, с отворени тегла, предоставящ поддръжка в генерирането на код и разбиране на езика."
  },
  "moonshot-v1-128k": {
    "description": "Moonshot V1 128K е модел с изключителна способност за обработка на дълги контексти, подходящ за генериране на много дълги текстове, отговарящи на сложни изисквания за генериране, способен да обработва до 128,000 токена, особено подходящ за научни изследвания, академични и генериране на големи документи."
  },
  "moonshot-v1-32k": {
    "description": "Moonshot V1 32K предлага средна дължина на контекста, способен да обработва 32,768 токена, особено подходящ за генериране на различни дълги документи и сложни диалози, използван в области като създаване на съдържание, генериране на отчети и диалогови системи."
  },
  "moonshot-v1-8k": {
    "description": "Moonshot V1 8K е проектиран за генериране на кратки текстови задачи, с ефективна производителност, способен да обработва 8,192 токена, особено подходящ за кратки диалози, бележки и бързо генериране на съдържание."
  },
  "nousresearch/hermes-2-pro-llama-3-8b": {
    "description": "Hermes 2 Pro Llama 3 8B е обновена версия на Nous Hermes 2, включваща най-новите вътрешно разработени набори от данни."
  },
  "nvidia/Llama-3.1-Nemotron-70B-Instruct": {
    "description": "Llama 3.1 Nemotron 70B е голям езиков модел, персонализиран от NVIDIA с цел подобряване на отговорите на потребителските запитвания."
  },
  "o1-mini": {
    "description": "o1-mini е бърз и икономичен модел за изводи, проектиран за приложения в програмирането, математиката и науката. Моделът разполага с контекст от 128K и дата на знание до октомври 2023."
  },
  "o1-preview": {
    "description": "o1 е новият модел за изводи на OpenAI, подходящ за сложни задачи, изискващи обширни общи знания. Моделът разполага с контекст от 128K и дата на знание до октомври 2023."
  },
  "open-codestral-mamba": {
    "description": "Codestral Mamba е модел на езика Mamba 2, специализиран в генерирането на код, предоставящ мощна поддръжка за напреднали кодови и разсъждателни задачи."
  },
  "open-mistral-7b": {
    "description": "Mistral 7B е компактен, но високопроизводителен модел, специализиран в обработка на партиди и прости задачи, като класификация и генериране на текст, с добра способност за разсъждение."
  },
  "open-mistral-nemo": {
    "description": "Mistral Nemo е 12B модел, разработен в сътрудничество с Nvidia, предлагащ отлични способности за разсъждение и кодиране, лесен за интеграция и замяна."
  },
  "open-mixtral-8x22b": {
    "description": "Mixtral 8x22B е по-голям експертен модел, фокусиран върху сложни задачи, предлагащ отлични способности за разсъждение и по-висока производителност."
  },
  "open-mixtral-8x7b": {
    "description": "Mixtral 8x7B е рядък експертен модел, който използва множество параметри за увеличаване на скоростта на разсъждение, подходящ за обработка на многоезични и кодови генериращи задачи."
  },
  "openai/gpt-4o": {
    "description": "ChatGPT-4o е динамичен модел, който се актуализира в реално време, за да поддържа най-новата версия. Той комбинира мощно разбиране на езика и способности за генериране, подходящ за мащабни приложения, включително обслужване на клиенти, образование и техническа поддръжка."
  },
  "openai/gpt-4o-mini": {
    "description": "GPT-4o mini е най-новият модел на OpenAI, пуснат след GPT-4 Omni, който поддържа вход и изход на текст и изображения. Като най-напредналият им малък модел, той е значително по-евтин от другите нови модели и е с над 60% по-евтин от GPT-3.5 Turbo. Запазва най-съвременната интелигентност, като предлага значителна стойност за парите. GPT-4o mini получи 82% на теста MMLU и в момента е с по-висок рейтинг от GPT-4 в предпочитанията за чат."
  },
  "openai/o1-mini": {
    "description": "o1-mini е бърз и икономичен модел за изводи, проектиран за приложения в програмирането, математиката и науката. Моделът разполага с контекст от 128K и дата на знание до октомври 2023."
  },
  "openai/o1-preview": {
    "description": "o1 е новият модел за изводи на OpenAI, подходящ за сложни задачи, изискващи обширни общи знания. Моделът разполага с контекст от 128K и дата на знание до октомври 2023."
  },
  "openchat/openchat-7b": {
    "description": "OpenChat 7B е отворен езиков модел, прецизно настроен с помощта на стратегията „C-RLFT (условно подсилващо обучение)“."
  },
  "openrouter/auto": {
    "description": "В зависимост от дължината на контекста, темата и сложността, вашето запитване ще бъде изпратено до Llama 3 70B Instruct, Claude 3.5 Sonnet (саморегулиращ) или GPT-4o."
  },
  "phi3": {
    "description": "Phi-3 е лек отворен модел, представен от Microsoft, подходящ за ефективна интеграция и мащабно знание разсъждение."
  },
  "phi3:14b": {
    "description": "Phi-3 е лек отворен модел, представен от Microsoft, подходящ за ефективна интеграция и мащабно знание разсъждение."
  },
  "pixtral-12b-2409": {
    "description": "Моделът Pixtral демонстрира силни способности в задачи като разбиране на графики и изображения, отговори на документи, многомодално разсъждение и следване на инструкции, способен да приема изображения с естествено разрешение и съотношение на страните, както и да обработва произволен брой изображения в контекстен прозорец с дължина до 128K токена."
  },
  "pixtral-large-latest": {
    "description": "Pixtral Large е отворен многомодален модел с 1240 милиарда параметри, базиран на Mistral Large 2. Това е вторият модел в нашето многомодално семейство, който демонстрира авангардни способности за разбиране на изображения."
  },
  "pro-128k": {
    "description": "Spark Pro 128K е конфигуриран с изключителна способност за обработка на контекст, способен да обработва до 128K контекстна информация, особено подходящ за дълги текстове, изискващи цялостен анализ и дългосрочна логическа свързаност, предоставяйки гладка и последователна логика и разнообразна поддръжка на цитати в сложни текстови комуникации."
  },
  "qwen-coder-plus-latest": {
    "description": "Модел за кодиране Qwen с общо предназначение."
  },
  "qwen-coder-turbo-latest": {
    "description": "Моделът на кода Qwen."
  },
  "qwen-long": {
    "description": "Qwen е мащабен езиков модел, който поддържа дълги текстови контексти и диалогови функции, базирани на дълги документи и множество документи."
  },
  "qwen-math-plus-latest": {
    "description": "Математическият модел Qwen е специално проектиран за решаване на математически задачи."
  },
  "qwen-math-turbo-latest": {
    "description": "Математическият модел Qwen е специално проектиран за решаване на математически задачи."
  },
  "qwen-max-latest": {
    "description": "Qwen Max е езиков модел с мащаб от стотици милиарди параметри, който поддържа вход на различни езици, включително китайски и английски. В момента е основният API модел зад версията на продукта Qwen 2.5."
  },
  "qwen-plus-latest": {
    "description": "Разширената версия на Qwen Turbo е мащабен езиков модел, който поддържа вход на различни езици, включително китайски и английски."
  },
  "qwen-turbo-latest": {
    "description": "Моделът на езика Qwen Turbo е мащабен езиков модел, който поддържа вход на различни езици, включително китайски и английски."
  },
  "qwen-vl-chat-v1": {
    "description": "Qwen VL поддържа гъвкави интерактивни методи, включително множество изображения, многократни въпроси и отговори, творчество и др."
  },
  "qwen-vl-max-latest": {
    "description": "Qwen-VL Max е модел за визуален език с изключително голям мащаб. В сравнение с подобрената версия, той отново подобрява способността за визуално разсъждение и следване на инструкции, предоставяйки по-високо ниво на визуално възприятие и познание."
  },
  "qwen-vl-plus-latest": {
    "description": "Моделят за визуален език Qwen-VL Plus е подобрена версия с голям мащаб. Значително подобрява способността за разпознаване на детайли и текст, поддържа резолюция над милион пиксела и изображения с произволно съотношение на страните."
  },
  "qwen-vl-v1": {
    "description": "Инициализиран с езиковия модел Qwen-7B, добавя модел за изображения, предтренировъчен модел с резолюция на входа от 448."
  },
  "qwen/qwen-2-7b-instruct:free": {
    "description": "Qwen2 е нова серия от големи езикови модели с по-силни способности за разбиране и генериране."
  },
  "qwen2": {
    "description": "Qwen2 е новото поколение голям езиков модел на Alibaba, предлагащ отлична производителност за разнообразни приложения."
  },
  "qwen2.5-14b-instruct": {
    "description": "Модел с мащаб 14B, отворен за обществеността от Qwen 2.5."
  },
  "qwen2.5-32b-instruct": {
    "description": "Модел с мащаб 32B, отворен за обществеността от Qwen 2.5."
  },
  "qwen2.5-72b-instruct": {
    "description": "Модел с мащаб 72B, отворен за обществеността от Qwen 2.5."
  },
  "qwen2.5-7b-instruct": {
    "description": "Модел с мащаб 7B, отворен за обществеността от Qwen 2.5."
  },
  "qwen2.5-coder-32b-instruct": {
    "description": "Отворена версия на модела за кодиране Qwen с общо предназначение."
  },
  "qwen2.5-coder-7b-instruct": {
    "description": "Отворената версия на модела на кода Qwen."
  },
  "qwen2.5-math-72b-instruct": {
    "description": "Моделът Qwen-Math притежава силни способности за решаване на математически задачи."
  },
  "qwen2.5-math-7b-instruct": {
    "description": "Моделът Qwen-Math притежава силни способности за решаване на математически задачи."
  },
  "qwen2:0.5b": {
    "description": "Qwen2 е новото поколение голям езиков модел на Alibaba, предлагащ отлична производителност за разнообразни приложения."
  },
  "qwen2:1.5b": {
    "description": "Qwen2 е новото поколение голям езиков модел на Alibaba, предлагащ отлична производителност за разнообразни приложения."
  },
  "qwen2:72b": {
    "description": "Qwen2 е новото поколение голям езиков модел на Alibaba, предлагащ отлична производителност за разнообразни приложения."
  },
  "solar-1-mini-chat": {
    "description": "Solar Mini е компактен LLM, с производителност над GPT-3.5, предлагащ мощни многоезични способности, поддържащ английски и корейски, предоставяйки ефективно и компактно решение."
  },
  "solar-1-mini-chat-ja": {
    "description": "Solar Mini (Ja) разширява възможностите на Solar Mini, фокусирайки се върху японския език, като същевременно поддържа висока ефективност и отлична производителност на английски и корейски."
  },
  "solar-pro": {
    "description": "Solar Pro е високоинтелигентен LLM, пуснат от Upstage, фокусиран върху способността за следване на инструкции с един GPU, с IFEval оценка над 80. В момента поддържа английски, а официалната версия е планирана за пускане през ноември 2024 г., с разширена поддръжка на езици и дължина на контекста."
  },
  "step-1-128k": {
    "description": "Баланс между производителност и разходи, подходящ за общи сценарии."
  },
  "step-1-256k": {
    "description": "Супер дълга контекстова обработка, особено подходяща за анализ на дълги документи."
  },
  "step-1-32k": {
    "description": "Поддържа диалози със средна дължина, подходящи за множество приложения."
  },
  "step-1-8k": {
    "description": "Малък модел, подходящ за леки задачи."
  },
  "step-1-flash": {
    "description": "Бърз модел, подходящ за реални диалози."
  },
  "step-1.5v-mini": {
    "description": "Този модел разполага с мощни способности за разбиране на видео."
  },
  "step-1v-32k": {
    "description": "Поддържа визуални входове, подобряваща мултимодалното взаимодействие."
  },
  "step-1v-8k": {
    "description": "Малък визуален модел, подходящ за основни текстово-визуални задачи."
  },
  "step-2-16k": {
    "description": "Поддържа взаимодействия с голям мащаб на контекста, подходящи за сложни диалогови сценарии."
  },
  "taichu_llm": {
    "description": "Моделът на езика TaiChu е с изключителни способности за разбиране на езика, текстово генериране, отговори на знания, програмиране, математически изчисления, логическо разсъждение, анализ на емоции, резюмиране на текст и др. Иновативно комбинира предварително обучение с големи данни и разнообразни източници на знания, чрез непрекъснато усъвършенстване на алгоритмичните технологии и усвояване на нови знания от масивни текстови данни, за да осигури на потребителите по-удобна информация и услуги, както и по-интелигентно изживяване."
  },
  "togethercomputer/StripedHyena-Nous-7B": {
    "description": "StripedHyena Nous (7B) предлага подобрена изчислителна мощ чрез ефективни стратегии и архитектура на модела."
  },
  "upstage/SOLAR-10.7B-Instruct-v1.0": {
    "description": "Upstage SOLAR Instruct v1 (11B) е подходящ за прецизни задачи с инструкции, предлагащи отлични способности за обработка на език."
  },
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnet повишава индустриалните стандарти, с производителност, надминаваща конкурентните модели и Claude 3 Opus, показвайки отлични резултати в широк спектър от оценки, като същевременно предлага скорост и разходи, сравними с нашите модели от средно ниво."
  },
  "wizardlm2": {
    "description": "WizardLM 2 е езиков модел, предоставен от Microsoft AI, който се отличава в сложни диалози, многоезичност, разсъждение и интелигентни асистенти."
  },
  "wizardlm2:8x22b": {
    "description": "WizardLM 2 е езиков модел, предоставен от Microsoft AI, който се отличава в сложни диалози, многоезичност, разсъждение и интелигентни асистенти."
  },
  "yi-large": {
    "description": "Новият модел с хиляда милиарда параметри предлага изключителни способности за отговори и генериране на текст."
  },
  "yi-large-fc": {
    "description": "Поддържа и усилва способностите за извикване на инструменти на базата на модела yi-large, подходящ за различни бизнес сценарии, изискващи изграждане на агенти или работни потоци."
  },
  "yi-large-preview": {
    "description": "Начална версия, препоръчва се да се използва yi-large (новата версия)."
  },
  "yi-large-rag": {
    "description": "Висококачествена услуга, базирана на мощния модел yi-large, комбинираща технологии за извличане и генериране, предлагаща точни отговори и услуги за търсене на информация в реално време."
  },
  "yi-large-turbo": {
    "description": "Изключителна производителност на висока цена. Балансирано прецизно настройване на производителността и скоростта на разсъжденията."
  },
  "yi-lightning": {
    "description": "Най-новият високо производителен модел, който гарантира висококачествени изходи, докато значително ускорява времето за разсъждение."
  },
  "yi-lightning-lite": {
    "description": "Лека версия, препоръчително е да се използва yi-lightning."
  },
  "yi-medium": {
    "description": "Модел с среден размер, обновен и прецизно настроен, с балансирани способности и висока цена на производителност."
  },
  "yi-medium-200k": {
    "description": "200K свръхдълъг контекстов прозорец, предлагащ дълбочинно разбиране и генериране на дълги текстове."
  },
  "yi-spark": {
    "description": "Малък и мощен, лек и бърз модел. Предлага подобрени способности за математически операции и писане на код."
  },
  "yi-vision": {
    "description": "Модел за сложни визуални задачи, предлагащ висока производителност за разбиране и анализ на изображения."
  }
}
